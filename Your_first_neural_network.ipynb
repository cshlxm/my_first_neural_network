{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 你的第一个神经网络\n",
    "\n",
    "在此项目中，你将构建你的第一个神经网络，并用该网络预测每日自行车租客人数。我们提供了一些代码，但是需要你来实现神经网络（大部分内容）。提交此项目后，欢迎进一步探索该数据和模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载和准备数据\n",
    "\n",
    "构建神经网络的关键一步是正确地准备数据。不同尺度级别的变量使网络难以高效地掌握正确的权重。我们在下方已经提供了加载和准备数据的代码。你很快将进一步学习这些代码！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = 'Bike-Sharing-Dataset/hour.csv'\n",
    "\n",
    "rides = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据简介\n",
    "\n",
    "此数据集包含的是从 2011 年 1 月 1 日到 2012 年 12 月 31 日期间每天每小时的骑车人数。骑车用户分成临时用户和注册用户，cnt 列是骑车用户数汇总列。你可以在上方看到前几行数据。\n",
    "\n",
    "下图展示的是数据集中前 10 天左右的骑车人数（某些天不一定是 24 个条目，所以不是精确的 10 天）。你可以在这里看到每小时租金。这些数据很复杂！周末的骑行人数少些，工作日上下班期间是骑行高峰期。我们还可以从上方的数据中看到温度、湿度和风速信息，所有这些信息都会影响骑行人数。你需要用你的模型展示所有这些数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x101decba8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvgAAAIPCAYAAAAGtapCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzMzM6uQ/wNsebXPxKcHXgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1073b5eb8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 263,
       "width": 380
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rides[:24*10].plot(x='dteday', y='cnt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 虚拟变量（哑变量）\n",
    "\n",
    "下面是一些分类变量，例如季节、天气、月份。要在我们的模型中包含这些数据，我们需要创建二进制虚拟变量。用 Pandas 库中的 `get_dummies()` 就可以轻松实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "      <th>season_1</th>\n",
       "      <th>season_2</th>\n",
       "      <th>...</th>\n",
       "      <th>hr_21</th>\n",
       "      <th>hr_22</th>\n",
       "      <th>hr_23</th>\n",
       "      <th>weekday_0</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   yr  holiday  temp   hum  windspeed  casual  registered  cnt  season_1  \\\n",
       "0   0        0  0.24  0.81        0.0       3          13   16         1   \n",
       "1   0        0  0.22  0.80        0.0       8          32   40         1   \n",
       "2   0        0  0.22  0.80        0.0       5          27   32         1   \n",
       "3   0        0  0.24  0.75        0.0       3          10   13         1   \n",
       "4   0        0  0.24  0.75        0.0       0           1    1         1   \n",
       "\n",
       "   season_2    ...      hr_21  hr_22  hr_23  weekday_0  weekday_1  weekday_2  \\\n",
       "0         0    ...          0      0      0          0          0          0   \n",
       "1         0    ...          0      0      0          0          0          0   \n",
       "2         0    ...          0      0      0          0          0          0   \n",
       "3         0    ...          0      0      0          0          0          0   \n",
       "4         0    ...          0      0      0          0          0          0   \n",
       "\n",
       "   weekday_3  weekday_4  weekday_5  weekday_6  \n",
       "0          0          0          0          1  \n",
       "1          0          0          0          1  \n",
       "2          0          0          0          1  \n",
       "3          0          0          0          1  \n",
       "4          0          0          0          1  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_fields = ['season', 'weathersit', 'mnth', 'hr', 'weekday']\n",
    "for each in dummy_fields:\n",
    "    dummies = pd.get_dummies(rides[each], prefix=each, drop_first=False)\n",
    "    rides = pd.concat([rides, dummies], axis=1)\n",
    "\n",
    "fields_to_drop = ['instant', 'dteday', 'season', 'weathersit', \n",
    "                  'weekday', 'atemp', 'mnth', 'workingday', 'hr']\n",
    "data = rides.drop(fields_to_drop, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调整目标变量\n",
    "\n",
    "为了更轻松地训练网络，我们将对每个连续变量标准化，即转换和调整变量，使它们的均值为 0，标准差为 1。\n",
    "\n",
    "我们会保存换算因子，以便当我们使用网络进行预测时可以还原数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quant_features = ['casual', 'registered', 'cnt', 'temp', 'hum', 'windspeed']\n",
    "# Store scalings in a dictionary so we can convert back later\n",
    "scaled_features = {}\n",
    "for each in quant_features:\n",
    "    mean, std = data[each].mean(), data[each].std()\n",
    "    scaled_features[each] = [mean, std]\n",
    "    data.loc[:, each] = (data[each] - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将数据拆分为训练、测试和验证数据集\n",
    "\n",
    "我们将大约最后 21 天的数据保存为测试数据集，这些数据集会在训练完网络后使用。我们将使用该数据集进行预测，并与实际的骑行人数进行对比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save data for approximately the last 21 days \n",
    "test_data = data[-21*24:]\n",
    "\n",
    "# Now remove the test data from the data set \n",
    "data = data[:-21*24]\n",
    "\n",
    "# Separate the data into features and targets\n",
    "target_fields = ['cnt', 'casual', 'registered']\n",
    "features, targets = data.drop(target_fields, axis=1), data[target_fields]\n",
    "test_features, test_targets = test_data.drop(target_fields, axis=1), test_data[target_fields]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将数据拆分为两个数据集，一个用作训练，一个在网络训练完后用来验证网络。因为数据是有时间序列特性的，所以我们用历史数据进行训练，然后尝试预测未来数据（验证数据集）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hold out the last 60 days or so of the remaining data as a validation set\n",
    "train_features, train_targets = features[:-60*24], targets[:-60*24]\n",
    "val_features, val_targets = features[-60*24:], targets[-60*24:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始构建网络\n",
    "\n",
    "下面你将构建自己的网络。我们已经构建好结构和反向传递部分。你将实现网络的前向传递部分。还需要设置超参数：学习速率、隐藏单元的数量，以及训练传递数量。\n",
    "\n",
    "<img src=\"assets/neural_network.png\" width=300px>\n",
    "\n",
    "该网络有两个层级，一个隐藏层和一个输出层。隐藏层级将使用 S 型函数作为激活函数。输出层只有一个节点，用于递归，节点的输出和节点的输入相同。即激活函数是 $f(x)=x$。这种函数获得输入信号，并生成输出信号，但是会考虑阈值，称为激活函数。我们完成网络的每个层级，并计算每个神经元的输出。一个层级的所有输出变成下一层级神经元的输入。这一流程叫做前向传播（forward propagation）。\n",
    "\n",
    "我们在神经网络中使用权重将信号从输入层传播到输出层。我们还使用权重将错误从输出层传播回网络，以便更新权重。这叫做反向传播（backpropagation）。\n",
    "\n",
    "> **提示**：你需要为反向传播实现计算输出激活函数 ($f(x) = x$) 的导数。如果你不熟悉微积分，其实该函数就等同于等式 $y = x$。该等式的斜率是多少？也就是导数 $f(x)$。\n",
    "\n",
    "\n",
    "你需要完成以下任务：\n",
    "\n",
    "1. 实现 S 型激活函数。将 `__init__` 中的 `self.activation_function`  设为你的 S 型函数。\n",
    "2. 在 `train` 方法中实现前向传递。\n",
    "3. 在 `train` 方法中实现反向传播算法，包括计算输出错误。\n",
    "4. 在 `run` 方法中实现前向传递。\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_input_to_hidden = np.random.normal(0.0, self.input_nodes**-0.5, \n",
    "                                       (self.input_nodes, self.hidden_nodes))\n",
    "\n",
    "        self.weights_hidden_to_output = np.random.normal(0.0, self.hidden_nodes**-0.5, \n",
    "                                       (self.hidden_nodes, self.output_nodes))\n",
    "        self.lr = learning_rate\n",
    "        \n",
    "        #### TODO: Set self.activation_function to your implemented sigmoid function ####\n",
    "        #\n",
    "        # Note: in Python, you can define a function with a lambda expression,\n",
    "        # as shown below.\n",
    "        self.activation_function = lambda x : ( 1 / (1+np.exp(-x)) )  # Replace 0 with your sigmoid calculation.\n",
    "        \n",
    "        ### If the lambda code above is not something you're familiar with,\n",
    "        # You can uncomment out the following three lines and put your \n",
    "        # implementation there instead.\n",
    "        #\n",
    "        #def sigmoid(x):\n",
    "        #    return 0  # Replace 0 with your sigmoid calculation here\n",
    "        #self.activation_function = sigmoid\n",
    "                    \n",
    "    \n",
    "    def train(self, features, targets):\n",
    "        ''' Train the network on batch of features and targets. \n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            \n",
    "            features: 2D array, each row is one data record, each column is a feature\n",
    "            targets: 1D array of target values\n",
    "        \n",
    "        '''\n",
    "        n_records = features.shape[0]\n",
    "        delta_weights_i_h = np.zeros(self.weights_input_to_hidden.shape)\n",
    "        delta_weights_h_o = np.zeros(self.weights_hidden_to_output.shape)\n",
    "        for X, y in zip(features, targets):\n",
    "            #### Implement the forward pass here ####\n",
    "            ### Forward pass ###\n",
    "            # TODO: Hidden layer - Replace these values with your calculations.\n",
    "            hidden_inputs =  np.dot(X, self.weights_input_to_hidden)  # signals into hidden layer\n",
    "            hidden_outputs = self.activation_function(hidden_inputs) # signals from hidden layer\n",
    "\n",
    "            # TODO: Output layer - Replace these values with your calculations.\n",
    "            final_inputs =np.dot(hidden_outputs, self.weights_hidden_to_output) # signals into final output layer\n",
    "            final_outputs = final_inputs # signals from final output layer\n",
    "            \n",
    "            #### Implement the backward pass here ####\n",
    "            ### Backward pass ###\n",
    "\n",
    "            # TODO: Output error - Replace this value with your calculations.\n",
    "            error =  y - final_outputs  # Output layer error is the difference between desired target and actual output.\n",
    "            output_error_term = error\n",
    "            # TODO: Calculate the hidden layer's contribution to the error\n",
    "            hidden_error =output_error_term * self.weights_hidden_to_output\n",
    "            \n",
    "            # TODO: Backpropagated error terms - Replace these values with your calculations.\n",
    "         \n",
    "            hidden_error_term = hidden_error * hidden_outputs[:, None] * (1 - hidden_outputs[:, None])\n",
    "            # Weight step (input to hidden)\n",
    "            delta_weights_i_h +=  (hidden_error_term * X[:, None].T).T\n",
    "            # Weight step (hidden to output)\n",
    "            delta_weights_h_o +=(output_error_term * hidden_outputs[:, None].T).T\n",
    "\n",
    "\n",
    "        # TODO: Update the weights - Replace these values with your calculations.\n",
    "        self.weights_hidden_to_output +=self.lr * delta_weights_h_o / n_records# update hidden-to-output weights with gradient descent step\n",
    "        self.weights_input_to_hidden += self.lr * delta_weights_i_h / n_records# update input-to-hidden weights with gradient descent step\n",
    " \n",
    "    def run(self, features):\n",
    "        ''' Run a forward pass through the network with input features \n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            features: 1D array of feature values\n",
    "        '''\n",
    "        \n",
    "        #### Implement the forward pass here ####\n",
    "        # TODO: Hidden layer - replace these values with the appropriate calculations.\n",
    "        hidden_inputs = np.dot(features, self.weights_input_to_hidden)    # signals into hidden layer\n",
    "        hidden_outputs =self.activation_function(hidden_inputs)    # signals from hidden layer\n",
    "        \n",
    "        # TODO: Output layer - Replace these values with the appropriate calculations.\n",
    "        final_inputs =np.dot(hidden_outputs, self.weights_hidden_to_output)  # signals into final output layer\n",
    "        final_outputs = final_inputs  # signals from final output layer \n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE(y, Y):\n",
    "    return np.mean((y-Y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单元测试\n",
    "\n",
    "运行这些单元测试，检查你的网络实现是否正确。这样可以帮助你确保网络已正确实现，然后再开始训练网络。这些测试必须成功才能通过此项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.011s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=5 errors=0 failures=0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "inputs = np.array([[0.5, -0.2, 0.1]])\n",
    "targets = np.array([[0.4]])\n",
    "test_w_i_h = np.array([[0.1, -0.2],\n",
    "                       [0.4, 0.5],\n",
    "                       [-0.3, 0.2]])\n",
    "test_w_h_o = np.array([[0.3],\n",
    "                       [-0.1]])\n",
    "\n",
    "class TestMethods(unittest.TestCase):\n",
    "    \n",
    "    ##########\n",
    "    # Unit tests for data loading\n",
    "    ##########\n",
    "    \n",
    "    def test_data_path(self):\n",
    "        # Test that file path to dataset has been unaltered\n",
    "        self.assertTrue(data_path.lower() == 'bike-sharing-dataset/hour.csv')\n",
    "        \n",
    "    def test_data_loaded(self):\n",
    "        # Test that data frame loaded\n",
    "        self.assertTrue(isinstance(rides, pd.DataFrame))\n",
    "    \n",
    "    ##########\n",
    "    # Unit tests for network functionality\n",
    "    ##########\n",
    "\n",
    "    def test_activation(self):\n",
    "        network = NeuralNetwork(3, 2, 1, 0.5)\n",
    "        # Test that the activation function is a sigmoid\n",
    "        self.assertTrue(np.all(network.activation_function(0.5) == 1/(1+np.exp(-0.5))))\n",
    "\n",
    "    def test_train(self):\n",
    "        # Test that weights are updated correctly on training\n",
    "        network = NeuralNetwork(3, 2, 1, 0.5)\n",
    "        network.weights_input_to_hidden = test_w_i_h.copy()\n",
    "        network.weights_hidden_to_output = test_w_h_o.copy()\n",
    "        \n",
    "        network.train(inputs, targets)\n",
    "        self.assertTrue(np.allclose(network.weights_hidden_to_output, \n",
    "                                    np.array([[ 0.37275328], \n",
    "                                              [-0.03172939]])))\n",
    "        self.assertTrue(np.allclose(network.weights_input_to_hidden,\n",
    "                                    np.array([[ 0.10562014, -0.20185996], \n",
    "                                              [0.39775194, 0.50074398], \n",
    "                                              [-0.29887597, 0.19962801]])))\n",
    "\n",
    "    def test_run(self):\n",
    "        # Test correctness of run method\n",
    "        network = NeuralNetwork(3, 2, 1, 0.5)\n",
    "        network.weights_input_to_hidden = test_w_i_h.copy()\n",
    "        network.weights_hidden_to_output = test_w_h_o.copy()\n",
    "\n",
    "        self.assertTrue(np.allclose(network.run(inputs), 0.09998924))\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromModule(TestMethods())\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练网络\n",
    "\n",
    "现在你将设置网络的超参数。策略是设置的超参数使训练集上的错误很小但是数据不会过拟合。如果网络训练时间太长，或者有太多的隐藏节点，可能就会过于针对特定训练集，无法泛化到验证数据集。即当训练集的损失降低时，验证集的损失将开始增大。\n",
    "\n",
    "你还将采用随机梯度下降 (SGD) 方法训练网络。对于每次训练，都获取随机样本数据，而不是整个数据集。与普通梯度下降相比，训练次数要更多，但是每次时间更短。这样的话，网络训练效率更高。稍后你将详细了解 SGD。\n",
    "\n",
    "\n",
    "### 选择迭代次数\n",
    "\n",
    "也就是训练网络时从训练数据中抽样的批次数量。迭代次数越多，模型就与数据越拟合。但是，如果迭代次数太多，模型就无法很好地泛化到其他数据，这叫做过拟合。你需要选择一个使训练损失很低并且验证损失保持中等水平的数字。当你开始过拟合时，你会发现训练损失继续下降，但是验证损失开始上升。\n",
    "\n",
    "### 选择学习速率\n",
    "\n",
    "速率可以调整权重更新幅度。如果速率太大，权重就会太大，导致网络无法与数据相拟合。建议从 0.1 开始。如果网络在与数据拟合时遇到问题，尝试降低学习速率。注意，学习速率越低，权重更新的步长就越小，神经网络收敛的时间就越长。\n",
    "\n",
    "\n",
    "### 选择隐藏节点数量\n",
    "\n",
    "隐藏节点越多，模型的预测结果就越准确。尝试不同的隐藏节点的数量，看看对性能有何影响。你可以查看损失字典，寻找网络性能指标。如果隐藏单元的数量太少，那么模型就没有足够的空间进行学习，如果太多，则学习方向就有太多的选择。选择隐藏单元数量的技巧在于找到合适的平衡点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress: 0.0% ... Training loss: 1.084 ... Validation loss: 1.300\r",
      "Progress: 0.0% ... Training loss: 1.120 ... Validation loss: 1.705\r",
      "Progress: 0.0% ... Training loss: 0.979 ... Validation loss: 1.301\r",
      "Progress: 0.1% ... Training loss: 1.076 ... Validation loss: 1.654\r",
      "Progress: 0.1% ... Training loss: 1.258 ... Validation loss: 1.351"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/csh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress: 0.1% ... Training loss: 1.473 ... Validation loss: 2.264\r",
      "Progress: 0.1% ... Training loss: 1.438 ... Validation loss: 1.444\r",
      "Progress: 0.1% ... Training loss: 1.323 ... Validation loss: 2.077\r",
      "Progress: 0.1% ... Training loss: 1.314 ... Validation loss: 1.366\r",
      "Progress: 0.2% ... Training loss: 0.919 ... Validation loss: 1.431\r",
      "Progress: 0.2% ... Training loss: 0.913 ... Validation loss: 1.244\r",
      "Progress: 0.2% ... Training loss: 0.880 ... Validation loss: 1.276\r",
      "Progress: 0.2% ... Training loss: 0.886 ... Validation loss: 1.391\r",
      "Progress: 0.2% ... Training loss: 0.863 ... Validation loss: 1.320\r",
      "Progress: 0.3% ... Training loss: 0.860 ... Validation loss: 1.249\r",
      "Progress: 0.3% ... Training loss: 0.846 ... Validation loss: 1.291\r",
      "Progress: 0.3% ... Training loss: 0.855 ... Validation loss: 1.376\r",
      "Progress: 0.3% ... Training loss: 0.877 ... Validation loss: 1.192\r",
      "Progress: 0.3% ... Training loss: 0.825 ... Validation loss: 1.309\r",
      "Progress: 0.3% ... Training loss: 0.820 ... Validation loss: 1.308\r",
      "Progress: 0.4% ... Training loss: 0.810 ... Validation loss: 1.281\r",
      "Progress: 0.4% ... Training loss: 0.806 ... Validation loss: 1.228\r",
      "Progress: 0.4% ... Training loss: 0.852 ... Validation loss: 1.454\r",
      "Progress: 0.4% ... Training loss: 0.802 ... Validation loss: 1.197\r",
      "Progress: 0.4% ... Training loss: 0.789 ... Validation loss: 1.297\r",
      "Progress: 0.5% ... Training loss: 0.858 ... Validation loss: 1.140\r",
      "Progress: 0.5% ... Training loss: 0.942 ... Validation loss: 1.666\r",
      "Progress: 0.5% ... Training loss: 0.920 ... Validation loss: 1.131\r",
      "Progress: 0.5% ... Training loss: 0.765 ... Validation loss: 1.297\r",
      "Progress: 0.5% ... Training loss: 0.789 ... Validation loss: 1.133\r",
      "Progress: 0.5% ... Training loss: 0.923 ... Validation loss: 1.668\r",
      "Progress: 0.6% ... Training loss: 0.773 ... Validation loss: 1.129\r",
      "Progress: 0.6% ... Training loss: 0.737 ... Validation loss: 1.234\r",
      "Progress: 0.6% ... Training loss: 0.744 ... Validation loss: 1.140\r",
      "Progress: 0.6% ... Training loss: 0.730 ... Validation loss: 1.163\r",
      "Progress: 0.6% ... Training loss: 0.723 ... Validation loss: 1.237\r",
      "Progress: 0.7% ... Training loss: 0.723 ... Validation loss: 1.260\r",
      "Progress: 0.7% ... Training loss: 0.732 ... Validation loss: 1.117\r",
      "Progress: 0.7% ... Training loss: 0.708 ... Validation loss: 1.190\r",
      "Progress: 0.7% ... Training loss: 0.738 ... Validation loss: 1.092\r",
      "Progress: 0.7% ... Training loss: 0.724 ... Validation loss: 1.310\r",
      "Progress: 0.7% ... Training loss: 0.736 ... Validation loss: 1.083\r",
      "Progress: 0.8% ... Training loss: 0.805 ... Validation loss: 1.506\r",
      "Progress: 0.8% ... Training loss: 0.890 ... Validation loss: 1.065\r",
      "Progress: 0.8% ... Training loss: 0.750 ... Validation loss: 1.402\r",
      "Progress: 0.8% ... Training loss: 0.921 ... Validation loss: 1.062\r",
      "Progress: 0.8% ... Training loss: 0.925 ... Validation loss: 1.740\r",
      "Progress: 0.9% ... Training loss: 0.869 ... Validation loss: 1.045\r",
      "Progress: 0.9% ... Training loss: 0.876 ... Validation loss: 1.660\r",
      "Progress: 0.9% ... Training loss: 0.720 ... Validation loss: 1.047\r",
      "Progress: 0.9% ... Training loss: 0.667 ... Validation loss: 1.165\r",
      "Progress: 0.9% ... Training loss: 0.669 ... Validation loss: 1.097\r",
      "Progress: 0.9% ... Training loss: 0.696 ... Validation loss: 1.302\r",
      "Progress: 1.0% ... Training loss: 0.662 ... Validation loss: 1.117\r",
      "Progress: 1.0% ... Training loss: 0.707 ... Validation loss: 1.330\r",
      "Progress: 1.0% ... Training loss: 0.750 ... Validation loss: 1.016\r",
      "Progress: 1.0% ... Training loss: 0.658 ... Validation loss: 1.177\r",
      "Progress: 1.0% ... Training loss: 0.652 ... Validation loss: 1.113\r",
      "Progress: 1.1% ... Training loss: 0.651 ... Validation loss: 1.095\r",
      "Progress: 1.1% ... Training loss: 0.652 ... Validation loss: 1.182\r",
      "Progress: 1.1% ... Training loss: 0.654 ... Validation loss: 1.056\r",
      "Progress: 1.1% ... Training loss: 0.643 ... Validation loss: 1.145\r",
      "Progress: 1.1% ... Training loss: 0.647 ... Validation loss: 1.060\r",
      "Progress: 1.1% ... Training loss: 0.639 ... Validation loss: 1.130\r",
      "Progress: 1.2% ... Training loss: 0.657 ... Validation loss: 1.028\r",
      "Progress: 1.2% ... Training loss: 0.727 ... Validation loss: 1.403\r",
      "Progress: 1.2% ... Training loss: 0.671 ... Validation loss: 1.006\r",
      "Progress: 1.2% ... Training loss: 0.638 ... Validation loss: 1.151\r",
      "Progress: 1.2% ... Training loss: 0.668 ... Validation loss: 0.999\r",
      "Progress: 1.3% ... Training loss: 0.631 ... Validation loss: 1.122\r",
      "Progress: 1.3% ... Training loss: 0.637 ... Validation loss: 1.160\r",
      "Progress: 1.3% ... Training loss: 0.737 ... Validation loss: 0.967\r",
      "Progress: 1.3% ... Training loss: 0.896 ... Validation loss: 1.696\r",
      "Progress: 1.3% ... Training loss: 0.849 ... Validation loss: 0.984\r",
      "Progress: 1.3% ... Training loss: 0.824 ... Validation loss: 1.572\r",
      "Progress: 1.4% ... Training loss: 0.750 ... Validation loss: 0.959\r",
      "Progress: 1.4% ... Training loss: 0.752 ... Validation loss: 1.445\r",
      "Progress: 1.4% ... Training loss: 0.772 ... Validation loss: 0.959\r",
      "Progress: 1.4% ... Training loss: 0.900 ... Validation loss: 1.698\r",
      "Progress: 1.4% ... Training loss: 0.696 ... Validation loss: 0.960\r",
      "Progress: 1.5% ... Training loss: 0.643 ... Validation loss: 1.200\r",
      "Progress: 1.5% ... Training loss: 0.665 ... Validation loss: 0.966\r",
      "Progress: 1.5% ... Training loss: 0.628 ... Validation loss: 1.153\r",
      "Progress: 1.5% ... Training loss: 0.646 ... Validation loss: 1.209\r",
      "Progress: 1.5% ... Training loss: 0.627 ... Validation loss: 0.993\r",
      "Progress: 1.5% ... Training loss: 0.679 ... Validation loss: 1.291\r",
      "Progress: 1.6% ... Training loss: 0.634 ... Validation loss: 0.978\r",
      "Progress: 1.6% ... Training loss: 0.675 ... Validation loss: 1.281\r",
      "Progress: 1.6% ... Training loss: 0.684 ... Validation loss: 0.947\r",
      "Progress: 1.6% ... Training loss: 0.631 ... Validation loss: 1.168\r",
      "Progress: 1.6% ... Training loss: 0.630 ... Validation loss: 0.969\r",
      "Progress: 1.7% ... Training loss: 0.714 ... Validation loss: 1.359\r",
      "Progress: 1.7% ... Training loss: 0.607 ... Validation loss: 1.070\r",
      "Progress: 1.7% ... Training loss: 0.639 ... Validation loss: 0.955\r",
      "Progress: 1.7% ... Training loss: 0.641 ... Validation loss: 1.199\r",
      "Progress: 1.7% ... Training loss: 0.609 ... Validation loss: 0.985\r",
      "Progress: 1.7% ... Training loss: 0.600 ... Validation loss: 1.035\r",
      "Progress: 1.8% ... Training loss: 0.599 ... Validation loss: 1.028\r",
      "Progress: 1.8% ... Training loss: 0.608 ... Validation loss: 0.976\r",
      "Progress: 1.8% ... Training loss: 0.598 ... Validation loss: 1.036\r",
      "Progress: 1.8% ... Training loss: 0.640 ... Validation loss: 1.191\r",
      "Progress: 1.8% ... Training loss: 0.649 ... Validation loss: 0.935\r",
      "Progress: 1.9% ... Training loss: 0.737 ... Validation loss: 1.389\r",
      "Progress: 1.9% ... Training loss: 0.694 ... Validation loss: 0.924\r",
      "Progress: 1.9% ... Training loss: 0.593 ... Validation loss: 1.024\r",
      "Progress: 1.9% ... Training loss: 0.594 ... Validation loss: 1.048\r",
      "Progress: 1.9% ... Training loss: 0.617 ... Validation loss: 0.940\r",
      "Progress: 1.9% ... Training loss: 0.590 ... Validation loss: 0.998\r",
      "Progress: 2.0% ... Training loss: 0.608 ... Validation loss: 1.105\r",
      "Progress: 2.0% ... Training loss: 0.669 ... Validation loss: 0.918\r",
      "Progress: 2.0% ... Training loss: 0.610 ... Validation loss: 1.114\r",
      "Progress: 2.0% ... Training loss: 0.649 ... Validation loss: 0.916\r",
      "Progress: 2.0% ... Training loss: 0.650 ... Validation loss: 1.211\r",
      "Progress: 2.1% ... Training loss: 0.613 ... Validation loss: 0.925\r",
      "Progress: 2.1% ... Training loss: 0.598 ... Validation loss: 1.084\r",
      "Progress: 2.1% ... Training loss: 0.594 ... Validation loss: 0.938\r",
      "Progress: 2.1% ... Training loss: 0.646 ... Validation loss: 1.195\r",
      "Progress: 2.1% ... Training loss: 0.594 ... Validation loss: 0.934\r",
      "Progress: 2.1% ... Training loss: 0.593 ... Validation loss: 1.063\r",
      "Progress: 2.2% ... Training loss: 0.589 ... Validation loss: 0.936\r",
      "Progress: 2.2% ... Training loss: 0.640 ... Validation loss: 1.182\r",
      "Progress: 2.2% ... Training loss: 0.657 ... Validation loss: 0.906\r",
      "Progress: 2.2% ... Training loss: 0.594 ... Validation loss: 1.072\r",
      "Progress: 2.2% ... Training loss: 0.656 ... Validation loss: 0.902\r",
      "Progress: 2.3% ... Training loss: 0.608 ... Validation loss: 1.110\r",
      "Progress: 2.3% ... Training loss: 0.634 ... Validation loss: 0.900\r",
      "Progress: 2.3% ... Training loss: 0.678 ... Validation loss: 1.246\r",
      "Progress: 2.3% ... Training loss: 0.591 ... Validation loss: 0.911\r",
      "Progress: 2.3% ... Training loss: 0.586 ... Validation loss: 1.049\r",
      "Progress: 2.3% ... Training loss: 0.585 ... Validation loss: 1.048\r",
      "Progress: 2.4% ... Training loss: 0.703 ... Validation loss: 0.903\r",
      "Progress: 2.4% ... Training loss: 0.567 ... Validation loss: 0.975\r",
      "Progress: 2.4% ... Training loss: 0.582 ... Validation loss: 0.908\r",
      "Progress: 2.4% ... Training loss: 0.592 ... Validation loss: 0.896\r",
      "Progress: 2.4% ... Training loss: 0.565 ... Validation loss: 0.973\r",
      "Progress: 2.5% ... Training loss: 0.563 ... Validation loss: 0.957\r",
      "Progress: 2.5% ... Training loss: 0.592 ... Validation loss: 1.066\r",
      "Progress: 2.5% ... Training loss: 0.611 ... Validation loss: 0.885\r",
      "Progress: 2.5% ... Training loss: 0.630 ... Validation loss: 1.145\r",
      "Progress: 2.5% ... Training loss: 0.644 ... Validation loss: 0.884\r",
      "Progress: 2.5% ... Training loss: 0.619 ... Validation loss: 1.124\r",
      "Progress: 2.6% ... Training loss: 0.573 ... Validation loss: 0.894\r",
      "Progress: 2.6% ... Training loss: 0.570 ... Validation loss: 1.009\r",
      "Progress: 2.6% ... Training loss: 0.556 ... Validation loss: 0.954\r",
      "Progress: 2.6% ... Training loss: 0.556 ... Validation loss: 0.919\r",
      "Progress: 2.6% ... Training loss: 0.562 ... Validation loss: 0.986\r",
      "Progress: 2.7% ... Training loss: 0.560 ... Validation loss: 0.980\r",
      "Progress: 2.7% ... Training loss: 0.566 ... Validation loss: 0.889\r",
      "Progress: 2.7% ... Training loss: 0.551 ... Validation loss: 0.931\r",
      "Progress: 2.7% ... Training loss: 0.575 ... Validation loss: 0.876\r",
      "Progress: 2.7% ... Training loss: 0.549 ... Validation loss: 0.915\r",
      "Progress: 2.7% ... Training loss: 0.562 ... Validation loss: 0.987\r",
      "Progress: 2.8% ... Training loss: 0.567 ... Validation loss: 0.875\r",
      "Progress: 2.8% ... Training loss: 0.575 ... Validation loss: 1.021\r",
      "Progress: 2.8% ... Training loss: 0.546 ... Validation loss: 0.930\r",
      "Progress: 2.8% ... Training loss: 0.545 ... Validation loss: 0.909\r",
      "Progress: 2.8% ... Training loss: 0.549 ... Validation loss: 0.949\r",
      "Progress: 2.9% ... Training loss: 0.543 ... Validation loss: 0.904\r",
      "Progress: 2.9% ... Training loss: 0.550 ... Validation loss: 0.877\r",
      "Progress: 2.9% ... Training loss: 0.571 ... Validation loss: 1.012\r",
      "Progress: 2.9% ... Training loss: 0.578 ... Validation loss: 0.854\r",
      "Progress: 2.9% ... Training loss: 0.655 ... Validation loss: 1.161\r",
      "Progress: 2.9% ... Training loss: 0.603 ... Validation loss: 0.854\r",
      "Progress: 3.0% ... Training loss: 0.647 ... Validation loss: 1.144\r",
      "Progress: 3.0% ... Training loss: 0.590 ... Validation loss: 0.853\r",
      "Progress: 3.0% ... Training loss: 0.540 ... Validation loss: 0.928\r",
      "Progress: 3.0% ... Training loss: 0.543 ... Validation loss: 0.863\r",
      "Progress: 3.0% ... Training loss: 0.725 ... Validation loss: 1.257\r",
      "Progress: 3.1% ... Training loss: 0.629 ... Validation loss: 0.860\r",
      "Progress: 3.1% ... Training loss: 0.562 ... Validation loss: 0.989\r",
      "Progress: 3.1% ... Training loss: 0.534 ... Validation loss: 0.869\r",
      "Progress: 3.1% ... Training loss: 0.560 ... Validation loss: 0.986\r",
      "Progress: 3.1% ... Training loss: 0.551 ... Validation loss: 0.849\r",
      "Progress: 3.1% ... Training loss: 0.583 ... Validation loss: 1.030\r",
      "Progress: 3.2% ... Training loss: 0.577 ... Validation loss: 0.845\r",
      "Progress: 3.2% ... Training loss: 0.562 ... Validation loss: 0.990\r",
      "Progress: 3.2% ... Training loss: 0.560 ... Validation loss: 0.842\r",
      "Progress: 3.2% ... Training loss: 0.529 ... Validation loss: 0.907\r",
      "Progress: 3.2% ... Training loss: 0.539 ... Validation loss: 0.843\r",
      "Progress: 3.3% ... Training loss: 0.550 ... Validation loss: 0.958\r",
      "Progress: 3.3% ... Training loss: 0.598 ... Validation loss: 0.840\r",
      "Progress: 3.3% ... Training loss: 0.554 ... Validation loss: 0.966\r",
      "Progress: 3.3% ... Training loss: 0.567 ... Validation loss: 0.831\r",
      "Progress: 3.3% ... Training loss: 0.638 ... Validation loss: 1.111\r",
      "Progress: 3.3% ... Training loss: 0.624 ... Validation loss: 0.850\r",
      "Progress: 3.4% ... Training loss: 0.563 ... Validation loss: 0.983\r",
      "Progress: 3.4% ... Training loss: 0.530 ... Validation loss: 0.836\r",
      "Progress: 3.4% ... Training loss: 0.528 ... Validation loss: 0.909\r",
      "Progress: 3.4% ... Training loss: 0.516 ... Validation loss: 0.870\r",
      "Progress: 3.4% ... Training loss: 0.515 ... Validation loss: 0.855\r",
      "Progress: 3.5% ... Training loss: 0.521 ... Validation loss: 0.836\r",
      "Progress: 3.5% ... Training loss: 0.521 ... Validation loss: 0.893\r",
      "Progress: 3.5% ... Training loss: 0.522 ... Validation loss: 0.832\r",
      "Progress: 3.5% ... Training loss: 0.537 ... Validation loss: 0.926\r",
      "Progress: 3.5% ... Training loss: 0.521 ... Validation loss: 0.829\r",
      "Progress: 3.5% ... Training loss: 0.562 ... Validation loss: 0.967\r",
      "Progress: 3.6% ... Training loss: 0.574 ... Validation loss: 0.836\r",
      "Progress: 3.6% ... Training loss: 0.578 ... Validation loss: 0.989\r",
      "Progress: 3.6% ... Training loss: 0.557 ... Validation loss: 0.828\r",
      "Progress: 3.6% ... Training loss: 0.638 ... Validation loss: 1.072\r",
      "Progress: 3.6% ... Training loss: 0.625 ... Validation loss: 0.863\r",
      "Progress: 3.7% ... Training loss: 0.620 ... Validation loss: 1.047\r",
      "Progress: 3.7% ... Training loss: 0.557 ... Validation loss: 0.829\r",
      "Progress: 3.7% ... Training loss: 0.551 ... Validation loss: 0.940\r",
      "Progress: 3.7% ... Training loss: 0.574 ... Validation loss: 0.836\r",
      "Progress: 3.7% ... Training loss: 0.538 ... Validation loss: 0.920\r",
      "Progress: 3.7% ... Training loss: 0.528 ... Validation loss: 0.815\r",
      "Progress: 3.8% ... Training loss: 0.498 ... Validation loss: 0.826\r",
      "Progress: 3.8% ... Training loss: 0.504 ... Validation loss: 0.854\r",
      "Progress: 3.8% ... Training loss: 0.537 ... Validation loss: 0.814\r",
      "Progress: 3.8% ... Training loss: 0.576 ... Validation loss: 0.970\r",
      "Progress: 3.8% ... Training loss: 0.572 ... Validation loss: 0.828\r",
      "Progress: 3.9% ... Training loss: 0.558 ... Validation loss: 0.943\r",
      "Progress: 3.9% ... Training loss: 0.586 ... Validation loss: 0.836\r",
      "Progress: 3.9% ... Training loss: 0.596 ... Validation loss: 0.993\r",
      "Progress: 3.9% ... Training loss: 0.551 ... Validation loss: 0.818\r",
      "Progress: 3.9% ... Training loss: 0.510 ... Validation loss: 0.864\r",
      "Progress: 3.9% ... Training loss: 0.505 ... Validation loss: 0.800\r",
      "Progress: 4.0% ... Training loss: 0.498 ... Validation loss: 0.840\r",
      "Progress: 4.0% ... Training loss: 0.489 ... Validation loss: 0.805\r",
      "Progress: 4.0% ... Training loss: 0.487 ... Validation loss: 0.808\r",
      "Progress: 4.0% ... Training loss: 0.496 ... Validation loss: 0.837\r",
      "Progress: 4.0% ... Training loss: 0.494 ... Validation loss: 0.796\r",
      "Progress: 4.1% ... Training loss: 0.492 ... Validation loss: 0.827\r",
      "Progress: 4.1% ... Training loss: 0.486 ... Validation loss: 0.813\r",
      "Progress: 4.1% ... Training loss: 0.483 ... Validation loss: 0.804\r",
      "Progress: 4.1% ... Training loss: 0.486 ... Validation loss: 0.815\r",
      "Progress: 4.1% ... Training loss: 0.498 ... Validation loss: 0.791\r",
      "Progress: 4.1% ... Training loss: 0.481 ... Validation loss: 0.791\r",
      "Progress: 4.2% ... Training loss: 0.482 ... Validation loss: 0.805\r",
      "Progress: 4.2% ... Training loss: 0.482 ... Validation loss: 0.807\r",
      "Progress: 4.2% ... Training loss: 0.479 ... Validation loss: 0.784\r",
      "Progress: 4.2% ... Training loss: 0.481 ... Validation loss: 0.780\r",
      "Progress: 4.2% ... Training loss: 0.504 ... Validation loss: 0.842\r",
      "Progress: 4.3% ... Training loss: 0.500 ... Validation loss: 0.780\r",
      "Progress: 4.3% ... Training loss: 0.563 ... Validation loss: 0.921\r",
      "Progress: 4.3% ... Training loss: 0.507 ... Validation loss: 0.783\r",
      "Progress: 4.3% ... Training loss: 0.501 ... Validation loss: 0.837\r",
      "Progress: 4.3% ... Training loss: 0.492 ... Validation loss: 0.773\r",
      "Progress: 4.3% ... Training loss: 0.475 ... Validation loss: 0.788\r",
      "Progress: 4.4% ... Training loss: 0.471 ... Validation loss: 0.769\r",
      "Progress: 4.4% ... Training loss: 0.469 ... Validation loss: 0.770\r",
      "Progress: 4.4% ... Training loss: 0.470 ... Validation loss: 0.778\r",
      "Progress: 4.4% ... Training loss: 0.475 ... Validation loss: 0.762\r",
      "Progress: 4.4% ... Training loss: 0.467 ... Validation loss: 0.771\r",
      "Progress: 4.5% ... Training loss: 0.466 ... Validation loss: 0.770\r",
      "Progress: 4.5% ... Training loss: 0.466 ... Validation loss: 0.771\r",
      "Progress: 4.5% ... Training loss: 0.465 ... Validation loss: 0.759\r",
      "Progress: 4.5% ... Training loss: 0.510 ... Validation loss: 0.778\r",
      "Progress: 4.5% ... Training loss: 0.462 ... Validation loss: 0.759\r",
      "Progress: 4.5% ... Training loss: 0.462 ... Validation loss: 0.759\r",
      "Progress: 4.6% ... Training loss: 0.486 ... Validation loss: 0.803\r",
      "Progress: 4.6% ... Training loss: 0.481 ... Validation loss: 0.759\r",
      "Progress: 4.6% ... Training loss: 0.462 ... Validation loss: 0.765\r",
      "Progress: 4.6% ... Training loss: 0.462 ... Validation loss: 0.769\r",
      "Progress: 4.6% ... Training loss: 0.458 ... Validation loss: 0.756\r",
      "Progress: 4.7% ... Training loss: 0.459 ... Validation loss: 0.761\r",
      "Progress: 4.7% ... Training loss: 0.456 ... Validation loss: 0.752\r",
      "Progress: 4.7% ... Training loss: 0.458 ... Validation loss: 0.748\r",
      "Progress: 4.7% ... Training loss: 0.486 ... Validation loss: 0.799\r",
      "Progress: 4.7% ... Training loss: 0.454 ... Validation loss: 0.747\r",
      "Progress: 4.7% ... Training loss: 0.481 ... Validation loss: 0.793\r",
      "Progress: 4.8% ... Training loss: 0.462 ... Validation loss: 0.748\r",
      "Progress: 4.8% ... Training loss: 0.498 ... Validation loss: 0.815\r",
      "Progress: 4.8% ... Training loss: 0.451 ... Validation loss: 0.745\r",
      "Progress: 4.8% ... Training loss: 0.469 ... Validation loss: 0.778\r",
      "Progress: 4.8% ... Training loss: 0.525 ... Validation loss: 0.792\r",
      "Progress: 4.9% ... Training loss: 0.500 ... Validation loss: 0.816\r",
      "Progress: 4.9% ... Training loss: 0.491 ... Validation loss: 0.769\r",
      "Progress: 4.9% ... Training loss: 0.554 ... Validation loss: 0.873\r",
      "Progress: 4.9% ... Training loss: 0.617 ... Validation loss: 0.870\r",
      "Progress: 4.9% ... Training loss: 0.565 ... Validation loss: 0.881\r",
      "Progress: 4.9% ... Training loss: 0.447 ... Validation loss: 0.733\r",
      "Progress: 5.0% ... Training loss: 0.446 ... Validation loss: 0.734\r",
      "Progress: 5.0% ... Training loss: 0.465 ... Validation loss: 0.766\r",
      "Progress: 5.0% ... Training loss: 0.442 ... Validation loss: 0.734\r",
      "Progress: 5.0% ... Training loss: 0.441 ... Validation loss: 0.730\r",
      "Progress: 5.0% ... Training loss: 0.449 ... Validation loss: 0.733\r",
      "Progress: 5.1% ... Training loss: 0.459 ... Validation loss: 0.755\r",
      "Progress: 5.1% ... Training loss: 0.496 ... Validation loss: 0.774\r",
      "Progress: 5.1% ... Training loss: 0.456 ... Validation loss: 0.749\r",
      "Progress: 5.1% ... Training loss: 0.437 ... Validation loss: 0.725\r",
      "Progress: 5.1% ... Training loss: 0.463 ... Validation loss: 0.737\r",
      "Progress: 5.1% ... Training loss: 0.617 ... Validation loss: 0.922\r",
      "Progress: 5.2% ... Training loss: 0.626 ... Validation loss: 0.887\r",
      "Progress: 5.2% ... Training loss: 0.716 ... Validation loss: 1.018\r",
      "Progress: 5.2% ... Training loss: 0.663 ... Validation loss: 0.922\r",
      "Progress: 5.2% ... Training loss: 0.617 ... Validation loss: 0.916\r",
      "Progress: 5.2% ... Training loss: 0.695 ... Validation loss: 0.949\r",
      "Progress: 5.3% ... Training loss: 0.782 ... Validation loss: 1.073\r",
      "Progress: 5.3% ... Training loss: 0.716 ... Validation loss: 0.983\r",
      "Progress: 5.3% ... Training loss: 0.528 ... Validation loss: 0.812\r",
      "Progress: 5.3% ... Training loss: 0.587 ... Validation loss: 0.856\r",
      "Progress: 5.3% ... Training loss: 0.614 ... Validation loss: 0.891\r",
      "Progress: 5.3% ... Training loss: 0.589 ... Validation loss: 0.861\r",
      "Progress: 5.4% ... Training loss: 0.642 ... Validation loss: 0.916\r",
      "Progress: 5.4% ... Training loss: 0.830 ... Validation loss: 1.097\r",
      "Progress: 5.4% ... Training loss: 1.029 ... Validation loss: 1.293\r",
      "Progress: 5.4% ... Training loss: 0.757 ... Validation loss: 1.021\r",
      "Progress: 5.4% ... Training loss: 0.481 ... Validation loss: 0.755\r",
      "Progress: 5.5% ... Training loss: 0.445 ... Validation loss: 0.717\r",
      "Progress: 5.5% ... Training loss: 0.440 ... Validation loss: 0.715\r",
      "Progress: 5.5% ... Training loss: 0.429 ... Validation loss: 0.703\r",
      "Progress: 5.5% ... Training loss: 0.449 ... Validation loss: 0.721\r",
      "Progress: 5.5% ... Training loss: 0.450 ... Validation loss: 0.723\r",
      "Progress: 5.5% ... Training loss: 0.470 ... Validation loss: 0.742\r",
      "Progress: 5.6% ... Training loss: 0.436 ... Validation loss: 0.709\r",
      "Progress: 5.6% ... Training loss: 0.441 ... Validation loss: 0.712\r",
      "Progress: 5.6% ... Training loss: 0.426 ... Validation loss: 0.693\r",
      "Progress: 5.6% ... Training loss: 0.429 ... Validation loss: 0.699\r",
      "Progress: 5.6% ... Training loss: 0.434 ... Validation loss: 0.695\r",
      "Progress: 5.7% ... Training loss: 0.420 ... Validation loss: 0.687\r",
      "Progress: 5.7% ... Training loss: 0.426 ... Validation loss: 0.688\r",
      "Progress: 5.7% ... Training loss: 0.416 ... Validation loss: 0.680\r",
      "Progress: 5.7% ... Training loss: 0.416 ... Validation loss: 0.682\r",
      "Progress: 5.7% ... Training loss: 0.413 ... Validation loss: 0.678\r",
      "Progress: 5.7% ... Training loss: 0.421 ... Validation loss: 0.682\r",
      "Progress: 5.8% ... Training loss: 0.420 ... Validation loss: 0.685\r",
      "Progress: 5.8% ... Training loss: 0.418 ... Validation loss: 0.682\r",
      "Progress: 5.8% ... Training loss: 0.460 ... Validation loss: 0.711\r",
      "Progress: 5.8% ... Training loss: 0.491 ... Validation loss: 0.756\r",
      "Progress: 5.8% ... Training loss: 0.421 ... Validation loss: 0.677\r",
      "Progress: 5.9% ... Training loss: 0.449 ... Validation loss: 0.716\r",
      "Progress: 5.9% ... Training loss: 0.444 ... Validation loss: 0.694\r",
      "Progress: 5.9% ... Training loss: 0.514 ... Validation loss: 0.784\r",
      "Progress: 5.9% ... Training loss: 0.535 ... Validation loss: 0.778\r",
      "Progress: 5.9% ... Training loss: 0.674 ... Validation loss: 0.950\r",
      "Progress: 5.9% ... Training loss: 0.703 ... Validation loss: 0.938\r",
      "Progress: 6.0% ... Training loss: 0.654 ... Validation loss: 0.930\r",
      "Progress: 6.0% ... Training loss: 0.794 ... Validation loss: 1.027\r",
      "Progress: 6.0% ... Training loss: 0.712 ... Validation loss: 0.986\r",
      "Progress: 6.0% ... Training loss: 0.543 ... Validation loss: 0.791\r",
      "Progress: 6.0% ... Training loss: 0.502 ... Validation loss: 0.770\r",
      "Progress: 6.1% ... Training loss: 0.704 ... Validation loss: 0.936\r",
      "Progress: 6.1% ... Training loss: 0.629 ... Validation loss: 0.899\r",
      "Progress: 6.1% ... Training loss: 0.504 ... Validation loss: 0.746\r",
      "Progress: 6.1% ... Training loss: 0.447 ... Validation loss: 0.708\r",
      "Progress: 6.1% ... Training loss: 0.421 ... Validation loss: 0.671\r",
      "Progress: 6.1% ... Training loss: 0.398 ... Validation loss: 0.654\r",
      "Progress: 6.2% ... Training loss: 0.398 ... Validation loss: 0.650\r",
      "Progress: 6.2% ... Training loss: 0.435 ... Validation loss: 0.692\r",
      "Progress: 6.2% ... Training loss: 0.397 ... Validation loss: 0.649\r",
      "Progress: 6.2% ... Training loss: 0.453 ... Validation loss: 0.711\r",
      "Progress: 6.2% ... Training loss: 0.502 ... Validation loss: 0.738\r",
      "Progress: 6.3% ... Training loss: 0.490 ... Validation loss: 0.750\r",
      "Progress: 6.3% ... Training loss: 0.425 ... Validation loss: 0.671\r",
      "Progress: 6.3% ... Training loss: 0.393 ... Validation loss: 0.644\r",
      "Progress: 6.3% ... Training loss: 0.440 ... Validation loss: 0.680\r",
      "Progress: 6.3% ... Training loss: 0.400 ... Validation loss: 0.650\r",
      "Progress: 6.3% ... Training loss: 0.498 ... Validation loss: 0.728\r",
      "Progress: 6.4% ... Training loss: 0.500 ... Validation loss: 0.757\r",
      "Progress: 6.4% ... Training loss: 0.413 ... Validation loss: 0.657\r",
      "Progress: 6.4% ... Training loss: 0.411 ... Validation loss: 0.664\r",
      "Progress: 6.4% ... Training loss: 0.431 ... Validation loss: 0.672\r",
      "Progress: 6.4% ... Training loss: 0.417 ... Validation loss: 0.668\r",
      "Progress: 6.5% ... Training loss: 0.391 ... Validation loss: 0.636\r",
      "Progress: 6.5% ... Training loss: 0.392 ... Validation loss: 0.639\r",
      "Progress: 6.5% ... Training loss: 0.394 ... Validation loss: 0.638\r",
      "Progress: 6.5% ... Training loss: 0.394 ... Validation loss: 0.642\r",
      "Progress: 6.5% ... Training loss: 0.385 ... Validation loss: 0.633\r",
      "Progress: 6.5% ... Training loss: 0.403 ... Validation loss: 0.651\r",
      "Progress: 6.6% ... Training loss: 0.405 ... Validation loss: 0.657\r",
      "Progress: 6.6% ... Training loss: 0.384 ... Validation loss: 0.635\r",
      "Progress: 6.6% ... Training loss: 0.395 ... Validation loss: 0.642\r",
      "Progress: 6.6% ... Training loss: 0.384 ... Validation loss: 0.634\r",
      "Progress: 6.6% ... Training loss: 0.425 ... Validation loss: 0.671\r",
      "Progress: 6.7% ... Training loss: 0.428 ... Validation loss: 0.682\r",
      "Progress: 6.7% ... Training loss: 0.491 ... Validation loss: 0.732\r",
      "Progress: 6.7% ... Training loss: 0.613 ... Validation loss: 0.864\r",
      "Progress: 6.7% ... Training loss: 0.501 ... Validation loss: 0.740\r",
      "Progress: 6.7% ... Training loss: 0.476 ... Validation loss: 0.735\r",
      "Progress: 6.7% ... Training loss: 0.432 ... Validation loss: 0.676\r",
      "Progress: 6.8% ... Training loss: 0.381 ... Validation loss: 0.631\r",
      "Progress: 6.8% ... Training loss: 0.393 ... Validation loss: 0.641\r",
      "Progress: 6.8% ... Training loss: 0.402 ... Validation loss: 0.651\r",
      "Progress: 6.8% ... Training loss: 0.377 ... Validation loss: 0.625\r",
      "Progress: 6.8% ... Training loss: 0.399 ... Validation loss: 0.644\r",
      "Progress: 6.9% ... Training loss: 0.435 ... Validation loss: 0.679\r",
      "Progress: 6.9% ... Training loss: 0.443 ... Validation loss: 0.685\r",
      "Progress: 6.9% ... Training loss: 0.378 ... Validation loss: 0.621\r",
      "Progress: 6.9% ... Training loss: 0.391 ... Validation loss: 0.635\r",
      "Progress: 6.9% ... Training loss: 0.383 ... Validation loss: 0.626\r",
      "Progress: 6.9% ... Training loss: 0.436 ... Validation loss: 0.682\r",
      "Progress: 7.0% ... Training loss: 0.374 ... Validation loss: 0.619\r",
      "Progress: 7.0% ... Training loss: 0.372 ... Validation loss: 0.617\r",
      "Progress: 7.0% ... Training loss: 0.429 ... Validation loss: 0.673\r",
      "Progress: 7.0% ... Training loss: 0.392 ... Validation loss: 0.636\r",
      "Progress: 7.0% ... Training loss: 0.382 ... Validation loss: 0.627\r",
      "Progress: 7.1% ... Training loss: 0.407 ... Validation loss: 0.651\r",
      "Progress: 7.1% ... Training loss: 0.422 ... Validation loss: 0.663\r",
      "Progress: 7.1% ... Training loss: 0.386 ... Validation loss: 0.630\r",
      "Progress: 7.1% ... Training loss: 0.404 ... Validation loss: 0.648\r",
      "Progress: 7.1% ... Training loss: 0.467 ... Validation loss: 0.705\r",
      "Progress: 7.1% ... Training loss: 0.566 ... Validation loss: 0.806\r",
      "Progress: 7.2% ... Training loss: 0.539 ... Validation loss: 0.774\r",
      "Progress: 7.2% ... Training loss: 0.496 ... Validation loss: 0.732\r",
      "Progress: 7.2% ... Training loss: 0.475 ... Validation loss: 0.717\r",
      "Progress: 7.2% ... Training loss: 0.382 ... Validation loss: 0.620\r",
      "Progress: 7.2% ... Training loss: 0.370 ... Validation loss: 0.607\r",
      "Progress: 7.3% ... Training loss: 0.401 ... Validation loss: 0.638\r",
      "Progress: 7.3% ... Training loss: 0.454 ... Validation loss: 0.685\r",
      "Progress: 7.3% ... Training loss: 0.497 ... Validation loss: 0.732\r",
      "Progress: 7.3% ... Training loss: 0.566 ... Validation loss: 0.788\r",
      "Progress: 7.3% ... Training loss: 0.450 ... Validation loss: 0.683\r",
      "Progress: 7.3% ... Training loss: 0.368 ... Validation loss: 0.601\r",
      "Progress: 7.4% ... Training loss: 0.378 ... Validation loss: 0.606\r",
      "Progress: 7.4% ... Training loss: 0.376 ... Validation loss: 0.609\r",
      "Progress: 7.4% ... Training loss: 0.403 ... Validation loss: 0.626\r",
      "Progress: 7.4% ... Training loss: 0.377 ... Validation loss: 0.610\r",
      "Progress: 7.4% ... Training loss: 0.370 ... Validation loss: 0.598\r",
      "Progress: 7.5% ... Training loss: 0.372 ... Validation loss: 0.602\r",
      "Progress: 7.5% ... Training loss: 0.363 ... Validation loss: 0.593\r",
      "Progress: 7.5% ... Training loss: 0.374 ... Validation loss: 0.598\r",
      "Progress: 7.5% ... Training loss: 0.398 ... Validation loss: 0.630\r",
      "Progress: 7.5% ... Training loss: 0.391 ... Validation loss: 0.613\r",
      "Progress: 7.5% ... Training loss: 0.421 ... Validation loss: 0.652\r",
      "Progress: 7.6% ... Training loss: 0.392 ... Validation loss: 0.611\r",
      "Progress: 7.6% ... Training loss: 0.381 ... Validation loss: 0.611\r",
      "Progress: 7.6% ... Training loss: 0.362 ... Validation loss: 0.588\r",
      "Progress: 7.6% ... Training loss: 0.369 ... Validation loss: 0.592\r",
      "Progress: 7.6% ... Training loss: 0.355 ... Validation loss: 0.582\r",
      "Progress: 7.7% ... Training loss: 0.366 ... Validation loss: 0.597\r",
      "Progress: 7.7% ... Training loss: 0.388 ... Validation loss: 0.604\r",
      "Progress: 7.7% ... Training loss: 0.406 ... Validation loss: 0.638\r",
      "Progress: 7.7% ... Training loss: 0.355 ... Validation loss: 0.580\r",
      "Progress: 7.7% ... Training loss: 0.355 ... Validation loss: 0.580\r",
      "Progress: 7.7% ... Training loss: 0.353 ... Validation loss: 0.581\r",
      "Progress: 7.8% ... Training loss: 0.364 ... Validation loss: 0.586\r",
      "Progress: 7.8% ... Training loss: 0.352 ... Validation loss: 0.575\r",
      "Progress: 7.8% ... Training loss: 0.353 ... Validation loss: 0.574\r",
      "Progress: 7.8% ... Training loss: 0.375 ... Validation loss: 0.591\r",
      "Progress: 7.8% ... Training loss: 0.382 ... Validation loss: 0.606\r",
      "Progress: 7.9% ... Training loss: 0.358 ... Validation loss: 0.580\r",
      "Progress: 7.9% ... Training loss: 0.404 ... Validation loss: 0.629\r",
      "Progress: 7.9% ... Training loss: 0.376 ... Validation loss: 0.602\r",
      "Progress: 7.9% ... Training loss: 0.355 ... Validation loss: 0.580\r",
      "Progress: 7.9% ... Training loss: 0.349 ... Validation loss: 0.573\r",
      "Progress: 7.9% ... Training loss: 0.353 ... Validation loss: 0.576\r",
      "Progress: 8.0% ... Training loss: 0.357 ... Validation loss: 0.581\r",
      "Progress: 8.0% ... Training loss: 0.351 ... Validation loss: 0.575\r",
      "Progress: 8.0% ... Training loss: 0.358 ... Validation loss: 0.582\r",
      "Progress: 8.0% ... Training loss: 0.352 ... Validation loss: 0.576\r",
      "Progress: 8.0% ... Training loss: 0.371 ... Validation loss: 0.598\r",
      "Progress: 8.1% ... Training loss: 0.388 ... Validation loss: 0.612\r",
      "Progress: 8.1% ... Training loss: 0.460 ... Validation loss: 0.686\r",
      "Progress: 8.1% ... Training loss: 0.459 ... Validation loss: 0.685\r",
      "Progress: 8.1% ... Training loss: 0.395 ... Validation loss: 0.616\r",
      "Progress: 8.1% ... Training loss: 0.386 ... Validation loss: 0.611\r",
      "Progress: 8.1% ... Training loss: 0.387 ... Validation loss: 0.610\r",
      "Progress: 8.2% ... Training loss: 0.367 ... Validation loss: 0.589\r",
      "Progress: 8.2% ... Training loss: 0.402 ... Validation loss: 0.624\r",
      "Progress: 8.2% ... Training loss: 0.412 ... Validation loss: 0.634\r",
      "Progress: 8.2% ... Training loss: 0.406 ... Validation loss: 0.630\r",
      "Progress: 8.2% ... Training loss: 0.380 ... Validation loss: 0.602\r",
      "Progress: 8.3% ... Training loss: 0.345 ... Validation loss: 0.567\r",
      "Progress: 8.3% ... Training loss: 0.346 ... Validation loss: 0.565\r",
      "Progress: 8.3% ... Training loss: 0.343 ... Validation loss: 0.564\r",
      "Progress: 8.3% ... Training loss: 0.376 ... Validation loss: 0.593\r",
      "Progress: 8.3% ... Training loss: 0.349 ... Validation loss: 0.569\r",
      "Progress: 8.3% ... Training loss: 0.343 ... Validation loss: 0.563\r",
      "Progress: 8.4% ... Training loss: 0.369 ... Validation loss: 0.590\r",
      "Progress: 8.4% ... Training loss: 0.342 ... Validation loss: 0.563\r",
      "Progress: 8.4% ... Training loss: 0.342 ... Validation loss: 0.563\r",
      "Progress: 8.4% ... Training loss: 0.343 ... Validation loss: 0.563\r",
      "Progress: 8.4% ... Training loss: 0.343 ... Validation loss: 0.561\r",
      "Progress: 8.5% ... Training loss: 0.343 ... Validation loss: 0.564\r",
      "Progress: 8.5% ... Training loss: 0.370 ... Validation loss: 0.591\r",
      "Progress: 8.5% ... Training loss: 0.359 ... Validation loss: 0.581\r",
      "Progress: 8.5% ... Training loss: 0.351 ... Validation loss: 0.570\r",
      "Progress: 8.5% ... Training loss: 0.353 ... Validation loss: 0.574\r",
      "Progress: 8.5% ... Training loss: 0.381 ... Validation loss: 0.597\r",
      "Progress: 8.6% ... Training loss: 0.501 ... Validation loss: 0.721\r",
      "Progress: 8.6% ... Training loss: 0.559 ... Validation loss: 0.762\r",
      "Progress: 8.6% ... Training loss: 0.441 ... Validation loss: 0.664\r",
      "Progress: 8.6% ... Training loss: 0.410 ... Validation loss: 0.622\r",
      "Progress: 8.6% ... Training loss: 0.416 ... Validation loss: 0.638\r",
      "Progress: 8.7% ... Training loss: 0.351 ... Validation loss: 0.568\r",
      "Progress: 8.7% ... Training loss: 0.339 ... Validation loss: 0.556\r",
      "Progress: 8.7% ... Training loss: 0.347 ... Validation loss: 0.568\r",
      "Progress: 8.7% ... Training loss: 0.351 ... Validation loss: 0.564\r",
      "Progress: 8.7% ... Training loss: 0.376 ... Validation loss: 0.600\r",
      "Progress: 8.7% ... Training loss: 0.374 ... Validation loss: 0.585\r",
      "Progress: 8.8% ... Training loss: 0.349 ... Validation loss: 0.566\r",
      "Progress: 8.8% ... Training loss: 0.356 ... Validation loss: 0.572\r",
      "Progress: 8.8% ... Training loss: 0.341 ... Validation loss: 0.556\r",
      "Progress: 8.8% ... Training loss: 0.335 ... Validation loss: 0.551\r",
      "Progress: 8.8% ... Training loss: 0.336 ... Validation loss: 0.551\r",
      "Progress: 8.9% ... Training loss: 0.351 ... Validation loss: 0.565\r",
      "Progress: 8.9% ... Training loss: 0.368 ... Validation loss: 0.584\r",
      "Progress: 8.9% ... Training loss: 0.342 ... Validation loss: 0.557\r",
      "Progress: 8.9% ... Training loss: 0.335 ... Validation loss: 0.550\r",
      "Progress: 8.9% ... Training loss: 0.336 ... Validation loss: 0.552\r",
      "Progress: 8.9% ... Training loss: 0.335 ... Validation loss: 0.552\r",
      "Progress: 9.0% ... Training loss: 0.359 ... Validation loss: 0.575\r",
      "Progress: 9.0% ... Training loss: 0.336 ... Validation loss: 0.549\r",
      "Progress: 9.0% ... Training loss: 0.333 ... Validation loss: 0.546\r",
      "Progress: 9.0% ... Training loss: 0.373 ... Validation loss: 0.583\r",
      "Progress: 9.0% ... Training loss: 0.365 ... Validation loss: 0.573\r",
      "Progress: 9.1% ... Training loss: 0.397 ... Validation loss: 0.604\r",
      "Progress: 9.1% ... Training loss: 0.347 ... Validation loss: 0.558\r",
      "Progress: 9.1% ... Training loss: 0.344 ... Validation loss: 0.555\r",
      "Progress: 9.1% ... Training loss: 0.332 ... Validation loss: 0.542\r",
      "Progress: 9.1% ... Training loss: 0.332 ... Validation loss: 0.541\r",
      "Progress: 9.1% ... Training loss: 0.335 ... Validation loss: 0.542\r",
      "Progress: 9.2% ... Training loss: 0.332 ... Validation loss: 0.542\r",
      "Progress: 9.2% ... Training loss: 0.332 ... Validation loss: 0.539\r",
      "Progress: 9.2% ... Training loss: 0.342 ... Validation loss: 0.547\r",
      "Progress: 9.2% ... Training loss: 0.330 ... Validation loss: 0.534\r",
      "Progress: 9.2% ... Training loss: 0.330 ... Validation loss: 0.535\r",
      "Progress: 9.3% ... Training loss: 0.336 ... Validation loss: 0.535\r",
      "Progress: 9.3% ... Training loss: 0.332 ... Validation loss: 0.534\r",
      "Progress: 9.3% ... Training loss: 0.351 ... Validation loss: 0.546\r",
      "Progress: 9.3% ... Training loss: 0.344 ... Validation loss: 0.548\r",
      "Progress: 9.3% ... Training loss: 0.328 ... Validation loss: 0.532\r",
      "Progress: 9.3% ... Training loss: 0.330 ... Validation loss: 0.532\r",
      "Progress: 9.4% ... Training loss: 0.373 ... Validation loss: 0.578\r",
      "Progress: 9.4% ... Training loss: 0.356 ... Validation loss: 0.556\r",
      "Progress: 9.4% ... Training loss: 0.366 ... Validation loss: 0.569\r",
      "Progress: 9.4% ... Training loss: 0.364 ... Validation loss: 0.561\r",
      "Progress: 9.4% ... Training loss: 0.344 ... Validation loss: 0.549\r",
      "Progress: 9.5% ... Training loss: 0.340 ... Validation loss: 0.541\r",
      "Progress: 9.5% ... Training loss: 0.351 ... Validation loss: 0.557\r",
      "Progress: 9.5% ... Training loss: 0.361 ... Validation loss: 0.555\r",
      "Progress: 9.5% ... Training loss: 0.340 ... Validation loss: 0.544\r",
      "Progress: 9.5% ... Training loss: 0.343 ... Validation loss: 0.539\r",
      "Progress: 9.5% ... Training loss: 0.342 ... Validation loss: 0.547\r",
      "Progress: 9.6% ... Training loss: 0.327 ... Validation loss: 0.526\r",
      "Progress: 9.6% ... Training loss: 0.327 ... Validation loss: 0.531\r",
      "Progress: 9.6% ... Training loss: 0.331 ... Validation loss: 0.534\r",
      "Progress: 9.6% ... Training loss: 0.328 ... Validation loss: 0.530\r",
      "Progress: 9.6% ... Training loss: 0.380 ... Validation loss: 0.569\r",
      "Progress: 9.7% ... Training loss: 0.458 ... Validation loss: 0.669\r",
      "Progress: 9.7% ... Training loss: 0.448 ... Validation loss: 0.634\r",
      "Progress: 9.7% ... Training loss: 0.451 ... Validation loss: 0.657\r",
      "Progress: 9.7% ... Training loss: 0.420 ... Validation loss: 0.611\r",
      "Progress: 9.7% ... Training loss: 0.375 ... Validation loss: 0.580\r",
      "Progress: 9.7% ... Training loss: 0.363 ... Validation loss: 0.551\r",
      "Progress: 9.8% ... Training loss: 0.355 ... Validation loss: 0.561\r",
      "Progress: 9.8% ... Training loss: 0.329 ... Validation loss: 0.524\r",
      "Progress: 9.8% ... Training loss: 0.327 ... Validation loss: 0.528\r",
      "Progress: 9.8% ... Training loss: 0.325 ... Validation loss: 0.522\r",
      "Progress: 9.8% ... Training loss: 0.327 ... Validation loss: 0.529\r",
      "Progress: 9.9% ... Training loss: 0.362 ... Validation loss: 0.542\r",
      "Progress: 9.9% ... Training loss: 0.396 ... Validation loss: 0.605\r",
      "Progress: 9.9% ... Training loss: 0.391 ... Validation loss: 0.573\r",
      "Progress: 9.9% ... Training loss: 0.378 ... Validation loss: 0.586\r",
      "Progress: 9.9% ... Training loss: 0.325 ... Validation loss: 0.518\r",
      "Progress: 9.9% ... Training loss: 0.360 ... Validation loss: 0.568\r",
      "Progress: 10.0% ... Training loss: 0.345 ... Validation loss: 0.537\r",
      "Progress: 10.0% ... Training loss: 0.330 ... Validation loss: 0.531\r",
      "Progress: 10.0% ... Training loss: 0.333 ... Validation loss: 0.523\r",
      "Progress: 10.0% ... Training loss: 0.356 ... Validation loss: 0.561\r",
      "Progress: 10.0% ... Training loss: 0.337 ... Validation loss: 0.529\r",
      "Progress: 10.1% ... Training loss: 0.321 ... Validation loss: 0.517\r",
      "Progress: 10.1% ... Training loss: 0.323 ... Validation loss: 0.523\r",
      "Progress: 10.1% ... Training loss: 0.453 ... Validation loss: 0.624\r",
      "Progress: 10.1% ... Training loss: 0.540 ... Validation loss: 0.760\r",
      "Progress: 10.1% ... Training loss: 0.462 ... Validation loss: 0.635\r",
      "Progress: 10.1% ... Training loss: 0.432 ... Validation loss: 0.651\r",
      "Progress: 10.2% ... Training loss: 0.393 ... Validation loss: 0.566\r",
      "Progress: 10.2% ... Training loss: 0.430 ... Validation loss: 0.649\r",
      "Progress: 10.2% ... Training loss: 0.334 ... Validation loss: 0.524\r",
      "Progress: 10.2% ... Training loss: 0.338 ... Validation loss: 0.545\r",
      "Progress: 10.2% ... Training loss: 0.341 ... Validation loss: 0.535\r",
      "Progress: 10.3% ... Training loss: 0.328 ... Validation loss: 0.521\r",
      "Progress: 10.3% ... Training loss: 0.327 ... Validation loss: 0.527\r",
      "Progress: 10.3% ... Training loss: 0.321 ... Validation loss: 0.514\r",
      "Progress: 10.3% ... Training loss: 0.327 ... Validation loss: 0.518\r",
      "Progress: 10.3% ... Training loss: 0.411 ... Validation loss: 0.618\r",
      "Progress: 10.3% ... Training loss: 0.335 ... Validation loss: 0.528\r",
      "Progress: 10.4% ... Training loss: 0.321 ... Validation loss: 0.517\r",
      "Progress: 10.4% ... Training loss: 0.318 ... Validation loss: 0.515\r",
      "Progress: 10.4% ... Training loss: 0.326 ... Validation loss: 0.520\r",
      "Progress: 10.4% ... Training loss: 0.318 ... Validation loss: 0.514\r",
      "Progress: 10.4% ... Training loss: 0.324 ... Validation loss: 0.522\r",
      "Progress: 10.5% ... Training loss: 0.318 ... Validation loss: 0.510\r",
      "Progress: 10.5% ... Training loss: 0.365 ... Validation loss: 0.564\r",
      "Progress: 10.5% ... Training loss: 0.325 ... Validation loss: 0.517\r",
      "Progress: 10.5% ... Training loss: 0.340 ... Validation loss: 0.540\r",
      "Progress: 10.5% ... Training loss: 0.316 ... Validation loss: 0.512\r",
      "Progress: 10.5% ... Training loss: 0.317 ... Validation loss: 0.513\r",
      "Progress: 10.6% ... Training loss: 0.320 ... Validation loss: 0.515\r",
      "Progress: 10.6% ... Training loss: 0.329 ... Validation loss: 0.520\r",
      "Progress: 10.6% ... Training loss: 0.343 ... Validation loss: 0.542\r",
      "Progress: 10.6% ... Training loss: 0.441 ... Validation loss: 0.624\r",
      "Progress: 10.6% ... Training loss: 0.500 ... Validation loss: 0.700\r",
      "Progress: 10.7% ... Training loss: 0.440 ... Validation loss: 0.618\r",
      "Progress: 10.7% ... Training loss: 0.407 ... Validation loss: 0.615\r",
      "Progress: 10.7% ... Training loss: 0.363 ... Validation loss: 0.546\r",
      "Progress: 10.7% ... Training loss: 0.349 ... Validation loss: 0.548\r",
      "Progress: 10.7% ... Training loss: 0.320 ... Validation loss: 0.513\r",
      "Progress: 10.7% ... Training loss: 0.342 ... Validation loss: 0.542\r",
      "Progress: 10.8% ... Training loss: 0.345 ... Validation loss: 0.530\r",
      "Progress: 10.8% ... Training loss: 0.405 ... Validation loss: 0.609\r",
      "Progress: 10.8% ... Training loss: 0.359 ... Validation loss: 0.542\r",
      "Progress: 10.8% ... Training loss: 0.396 ... Validation loss: 0.600\r",
      "Progress: 10.8% ... Training loss: 0.331 ... Validation loss: 0.521\r",
      "Progress: 10.9% ... Training loss: 0.342 ... Validation loss: 0.541\r",
      "Progress: 10.9% ... Training loss: 0.318 ... Validation loss: 0.514\r",
      "Progress: 10.9% ... Training loss: 0.315 ... Validation loss: 0.509\r",
      "Progress: 10.9% ... Training loss: 0.322 ... Validation loss: 0.511\r",
      "Progress: 10.9% ... Training loss: 0.337 ... Validation loss: 0.533\r",
      "Progress: 10.9% ... Training loss: 0.335 ... Validation loss: 0.521\r",
      "Progress: 11.0% ... Training loss: 0.315 ... Validation loss: 0.504\r",
      "Progress: 11.0% ... Training loss: 0.316 ... Validation loss: 0.506\r",
      "Progress: 11.0% ... Training loss: 0.314 ... Validation loss: 0.506\r",
      "Progress: 11.0% ... Training loss: 0.315 ... Validation loss: 0.506\r",
      "Progress: 11.0% ... Training loss: 0.315 ... Validation loss: 0.508\r",
      "Progress: 11.1% ... Training loss: 0.314 ... Validation loss: 0.506\r",
      "Progress: 11.1% ... Training loss: 0.318 ... Validation loss: 0.512\r",
      "Progress: 11.1% ... Training loss: 0.316 ... Validation loss: 0.508\r",
      "Progress: 11.1% ... Training loss: 0.317 ... Validation loss: 0.509\r",
      "Progress: 11.1% ... Training loss: 0.385 ... Validation loss: 0.580\r",
      "Progress: 11.1% ... Training loss: 0.437 ... Validation loss: 0.618\r",
      "Progress: 11.2% ... Training loss: 0.367 ... Validation loss: 0.565\r",
      "Progress: 11.2% ... Training loss: 0.349 ... Validation loss: 0.526\r",
      "Progress: 11.2% ... Training loss: 0.322 ... Validation loss: 0.514\r",
      "Progress: 11.2% ... Training loss: 0.319 ... Validation loss: 0.497\r",
      "Progress: 11.2% ... Training loss: 0.330 ... Validation loss: 0.524\r",
      "Progress: 11.3% ... Training loss: 0.316 ... Validation loss: 0.498\r",
      "Progress: 11.3% ... Training loss: 0.315 ... Validation loss: 0.505\r",
      "Progress: 11.3% ... Training loss: 0.313 ... Validation loss: 0.499\r",
      "Progress: 11.3% ... Training loss: 0.312 ... Validation loss: 0.502\r",
      "Progress: 11.3% ... Training loss: 0.315 ... Validation loss: 0.508\r",
      "Progress: 11.3% ... Training loss: 0.320 ... Validation loss: 0.515\r",
      "Progress: 11.4% ... Training loss: 0.318 ... Validation loss: 0.505\r",
      "Progress: 11.4% ... Training loss: 0.318 ... Validation loss: 0.513\r",
      "Progress: 11.4% ... Training loss: 0.373 ... Validation loss: 0.543\r",
      "Progress: 11.4% ... Training loss: 0.408 ... Validation loss: 0.619\r",
      "Progress: 11.4% ... Training loss: 0.364 ... Validation loss: 0.535\r",
      "Progress: 11.5% ... Training loss: 0.347 ... Validation loss: 0.551\r",
      "Progress: 11.5% ... Training loss: 0.338 ... Validation loss: 0.511\r",
      "Progress: 11.5% ... Training loss: 0.336 ... Validation loss: 0.536\r",
      "Progress: 11.5% ... Training loss: 0.406 ... Validation loss: 0.558\r",
      "Progress: 11.5% ... Training loss: 0.434 ... Validation loss: 0.652\r",
      "Progress: 11.5% ... Training loss: 0.552 ... Validation loss: 0.691\r",
      "Progress: 11.6% ... Training loss: 0.382 ... Validation loss: 0.582\r",
      "Progress: 11.6% ... Training loss: 0.370 ... Validation loss: 0.529\r",
      "Progress: 11.6% ... Training loss: 0.359 ... Validation loss: 0.554\r",
      "Progress: 11.6% ... Training loss: 0.379 ... Validation loss: 0.537\r",
      "Progress: 11.6% ... Training loss: 0.335 ... Validation loss: 0.526\r",
      "Progress: 11.7% ... Training loss: 0.319 ... Validation loss: 0.496\r",
      "Progress: 11.7% ... Training loss: 0.327 ... Validation loss: 0.499\r",
      "Progress: 11.7% ... Training loss: 0.321 ... Validation loss: 0.511\r",
      "Progress: 11.7% ... Training loss: 0.335 ... Validation loss: 0.506\r",
      "Progress: 11.7% ... Training loss: 0.320 ... Validation loss: 0.510\r",
      "Progress: 11.7% ... Training loss: 0.341 ... Validation loss: 0.534\r",
      "Progress: 11.8% ... Training loss: 0.317 ... Validation loss: 0.504\r",
      "Progress: 11.8% ... Training loss: 0.317 ... Validation loss: 0.508\r",
      "Progress: 11.8% ... Training loss: 0.312 ... Validation loss: 0.503\r",
      "Progress: 11.8% ... Training loss: 0.314 ... Validation loss: 0.506\r",
      "Progress: 11.8% ... Training loss: 0.346 ... Validation loss: 0.537\r",
      "Progress: 11.9% ... Training loss: 0.371 ... Validation loss: 0.562\r",
      "Progress: 11.9% ... Training loss: 0.346 ... Validation loss: 0.538\r",
      "Progress: 11.9% ... Training loss: 0.417 ... Validation loss: 0.591\r",
      "Progress: 11.9% ... Training loss: 0.457 ... Validation loss: 0.647\r",
      "Progress: 11.9% ... Training loss: 0.412 ... Validation loss: 0.586\r",
      "Progress: 11.9% ... Training loss: 0.324 ... Validation loss: 0.511\r",
      "Progress: 12.0% ... Training loss: 0.318 ... Validation loss: 0.492\r",
      "Progress: 12.0% ... Training loss: 0.327 ... Validation loss: 0.512\r",
      "Progress: 12.0% ... Training loss: 0.319 ... Validation loss: 0.495\r",
      "Progress: 12.0% ... Training loss: 0.321 ... Validation loss: 0.508\r",
      "Progress: 12.0% ... Training loss: 0.315 ... Validation loss: 0.492\r",
      "Progress: 12.1% ... Training loss: 0.311 ... Validation loss: 0.496\r",
      "Progress: 12.1% ... Training loss: 0.309 ... Validation loss: 0.492\r",
      "Progress: 12.1% ... Training loss: 0.319 ... Validation loss: 0.507\r",
      "Progress: 12.1% ... Training loss: 0.338 ... Validation loss: 0.508\r",
      "Progress: 12.1% ... Training loss: 0.331 ... Validation loss: 0.517\r",
      "Progress: 12.1% ... Training loss: 0.378 ... Validation loss: 0.545\r",
      "Progress: 12.2% ... Training loss: 0.450 ... Validation loss: 0.644\r",
      "Progress: 12.2% ... Training loss: 0.510 ... Validation loss: 0.670\r",
      "Progress: 12.2% ... Training loss: 0.474 ... Validation loss: 0.677\r",
      "Progress: 12.2% ... Training loss: 0.613 ... Validation loss: 0.751\r",
      "Progress: 12.2% ... Training loss: 0.717 ... Validation loss: 0.947\r",
      "Progress: 12.3% ... Training loss: 0.542 ... Validation loss: 0.665\r",
      "Progress: 12.3% ... Training loss: 0.489 ... Validation loss: 0.716\r",
      "Progress: 12.3% ... Training loss: 0.457 ... Validation loss: 0.588\r",
      "Progress: 12.3% ... Training loss: 0.539 ... Validation loss: 0.763\r",
      "Progress: 12.3% ... Training loss: 0.427 ... Validation loss: 0.569\r",
      "Progress: 12.3% ... Training loss: 0.424 ... Validation loss: 0.635\r",
      "Progress: 12.4% ... Training loss: 0.462 ... Validation loss: 0.606\r",
      "Progress: 12.4% ... Training loss: 0.392 ... Validation loss: 0.594\r",
      "Progress: 12.4% ... Training loss: 0.373 ... Validation loss: 0.530\r",
      "Progress: 12.4% ... Training loss: 0.381 ... Validation loss: 0.579\r",
      "Progress: 12.4% ... Training loss: 0.317 ... Validation loss: 0.494\r",
      "Progress: 12.5% ... Training loss: 0.321 ... Validation loss: 0.511\r",
      "Progress: 12.5% ... Training loss: 0.324 ... Validation loss: 0.513\r",
      "Progress: 12.5% ... Training loss: 0.310 ... Validation loss: 0.493\r",
      "Progress: 12.5% ... Training loss: 0.315 ... Validation loss: 0.494\r",
      "Progress: 12.5% ... Training loss: 0.333 ... Validation loss: 0.526\r",
      "Progress: 12.5% ... Training loss: 0.507 ... Validation loss: 0.659\r",
      "Progress: 12.6% ... Training loss: 0.398 ... Validation loss: 0.600\r",
      "Progress: 12.6% ... Training loss: 0.385 ... Validation loss: 0.557\r",
      "Progress: 12.6% ... Training loss: 0.368 ... Validation loss: 0.567\r",
      "Progress: 12.6% ... Training loss: 0.427 ... Validation loss: 0.590\r",
      "Progress: 12.6% ... Training loss: 0.334 ... Validation loss: 0.524\r",
      "Progress: 12.7% ... Training loss: 0.379 ... Validation loss: 0.550\r",
      "Progress: 12.7% ... Training loss: 0.388 ... Validation loss: 0.579\r",
      "Progress: 12.7% ... Training loss: 0.358 ... Validation loss: 0.525\r",
      "Progress: 12.7% ... Training loss: 0.321 ... Validation loss: 0.505\r",
      "Progress: 12.7% ... Training loss: 0.336 ... Validation loss: 0.506\r",
      "Progress: 12.7% ... Training loss: 0.318 ... Validation loss: 0.497\r",
      "Progress: 12.8% ... Training loss: 0.323 ... Validation loss: 0.491\r",
      "Progress: 12.8% ... Training loss: 0.333 ... Validation loss: 0.512\r",
      "Progress: 12.8% ... Training loss: 0.307 ... Validation loss: 0.486\r",
      "Progress: 12.8% ... Training loss: 0.318 ... Validation loss: 0.499\r",
      "Progress: 12.8% ... Training loss: 0.311 ... Validation loss: 0.488\r",
      "Progress: 12.9% ... Training loss: 0.307 ... Validation loss: 0.487\r",
      "Progress: 12.9% ... Training loss: 0.314 ... Validation loss: 0.493\r",
      "Progress: 12.9% ... Training loss: 0.307 ... Validation loss: 0.484\r",
      "Progress: 12.9% ... Training loss: 0.322 ... Validation loss: 0.500\r",
      "Progress: 12.9% ... Training loss: 0.309 ... Validation loss: 0.485\r",
      "Progress: 12.9% ... Training loss: 0.306 ... Validation loss: 0.482\r",
      "Progress: 13.0% ... Training loss: 0.306 ... Validation loss: 0.482\r",
      "Progress: 13.0% ... Training loss: 0.306 ... Validation loss: 0.481\r",
      "Progress: 13.0% ... Training loss: 0.311 ... Validation loss: 0.490\r",
      "Progress: 13.0% ... Training loss: 0.306 ... Validation loss: 0.482\r",
      "Progress: 13.0% ... Training loss: 0.335 ... Validation loss: 0.519\r",
      "Progress: 13.1% ... Training loss: 0.371 ... Validation loss: 0.530\r",
      "Progress: 13.1% ... Training loss: 0.365 ... Validation loss: 0.553\r",
      "Progress: 13.1% ... Training loss: 0.344 ... Validation loss: 0.508\r",
      "Progress: 13.1% ... Training loss: 0.363 ... Validation loss: 0.546\r",
      "Progress: 13.1% ... Training loss: 0.332 ... Validation loss: 0.497\r",
      "Progress: 13.1% ... Training loss: 0.328 ... Validation loss: 0.506\r",
      "Progress: 13.2% ... Training loss: 0.337 ... Validation loss: 0.503\r",
      "Progress: 13.2% ... Training loss: 0.315 ... Validation loss: 0.490\r",
      "Progress: 13.2% ... Training loss: 0.320 ... Validation loss: 0.487\r",
      "Progress: 13.2% ... Training loss: 0.364 ... Validation loss: 0.542\r",
      "Progress: 13.2% ... Training loss: 0.385 ... Validation loss: 0.540\r",
      "Progress: 13.3% ... Training loss: 0.331 ... Validation loss: 0.501\r",
      "Progress: 13.3% ... Training loss: 0.333 ... Validation loss: 0.495\r",
      "Progress: 13.3% ... Training loss: 0.313 ... Validation loss: 0.484\r",
      "Progress: 13.3% ... Training loss: 0.314 ... Validation loss: 0.484\r",
      "Progress: 13.3% ... Training loss: 0.311 ... Validation loss: 0.482\r",
      "Progress: 13.3% ... Training loss: 0.306 ... Validation loss: 0.475\r",
      "Progress: 13.4% ... Training loss: 0.318 ... Validation loss: 0.489\r",
      "Progress: 13.4% ... Training loss: 0.354 ... Validation loss: 0.519\r",
      "Progress: 13.4% ... Training loss: 0.307 ... Validation loss: 0.472\r",
      "Progress: 13.4% ... Training loss: 0.332 ... Validation loss: 0.500\r",
      "Progress: 13.4% ... Training loss: 0.324 ... Validation loss: 0.491\r",
      "Progress: 13.5% ... Training loss: 0.358 ... Validation loss: 0.522\r",
      "Progress: 13.5% ... Training loss: 0.308 ... Validation loss: 0.471\r",
      "Progress: 13.5% ... Training loss: 0.315 ... Validation loss: 0.485\r",
      "Progress: 13.5% ... Training loss: 0.311 ... Validation loss: 0.479\r",
      "Progress: 13.5% ... Training loss: 0.359 ... Validation loss: 0.521\r",
      "Progress: 13.5% ... Training loss: 0.385 ... Validation loss: 0.566\r",
      "Progress: 13.6% ... Training loss: 0.326 ... Validation loss: 0.492\r",
      "Progress: 13.6% ... Training loss: 0.305 ... Validation loss: 0.477\r",
      "Progress: 13.6% ... Training loss: 0.329 ... Validation loss: 0.492\r",
      "Progress: 13.6% ... Training loss: 0.350 ... Validation loss: 0.521\r",
      "Progress: 13.6% ... Training loss: 0.398 ... Validation loss: 0.557\r",
      "Progress: 13.7% ... Training loss: 0.332 ... Validation loss: 0.511\r",
      "Progress: 13.7% ... Training loss: 0.342 ... Validation loss: 0.508\r",
      "Progress: 13.7% ... Training loss: 0.351 ... Validation loss: 0.528\r",
      "Progress: 13.7% ... Training loss: 0.328 ... Validation loss: 0.491\r",
      "Progress: 13.7% ... Training loss: 0.402 ... Validation loss: 0.576\r",
      "Progress: 13.7% ... Training loss: 0.402 ... Validation loss: 0.559\r",
      "Progress: 13.8% ... Training loss: 0.400 ... Validation loss: 0.579\r",
      "Progress: 13.8% ... Training loss: 0.376 ... Validation loss: 0.533\r",
      "Progress: 13.8% ... Training loss: 0.417 ... Validation loss: 0.598\r",
      "Progress: 13.8% ... Training loss: 0.495 ... Validation loss: 0.647\r",
      "Progress: 13.8% ... Training loss: 0.518 ... Validation loss: 0.684\r",
      "Progress: 13.9% ... Training loss: 0.638 ... Validation loss: 0.799\r",
      "Progress: 13.9% ... Training loss: 0.546 ... Validation loss: 0.707\r",
      "Progress: 13.9% ... Training loss: 0.376 ... Validation loss: 0.548\r",
      "Progress: 13.9% ... Training loss: 0.326 ... Validation loss: 0.488\r",
      "Progress: 13.9% ... Training loss: 0.306 ... Validation loss: 0.475\r",
      "Progress: 13.9% ... Training loss: 0.306 ... Validation loss: 0.474\r",
      "Progress: 14.0% ... Training loss: 0.305 ... Validation loss: 0.473\r",
      "Progress: 14.0% ... Training loss: 0.304 ... Validation loss: 0.472\r",
      "Progress: 14.0% ... Training loss: 0.321 ... Validation loss: 0.491\r",
      "Progress: 14.0% ... Training loss: 0.363 ... Validation loss: 0.535\r",
      "Progress: 14.0% ... Training loss: 0.316 ... Validation loss: 0.487\r",
      "Progress: 14.1% ... Training loss: 0.306 ... Validation loss: 0.478\r",
      "Progress: 14.1% ... Training loss: 0.322 ... Validation loss: 0.494\r",
      "Progress: 14.1% ... Training loss: 0.304 ... Validation loss: 0.475\r",
      "Progress: 14.1% ... Training loss: 0.303 ... Validation loss: 0.475\r",
      "Progress: 14.1% ... Training loss: 0.327 ... Validation loss: 0.501\r",
      "Progress: 14.1% ... Training loss: 0.309 ... Validation loss: 0.484\r",
      "Progress: 14.2% ... Training loss: 0.309 ... Validation loss: 0.485\r",
      "Progress: 14.2% ... Training loss: 0.331 ... Validation loss: 0.506\r",
      "Progress: 14.2% ... Training loss: 0.346 ... Validation loss: 0.518\r",
      "Progress: 14.2% ... Training loss: 0.339 ... Validation loss: 0.516\r",
      "Progress: 14.2% ... Training loss: 0.377 ... Validation loss: 0.547\r",
      "Progress: 14.3% ... Training loss: 0.350 ... Validation loss: 0.524\r",
      "Progress: 14.3% ... Training loss: 0.320 ... Validation loss: 0.493\r",
      "Progress: 14.3% ... Training loss: 0.314 ... Validation loss: 0.485\r",
      "Progress: 14.3% ... Training loss: 0.329 ... Validation loss: 0.503\r",
      "Progress: 14.3% ... Training loss: 0.334 ... Validation loss: 0.504\r",
      "Progress: 14.3% ... Training loss: 0.317 ... Validation loss: 0.485\r",
      "Progress: 14.4% ... Training loss: 0.319 ... Validation loss: 0.493\r",
      "Progress: 14.4% ... Training loss: 0.353 ... Validation loss: 0.519\r",
      "Progress: 14.4% ... Training loss: 0.352 ... Validation loss: 0.527\r",
      "Progress: 14.4% ... Training loss: 0.367 ... Validation loss: 0.528\r",
      "Progress: 14.4% ... Training loss: 0.324 ... Validation loss: 0.496\r",
      "Progress: 14.5% ... Training loss: 0.370 ... Validation loss: 0.529\r",
      "Progress: 14.5% ... Training loss: 0.391 ... Validation loss: 0.568\r",
      "Progress: 14.5% ... Training loss: 0.326 ... Validation loss: 0.489\r",
      "Progress: 14.5% ... Training loss: 0.341 ... Validation loss: 0.513\r",
      "Progress: 14.5% ... Training loss: 0.337 ... Validation loss: 0.504\r",
      "Progress: 14.5% ... Training loss: 0.303 ... Validation loss: 0.473\r",
      "Progress: 14.6% ... Training loss: 0.307 ... Validation loss: 0.476\r",
      "Progress: 14.6% ... Training loss: 0.310 ... Validation loss: 0.483\r",
      "Progress: 14.6% ... Training loss: 0.304 ... Validation loss: 0.472\r",
      "Progress: 14.6% ... Training loss: 0.305 ... Validation loss: 0.477\r",
      "Progress: 14.6% ... Training loss: 0.303 ... Validation loss: 0.473\r",
      "Progress: 14.7% ... Training loss: 0.338 ... Validation loss: 0.502\r",
      "Progress: 14.7% ... Training loss: 0.317 ... Validation loss: 0.492\r",
      "Progress: 14.7% ... Training loss: 0.312 ... Validation loss: 0.478\r",
      "Progress: 14.7% ... Training loss: 0.310 ... Validation loss: 0.483\r",
      "Progress: 14.7% ... Training loss: 0.304 ... Validation loss: 0.478\r",
      "Progress: 14.7% ... Training loss: 0.315 ... Validation loss: 0.485\r",
      "Progress: 14.8% ... Training loss: 0.303 ... Validation loss: 0.477\r",
      "Progress: 14.8% ... Training loss: 0.308 ... Validation loss: 0.477\r",
      "Progress: 14.8% ... Training loss: 0.303 ... Validation loss: 0.473\r",
      "Progress: 14.8% ... Training loss: 0.317 ... Validation loss: 0.481\r",
      "Progress: 14.8% ... Training loss: 0.339 ... Validation loss: 0.514\r",
      "Progress: 14.9% ... Training loss: 0.332 ... Validation loss: 0.492\r",
      "Progress: 14.9% ... Training loss: 0.333 ... Validation loss: 0.514\r",
      "Progress: 14.9% ... Training loss: 0.308 ... Validation loss: 0.476\r",
      "Progress: 14.9% ... Training loss: 0.310 ... Validation loss: 0.486\r",
      "Progress: 14.9% ... Training loss: 0.303 ... Validation loss: 0.477\r",
      "Progress: 14.9% ... Training loss: 0.307 ... Validation loss: 0.478\r",
      "Progress: 15.0% ... Training loss: 0.349 ... Validation loss: 0.509\r",
      "Progress: 15.0% ... Training loss: 0.420 ... Validation loss: 0.599\r",
      "Progress: 15.0% ... Training loss: 0.478 ... Validation loss: 0.628\r",
      "Progress: 15.0% ... Training loss: 0.355 ... Validation loss: 0.531\r",
      "Progress: 15.0% ... Training loss: 0.326 ... Validation loss: 0.483\r",
      "Progress: 15.1% ... Training loss: 0.310 ... Validation loss: 0.482\r",
      "Progress: 15.1% ... Training loss: 0.351 ... Validation loss: 0.499\r",
      "Progress: 15.1% ... Training loss: 0.316 ... Validation loss: 0.488\r",
      "Progress: 15.1% ... Training loss: 0.321 ... Validation loss: 0.480\r",
      "Progress: 15.1% ... Training loss: 0.312 ... Validation loss: 0.474\r",
      "Progress: 15.1% ... Training loss: 0.302 ... Validation loss: 0.472\r",
      "Progress: 15.2% ... Training loss: 0.303 ... Validation loss: 0.472\r",
      "Progress: 15.2% ... Training loss: 0.304 ... Validation loss: 0.471\r",
      "Progress: 15.2% ... Training loss: 0.332 ... Validation loss: 0.506\r",
      "Progress: 15.2% ... Training loss: 0.306 ... Validation loss: 0.477\r",
      "Progress: 15.2% ... Training loss: 0.303 ... Validation loss: 0.476\r",
      "Progress: 15.3% ... Training loss: 0.316 ... Validation loss: 0.483\r",
      "Progress: 15.3% ... Training loss: 0.358 ... Validation loss: 0.536\r",
      "Progress: 15.3% ... Training loss: 0.381 ... Validation loss: 0.536\r",
      "Progress: 15.3% ... Training loss: 0.429 ... Validation loss: 0.612\r",
      "Progress: 15.3% ... Training loss: 0.448 ... Validation loss: 0.608\r",
      "Progress: 15.3% ... Training loss: 0.348 ... Validation loss: 0.525\r",
      "Progress: 15.4% ... Training loss: 0.303 ... Validation loss: 0.477\r",
      "Progress: 15.4% ... Training loss: 0.306 ... Validation loss: 0.482\r",
      "Progress: 15.4% ... Training loss: 0.310 ... Validation loss: 0.481\r",
      "Progress: 15.4% ... Training loss: 0.303 ... Validation loss: 0.477\r",
      "Progress: 15.4% ... Training loss: 0.305 ... Validation loss: 0.475\r",
      "Progress: 15.5% ... Training loss: 0.305 ... Validation loss: 0.469\r",
      "Progress: 15.5% ... Training loss: 0.302 ... Validation loss: 0.467\r",
      "Progress: 15.5% ... Training loss: 0.315 ... Validation loss: 0.486\r",
      "Progress: 15.5% ... Training loss: 0.322 ... Validation loss: 0.484\r",
      "Progress: 15.5% ... Training loss: 0.317 ... Validation loss: 0.488\r",
      "Progress: 15.5% ... Training loss: 0.411 ... Validation loss: 0.554\r",
      "Progress: 15.6% ... Training loss: 0.458 ... Validation loss: 0.631\r",
      "Progress: 15.6% ... Training loss: 0.401 ... Validation loss: 0.560\r",
      "Progress: 15.6% ... Training loss: 0.348 ... Validation loss: 0.518\r",
      "Progress: 15.6% ... Training loss: 0.439 ... Validation loss: 0.596\r",
      "Progress: 15.6% ... Training loss: 0.375 ... Validation loss: 0.542\r",
      "Progress: 15.7% ... Training loss: 0.339 ... Validation loss: 0.500\r",
      "Progress: 15.7% ... Training loss: 0.308 ... Validation loss: 0.475\r",
      "Progress: 15.7% ... Training loss: 0.332 ... Validation loss: 0.485\r",
      "Progress: 15.7% ... Training loss: 0.339 ... Validation loss: 0.510\r",
      "Progress: 15.7% ... Training loss: 0.302 ... Validation loss: 0.469\r",
      "Progress: 15.7% ... Training loss: 0.308 ... Validation loss: 0.473\r",
      "Progress: 15.8% ... Training loss: 0.331 ... Validation loss: 0.505\r",
      "Progress: 15.8% ... Training loss: 0.324 ... Validation loss: 0.487\r",
      "Progress: 15.8% ... Training loss: 0.332 ... Validation loss: 0.506\r",
      "Progress: 15.8% ... Training loss: 0.304 ... Validation loss: 0.470\r",
      "Progress: 15.8% ... Training loss: 0.313 ... Validation loss: 0.485\r",
      "Progress: 15.9% ... Training loss: 0.328 ... Validation loss: 0.491\r",
      "Progress: 15.9% ... Training loss: 0.318 ... Validation loss: 0.490\r",
      "Progress: 15.9% ... Training loss: 0.307 ... Validation loss: 0.475\r",
      "Progress: 15.9% ... Training loss: 0.342 ... Validation loss: 0.516\r",
      "Progress: 15.9% ... Training loss: 0.375 ... Validation loss: 0.546\r",
      "Progress: 15.9% ... Training loss: 0.375 ... Validation loss: 0.547\r",
      "Progress: 16.0% ... Training loss: 0.321 ... Validation loss: 0.486\r",
      "Progress: 16.0% ... Training loss: 0.378 ... Validation loss: 0.555\r",
      "Progress: 16.0% ... Training loss: 0.415 ... Validation loss: 0.566\r",
      "Progress: 16.0% ... Training loss: 0.331 ... Validation loss: 0.507\r",
      "Progress: 16.0% ... Training loss: 0.348 ... Validation loss: 0.510\r",
      "Progress: 16.1% ... Training loss: 0.303 ... Validation loss: 0.474\r",
      "Progress: 16.1% ... Training loss: 0.318 ... Validation loss: 0.477\r",
      "Progress: 16.1% ... Training loss: 0.304 ... Validation loss: 0.474\r",
      "Progress: 16.1% ... Training loss: 0.315 ... Validation loss: 0.469\r",
      "Progress: 16.1% ... Training loss: 0.304 ... Validation loss: 0.471\r",
      "Progress: 16.1% ... Training loss: 0.397 ... Validation loss: 0.533\r",
      "Progress: 16.2% ... Training loss: 0.334 ... Validation loss: 0.510\r",
      "Progress: 16.2% ... Training loss: 0.314 ... Validation loss: 0.487\r",
      "Progress: 16.2% ... Training loss: 0.386 ... Validation loss: 0.531\r",
      "Progress: 16.2% ... Training loss: 0.347 ... Validation loss: 0.524\r",
      "Progress: 16.2% ... Training loss: 0.345 ... Validation loss: 0.490\r",
      "Progress: 16.3% ... Training loss: 0.319 ... Validation loss: 0.487\r",
      "Progress: 16.3% ... Training loss: 0.302 ... Validation loss: 0.462\r",
      "Progress: 16.3% ... Training loss: 0.327 ... Validation loss: 0.499\r",
      "Progress: 16.3% ... Training loss: 0.321 ... Validation loss: 0.477\r",
      "Progress: 16.3% ... Training loss: 0.332 ... Validation loss: 0.502\r",
      "Progress: 16.3% ... Training loss: 0.333 ... Validation loss: 0.487\r",
      "Progress: 16.4% ... Training loss: 0.316 ... Validation loss: 0.484\r",
      "Progress: 16.4% ... Training loss: 0.306 ... Validation loss: 0.465\r",
      "Progress: 16.4% ... Training loss: 0.311 ... Validation loss: 0.477\r",
      "Progress: 16.4% ... Training loss: 0.301 ... Validation loss: 0.466\r",
      "Progress: 16.4% ... Training loss: 0.307 ... Validation loss: 0.476\r",
      "Progress: 16.5% ... Training loss: 0.322 ... Validation loss: 0.479\r",
      "Progress: 16.5% ... Training loss: 0.351 ... Validation loss: 0.525\r",
      "Progress: 16.5% ... Training loss: 0.388 ... Validation loss: 0.532\r",
      "Progress: 16.5% ... Training loss: 0.448 ... Validation loss: 0.633\r",
      "Progress: 16.5% ... Training loss: 0.347 ... Validation loss: 0.507\r",
      "Progress: 16.5% ... Training loss: 0.325 ... Validation loss: 0.499\r",
      "Progress: 16.6% ... Training loss: 0.312 ... Validation loss: 0.479\r",
      "Progress: 16.6% ... Training loss: 0.347 ... Validation loss: 0.522\r",
      "Progress: 16.6% ... Training loss: 0.362 ... Validation loss: 0.524\r",
      "Progress: 16.6% ... Training loss: 0.320 ... Validation loss: 0.493\r",
      "Progress: 16.6% ... Training loss: 0.318 ... Validation loss: 0.484\r",
      "Progress: 16.7% ... Training loss: 0.355 ... Validation loss: 0.529\r",
      "Progress: 16.7% ... Training loss: 0.307 ... Validation loss: 0.475\r",
      "Progress: 16.7% ... Training loss: 0.314 ... Validation loss: 0.487\r",
      "Progress: 16.7% ... Training loss: 0.372 ... Validation loss: 0.533\r",
      "Progress: 16.7% ... Training loss: 0.366 ... Validation loss: 0.531\r",
      "Progress: 16.7% ... Training loss: 0.373 ... Validation loss: 0.532\r",
      "Progress: 16.8% ... Training loss: 0.389 ... Validation loss: 0.555\r",
      "Progress: 16.8% ... Training loss: 0.373 ... Validation loss: 0.539\r",
      "Progress: 16.8% ... Training loss: 0.376 ... Validation loss: 0.541\r",
      "Progress: 16.8% ... Training loss: 0.398 ... Validation loss: 0.558\r",
      "Progress: 16.8% ... Training loss: 0.328 ... Validation loss: 0.493\r",
      "Progress: 16.9% ... Training loss: 0.319 ... Validation loss: 0.480\r",
      "Progress: 16.9% ... Training loss: 0.329 ... Validation loss: 0.494\r",
      "Progress: 16.9% ... Training loss: 0.354 ... Validation loss: 0.515\r",
      "Progress: 16.9% ... Training loss: 0.319 ... Validation loss: 0.485\r",
      "Progress: 16.9% ... Training loss: 0.302 ... Validation loss: 0.471\r",
      "Progress: 16.9% ... Training loss: 0.345 ... Validation loss: 0.505\r",
      "Progress: 17.0% ... Training loss: 0.305 ... Validation loss: 0.470\r",
      "Progress: 17.0% ... Training loss: 0.301 ... Validation loss: 0.465\r",
      "Progress: 17.0% ... Training loss: 0.351 ... Validation loss: 0.520\r",
      "Progress: 17.0% ... Training loss: 0.415 ... Validation loss: 0.569\r",
      "Progress: 17.0% ... Training loss: 0.358 ... Validation loss: 0.526\r",
      "Progress: 17.1% ... Training loss: 0.348 ... Validation loss: 0.507\r",
      "Progress: 17.1% ... Training loss: 0.312 ... Validation loss: 0.480\r",
      "Progress: 17.1% ... Training loss: 0.308 ... Validation loss: 0.468\r",
      "Progress: 17.1% ... Training loss: 0.345 ... Validation loss: 0.518\r",
      "Progress: 17.1% ... Training loss: 0.314 ... Validation loss: 0.477\r",
      "Progress: 17.1% ... Training loss: 0.307 ... Validation loss: 0.475\r",
      "Progress: 17.2% ... Training loss: 0.311 ... Validation loss: 0.475\r",
      "Progress: 17.2% ... Training loss: 0.308 ... Validation loss: 0.480\r",
      "Progress: 17.2% ... Training loss: 0.307 ... Validation loss: 0.470\r",
      "Progress: 17.2% ... Training loss: 0.301 ... Validation loss: 0.465\r",
      "Progress: 17.2% ... Training loss: 0.304 ... Validation loss: 0.475\r",
      "Progress: 17.3% ... Training loss: 0.301 ... Validation loss: 0.466\r",
      "Progress: 17.3% ... Training loss: 0.318 ... Validation loss: 0.492\r",
      "Progress: 17.3% ... Training loss: 0.308 ... Validation loss: 0.471\r",
      "Progress: 17.3% ... Training loss: 0.306 ... Validation loss: 0.477\r",
      "Progress: 17.3% ... Training loss: 0.311 ... Validation loss: 0.481\r",
      "Progress: 17.3% ... Training loss: 0.301 ... Validation loss: 0.469\r",
      "Progress: 17.4% ... Training loss: 0.306 ... Validation loss: 0.471\r",
      "Progress: 17.4% ... Training loss: 0.308 ... Validation loss: 0.479\r",
      "Progress: 17.4% ... Training loss: 0.303 ... Validation loss: 0.475\r",
      "Progress: 17.4% ... Training loss: 0.306 ... Validation loss: 0.475\r",
      "Progress: 17.4% ... Training loss: 0.313 ... Validation loss: 0.484\r",
      "Progress: 17.5% ... Training loss: 0.307 ... Validation loss: 0.479\r",
      "Progress: 17.5% ... Training loss: 0.318 ... Validation loss: 0.486\r",
      "Progress: 17.5% ... Training loss: 0.349 ... Validation loss: 0.524\r",
      "Progress: 17.5% ... Training loss: 0.301 ... Validation loss: 0.472\r",
      "Progress: 17.5% ... Training loss: 0.306 ... Validation loss: 0.478\r",
      "Progress: 17.5% ... Training loss: 0.364 ... Validation loss: 0.520\r",
      "Progress: 17.6% ... Training loss: 0.378 ... Validation loss: 0.550\r",
      "Progress: 17.6% ... Training loss: 0.359 ... Validation loss: 0.510\r",
      "Progress: 17.6% ... Training loss: 0.357 ... Validation loss: 0.530\r",
      "Progress: 17.6% ... Training loss: 0.311 ... Validation loss: 0.470\r",
      "Progress: 17.6% ... Training loss: 0.319 ... Validation loss: 0.489\r",
      "Progress: 17.7% ... Training loss: 0.303 ... Validation loss: 0.468\r",
      "Progress: 17.7% ... Training loss: 0.302 ... Validation loss: 0.470\r",
      "Progress: 17.7% ... Training loss: 0.309 ... Validation loss: 0.471\r",
      "Progress: 17.7% ... Training loss: 0.301 ... Validation loss: 0.465\r",
      "Progress: 17.7% ... Training loss: 0.310 ... Validation loss: 0.471\r",
      "Progress: 17.7% ... Training loss: 0.337 ... Validation loss: 0.505\r",
      "Progress: 17.8% ... Training loss: 0.337 ... Validation loss: 0.495\r",
      "Progress: 17.8% ... Training loss: 0.305 ... Validation loss: 0.472\r",
      "Progress: 17.8% ... Training loss: 0.300 ... Validation loss: 0.466\r",
      "Progress: 17.8% ... Training loss: 0.300 ... Validation loss: 0.465\r",
      "Progress: 17.8% ... Training loss: 0.314 ... Validation loss: 0.480\r",
      "Progress: 17.9% ... Training loss: 0.316 ... Validation loss: 0.472\r",
      "Progress: 17.9% ... Training loss: 0.305 ... Validation loss: 0.466\r",
      "Progress: 17.9% ... Training loss: 0.319 ... Validation loss: 0.477\r",
      "Progress: 17.9% ... Training loss: 0.300 ... Validation loss: 0.464\r",
      "Progress: 17.9% ... Training loss: 0.304 ... Validation loss: 0.468\r",
      "Progress: 17.9% ... Training loss: 0.309 ... Validation loss: 0.474\r",
      "Progress: 18.0% ... Training loss: 0.326 ... Validation loss: 0.482\r",
      "Progress: 18.0% ... Training loss: 0.412 ... Validation loss: 0.578\r",
      "Progress: 18.0% ... Training loss: 0.316 ... Validation loss: 0.477\r",
      "Progress: 18.0% ... Training loss: 0.300 ... Validation loss: 0.464\r",
      "Progress: 18.0% ... Training loss: 0.301 ... Validation loss: 0.468\r",
      "Progress: 18.1% ... Training loss: 0.345 ... Validation loss: 0.511\r",
      "Progress: 18.1% ... Training loss: 0.300 ... Validation loss: 0.470\r",
      "Progress: 18.1% ... Training loss: 0.334 ... Validation loss: 0.501\r",
      "Progress: 18.1% ... Training loss: 0.317 ... Validation loss: 0.491\r",
      "Progress: 18.1% ... Training loss: 0.350 ... Validation loss: 0.514\r",
      "Progress: 18.1% ... Training loss: 0.339 ... Validation loss: 0.512\r",
      "Progress: 18.2% ... Training loss: 0.361 ... Validation loss: 0.525\r",
      "Progress: 18.2% ... Training loss: 0.300 ... Validation loss: 0.470\r",
      "Progress: 18.2% ... Training loss: 0.319 ... Validation loss: 0.485\r",
      "Progress: 18.2% ... Training loss: 0.321 ... Validation loss: 0.485\r",
      "Progress: 18.2% ... Training loss: 0.330 ... Validation loss: 0.499\r",
      "Progress: 18.3% ... Training loss: 0.345 ... Validation loss: 0.509\r",
      "Progress: 18.3% ... Training loss: 0.333 ... Validation loss: 0.502\r",
      "Progress: 18.3% ... Training loss: 0.318 ... Validation loss: 0.484\r",
      "Progress: 18.3% ... Training loss: 0.300 ... Validation loss: 0.469\r",
      "Progress: 18.3% ... Training loss: 0.303 ... Validation loss: 0.474\r",
      "Progress: 18.3% ... Training loss: 0.303 ... Validation loss: 0.470\r",
      "Progress: 18.4% ... Training loss: 0.311 ... Validation loss: 0.476\r",
      "Progress: 18.4% ... Training loss: 0.324 ... Validation loss: 0.487\r",
      "Progress: 18.4% ... Training loss: 0.317 ... Validation loss: 0.488\r",
      "Progress: 18.4% ... Training loss: 0.306 ... Validation loss: 0.472\r",
      "Progress: 18.4% ... Training loss: 0.347 ... Validation loss: 0.514\r",
      "Progress: 18.5% ... Training loss: 0.343 ... Validation loss: 0.507\r",
      "Progress: 18.5% ... Training loss: 0.395 ... Validation loss: 0.552\r",
      "Progress: 18.5% ... Training loss: 0.486 ... Validation loss: 0.643\r",
      "Progress: 18.5% ... Training loss: 0.425 ... Validation loss: 0.589\r",
      "Progress: 18.5% ... Training loss: 0.376 ... Validation loss: 0.534\r",
      "Progress: 18.5% ... Training loss: 0.475 ... Validation loss: 0.637\r",
      "Progress: 18.6% ... Training loss: 0.577 ... Validation loss: 0.715\r",
      "Progress: 18.6% ... Training loss: 0.615 ... Validation loss: 0.791\r",
      "Progress: 18.6% ... Training loss: 0.669 ... Validation loss: 0.799\r",
      "Progress: 18.6% ... Training loss: 0.482 ... Validation loss: 0.661\r",
      "Progress: 18.6% ... Training loss: 0.359 ... Validation loss: 0.516\r",
      "Progress: 18.7% ... Training loss: 0.308 ... Validation loss: 0.475\r",
      "Progress: 18.7% ... Training loss: 0.303 ... Validation loss: 0.466\r",
      "Progress: 18.7% ... Training loss: 0.301 ... Validation loss: 0.468\r",
      "Progress: 18.7% ... Training loss: 0.301 ... Validation loss: 0.466\r",
      "Progress: 18.7% ... Training loss: 0.311 ... Validation loss: 0.478\r",
      "Progress: 18.7% ... Training loss: 0.303 ... Validation loss: 0.464\r",
      "Progress: 18.8% ... Training loss: 0.308 ... Validation loss: 0.472\r",
      "Progress: 18.8% ... Training loss: 0.317 ... Validation loss: 0.471\r",
      "Progress: 18.8% ... Training loss: 0.303 ... Validation loss: 0.459\r",
      "Progress: 18.8% ... Training loss: 0.302 ... Validation loss: 0.457\r",
      "Progress: 18.8% ... Training loss: 0.348 ... Validation loss: 0.496\r",
      "Progress: 18.9% ... Training loss: 0.367 ... Validation loss: 0.520\r",
      "Progress: 18.9% ... Training loss: 0.356 ... Validation loss: 0.515\r",
      "Progress: 18.9% ... Training loss: 0.364 ... Validation loss: 0.518\r",
      "Progress: 18.9% ... Training loss: 0.316 ... Validation loss: 0.479\r",
      "Progress: 18.9% ... Training loss: 0.307 ... Validation loss: 0.466\r",
      "Progress: 18.9% ... Training loss: 0.307 ... Validation loss: 0.469\r",
      "Progress: 19.0% ... Training loss: 0.303 ... Validation loss: 0.466\r",
      "Progress: 19.0% ... Training loss: 0.300 ... Validation loss: 0.466\r",
      "Progress: 19.0% ... Training loss: 0.304 ... Validation loss: 0.469\r",
      "Progress: 19.0% ... Training loss: 0.303 ... Validation loss: 0.470\r",
      "Progress: 19.0% ... Training loss: 0.299 ... Validation loss: 0.466\r",
      "Progress: 19.1% ... Training loss: 0.318 ... Validation loss: 0.481\r",
      "Progress: 19.1% ... Training loss: 0.353 ... Validation loss: 0.526\r",
      "Progress: 19.1% ... Training loss: 0.300 ... Validation loss: 0.465\r",
      "Progress: 19.1% ... Training loss: 0.311 ... Validation loss: 0.473\r",
      "Progress: 19.1% ... Training loss: 0.302 ... Validation loss: 0.467\r",
      "Progress: 19.1% ... Training loss: 0.311 ... Validation loss: 0.487\r",
      "Progress: 19.2% ... Training loss: 0.307 ... Validation loss: 0.473\r",
      "Progress: 19.2% ... Training loss: 0.301 ... Validation loss: 0.475\r",
      "Progress: 19.2% ... Training loss: 0.303 ... Validation loss: 0.475\r",
      "Progress: 19.2% ... Training loss: 0.366 ... Validation loss: 0.555\r",
      "Progress: 19.2% ... Training loss: 0.445 ... Validation loss: 0.592\r",
      "Progress: 19.3% ... Training loss: 0.371 ... Validation loss: 0.560\r",
      "Progress: 19.3% ... Training loss: 0.402 ... Validation loss: 0.559\r",
      "Progress: 19.3% ... Training loss: 0.385 ... Validation loss: 0.566\r",
      "Progress: 19.3% ... Training loss: 0.324 ... Validation loss: 0.488\r",
      "Progress: 19.3% ... Training loss: 0.429 ... Validation loss: 0.613\r",
      "Progress: 19.3% ... Training loss: 0.391 ... Validation loss: 0.541\r",
      "Progress: 19.4% ... Training loss: 0.321 ... Validation loss: 0.502\r",
      "Progress: 19.4% ... Training loss: 0.325 ... Validation loss: 0.488\r",
      "Progress: 19.4% ... Training loss: 0.302 ... Validation loss: 0.472\r",
      "Progress: 19.4% ... Training loss: 0.311 ... Validation loss: 0.476\r",
      "Progress: 19.4% ... Training loss: 0.320 ... Validation loss: 0.483\r",
      "Progress: 19.5% ... Training loss: 0.343 ... Validation loss: 0.505\r",
      "Progress: 19.5% ... Training loss: 0.364 ... Validation loss: 0.527\r",
      "Progress: 19.5% ... Training loss: 0.343 ... Validation loss: 0.500\r",
      "Progress: 19.5% ... Training loss: 0.302 ... Validation loss: 0.473\r",
      "Progress: 19.5% ... Training loss: 0.306 ... Validation loss: 0.469\r",
      "Progress: 19.5% ... Training loss: 0.304 ... Validation loss: 0.475\r",
      "Progress: 19.6% ... Training loss: 0.317 ... Validation loss: 0.477\r",
      "Progress: 19.6% ... Training loss: 0.309 ... Validation loss: 0.483\r",
      "Progress: 19.6% ... Training loss: 0.361 ... Validation loss: 0.518\r",
      "Progress: 19.6% ... Training loss: 0.304 ... Validation loss: 0.476\r",
      "Progress: 19.6% ... Training loss: 0.299 ... Validation loss: 0.468\r",
      "Progress: 19.7% ... Training loss: 0.299 ... Validation loss: 0.468\r",
      "Progress: 19.7% ... Training loss: 0.299 ... Validation loss: 0.468\r",
      "Progress: 19.7% ... Training loss: 0.314 ... Validation loss: 0.481\r",
      "Progress: 19.7% ... Training loss: 0.302 ... Validation loss: 0.478\r",
      "Progress: 19.7% ... Training loss: 0.299 ... Validation loss: 0.470\r",
      "Progress: 19.7% ... Training loss: 0.302 ... Validation loss: 0.470\r",
      "Progress: 19.8% ... Training loss: 0.299 ... Validation loss: 0.467\r",
      "Progress: 19.8% ... Training loss: 0.299 ... Validation loss: 0.468\r",
      "Progress: 19.8% ... Training loss: 0.348 ... Validation loss: 0.524\r",
      "Progress: 19.8% ... Training loss: 0.368 ... Validation loss: 0.521\r",
      "Progress: 19.8% ... Training loss: 0.338 ... Validation loss: 0.514\r",
      "Progress: 19.9% ... Training loss: 0.328 ... Validation loss: 0.488\r",
      "Progress: 19.9% ... Training loss: 0.371 ... Validation loss: 0.544\r",
      "Progress: 19.9% ... Training loss: 0.321 ... Validation loss: 0.485\r",
      "Progress: 19.9% ... Training loss: 0.345 ... Validation loss: 0.506\r",
      "Progress: 19.9% ... Training loss: 0.367 ... Validation loss: 0.533\r",
      "Progress: 19.9% ... Training loss: 0.471 ... Validation loss: 0.624\r",
      "Progress: 20.0% ... Training loss: 0.460 ... Validation loss: 0.629\r",
      "Progress: 20.0% ... Training loss: 0.434 ... Validation loss: 0.601\r",
      "Progress: 20.0% ... Training loss: 0.384 ... Validation loss: 0.547\r",
      "Progress: 20.0% ... Training loss: 0.318 ... Validation loss: 0.479\r",
      "Progress: 20.0% ... Training loss: 0.322 ... Validation loss: 0.486\r",
      "Progress: 20.1% ... Training loss: 0.304 ... Validation loss: 0.469\r",
      "Progress: 20.1% ... Training loss: 0.357 ... Validation loss: 0.520\r",
      "Progress: 20.1% ... Training loss: 0.357 ... Validation loss: 0.527\r",
      "Progress: 20.1% ... Training loss: 0.365 ... Validation loss: 0.526\r",
      "Progress: 20.1% ... Training loss: 0.300 ... Validation loss: 0.472\r",
      "Progress: 20.1% ... Training loss: 0.298 ... Validation loss: 0.466\r",
      "Progress: 20.2% ... Training loss: 0.342 ... Validation loss: 0.508\r",
      "Progress: 20.2% ... Training loss: 0.377 ... Validation loss: 0.543\r",
      "Progress: 20.2% ... Training loss: 0.344 ... Validation loss: 0.503\r",
      "Progress: 20.2% ... Training loss: 0.330 ... Validation loss: 0.496\r",
      "Progress: 20.2% ... Training loss: 0.385 ... Validation loss: 0.547\r",
      "Progress: 20.3% ... Training loss: 0.368 ... Validation loss: 0.532\r",
      "Progress: 20.3% ... Training loss: 0.393 ... Validation loss: 0.551\r",
      "Progress: 20.3% ... Training loss: 0.400 ... Validation loss: 0.562\r",
      "Progress: 20.3% ... Training loss: 0.415 ... Validation loss: 0.584\r",
      "Progress: 20.3% ... Training loss: 0.427 ... Validation loss: 0.585\r",
      "Progress: 20.3% ... Training loss: 0.382 ... Validation loss: 0.547\r",
      "Progress: 20.4% ... Training loss: 0.324 ... Validation loss: 0.487\r",
      "Progress: 20.4% ... Training loss: 0.414 ... Validation loss: 0.564\r",
      "Progress: 20.4% ... Training loss: 0.366 ... Validation loss: 0.528\r",
      "Progress: 20.4% ... Training loss: 0.302 ... Validation loss: 0.461\r",
      "Progress: 20.4% ... Training loss: 0.317 ... Validation loss: 0.472\r",
      "Progress: 20.5% ... Training loss: 0.341 ... Validation loss: 0.503\r",
      "Progress: 20.5% ... Training loss: 0.398 ... Validation loss: 0.560\r",
      "Progress: 20.5% ... Training loss: 0.351 ... Validation loss: 0.511\r",
      "Progress: 20.5% ... Training loss: 0.327 ... Validation loss: 0.498\r",
      "Progress: 20.5% ... Training loss: 0.314 ... Validation loss: 0.478\r",
      "Progress: 20.5% ... Training loss: 0.301 ... Validation loss: 0.474\r",
      "Progress: 20.6% ... Training loss: 0.299 ... Validation loss: 0.472\r",
      "Progress: 20.6% ... Training loss: 0.299 ... Validation loss: 0.470\r",
      "Progress: 20.6% ... Training loss: 0.325 ... Validation loss: 0.487\r",
      "Progress: 20.6% ... Training loss: 0.305 ... Validation loss: 0.482\r",
      "Progress: 20.6% ... Training loss: 0.321 ... Validation loss: 0.502\r",
      "Progress: 20.7% ... Training loss: 0.389 ... Validation loss: 0.536\r",
      "Progress: 20.7% ... Training loss: 0.345 ... Validation loss: 0.539\r",
      "Progress: 20.7% ... Training loss: 0.305 ... Validation loss: 0.474\r",
      "Progress: 20.7% ... Training loss: 0.301 ... Validation loss: 0.479\r",
      "Progress: 20.7% ... Training loss: 0.299 ... Validation loss: 0.475\r",
      "Progress: 20.7% ... Training loss: 0.299 ... Validation loss: 0.471\r",
      "Progress: 20.8% ... Training loss: 0.299 ... Validation loss: 0.475\r",
      "Progress: 20.8% ... Training loss: 0.298 ... Validation loss: 0.469\r",
      "Progress: 20.8% ... Training loss: 0.298 ... Validation loss: 0.468\r",
      "Progress: 20.8% ... Training loss: 0.302 ... Validation loss: 0.477\r",
      "Progress: 20.8% ... Training loss: 0.299 ... Validation loss: 0.465\r",
      "Progress: 20.9% ... Training loss: 0.305 ... Validation loss: 0.479\r",
      "Progress: 20.9% ... Training loss: 0.316 ... Validation loss: 0.476\r",
      "Progress: 20.9% ... Training loss: 0.332 ... Validation loss: 0.513\r",
      "Progress: 20.9% ... Training loss: 0.442 ... Validation loss: 0.590\r",
      "Progress: 20.9% ... Training loss: 0.547 ... Validation loss: 0.721\r",
      "Progress: 20.9% ... Training loss: 0.478 ... Validation loss: 0.624\r",
      "Progress: 21.0% ... Training loss: 0.470 ... Validation loss: 0.644\r",
      "Progress: 21.0% ... Training loss: 0.461 ... Validation loss: 0.614\r",
      "Progress: 21.0% ... Training loss: 0.447 ... Validation loss: 0.622\r",
      "Progress: 21.0% ... Training loss: 0.410 ... Validation loss: 0.562\r",
      "Progress: 21.0% ... Training loss: 0.377 ... Validation loss: 0.553\r",
      "Progress: 21.1% ... Training loss: 0.323 ... Validation loss: 0.482\r",
      "Progress: 21.1% ... Training loss: 0.345 ... Validation loss: 0.523\r",
      "Progress: 21.1% ... Training loss: 0.300 ... Validation loss: 0.469\r",
      "Progress: 21.1% ... Training loss: 0.298 ... Validation loss: 0.463\r",
      "Progress: 21.1% ... Training loss: 0.302 ... Validation loss: 0.466\r",
      "Progress: 21.1% ... Training loss: 0.332 ... Validation loss: 0.489\r",
      "Progress: 21.2% ... Training loss: 0.393 ... Validation loss: 0.572\r",
      "Progress: 21.2% ... Training loss: 0.335 ... Validation loss: 0.490\r",
      "Progress: 21.2% ... Training loss: 0.360 ... Validation loss: 0.535\r",
      "Progress: 21.2% ... Training loss: 0.362 ... Validation loss: 0.514\r",
      "Progress: 21.2% ... Training loss: 0.312 ... Validation loss: 0.480\r",
      "Progress: 21.3% ... Training loss: 0.321 ... Validation loss: 0.481\r",
      "Progress: 21.3% ... Training loss: 0.341 ... Validation loss: 0.513\r",
      "Progress: 21.3% ... Training loss: 0.339 ... Validation loss: 0.496\r",
      "Progress: 21.3% ... Training loss: 0.299 ... Validation loss: 0.464\r",
      "Progress: 21.3% ... Training loss: 0.306 ... Validation loss: 0.469\r",
      "Progress: 21.3% ... Training loss: 0.306 ... Validation loss: 0.477\r",
      "Progress: 21.4% ... Training loss: 0.303 ... Validation loss: 0.468\r",
      "Progress: 21.4% ... Training loss: 0.300 ... Validation loss: 0.467\r",
      "Progress: 21.4% ... Training loss: 0.338 ... Validation loss: 0.514\r",
      "Progress: 21.4% ... Training loss: 0.349 ... Validation loss: 0.505\r",
      "Progress: 21.4% ... Training loss: 0.304 ... Validation loss: 0.475\r",
      "Progress: 21.5% ... Training loss: 0.299 ... Validation loss: 0.465\r",
      "Progress: 21.5% ... Training loss: 0.299 ... Validation loss: 0.462\r",
      "Progress: 21.5% ... Training loss: 0.305 ... Validation loss: 0.468\r",
      "Progress: 21.5% ... Training loss: 0.305 ... Validation loss: 0.476\r",
      "Progress: 21.5% ... Training loss: 0.297 ... Validation loss: 0.465\r",
      "Progress: 21.5% ... Training loss: 0.302 ... Validation loss: 0.467\r",
      "Progress: 21.6% ... Training loss: 0.298 ... Validation loss: 0.465\r",
      "Progress: 21.6% ... Training loss: 0.297 ... Validation loss: 0.462\r",
      "Progress: 21.6% ... Training loss: 0.308 ... Validation loss: 0.471\r",
      "Progress: 21.6% ... Training loss: 0.300 ... Validation loss: 0.470\r",
      "Progress: 21.6% ... Training loss: 0.333 ... Validation loss: 0.495\r",
      "Progress: 21.7% ... Training loss: 0.307 ... Validation loss: 0.476\r",
      "Progress: 21.7% ... Training loss: 0.304 ... Validation loss: 0.469\r",
      "Progress: 21.7% ... Training loss: 0.298 ... Validation loss: 0.467\r",
      "Progress: 21.7% ... Training loss: 0.298 ... Validation loss: 0.466\r",
      "Progress: 21.7% ... Training loss: 0.298 ... Validation loss: 0.467\r",
      "Progress: 21.7% ... Training loss: 0.298 ... Validation loss: 0.467\r",
      "Progress: 21.8% ... Training loss: 0.298 ... Validation loss: 0.469\r",
      "Progress: 21.8% ... Training loss: 0.311 ... Validation loss: 0.478\r",
      "Progress: 21.8% ... Training loss: 0.351 ... Validation loss: 0.528\r",
      "Progress: 21.8% ... Training loss: 0.378 ... Validation loss: 0.534\r",
      "Progress: 21.8% ... Training loss: 0.511 ... Validation loss: 0.689\r",
      "Progress: 21.9% ... Training loss: 0.456 ... Validation loss: 0.605\r",
      "Progress: 21.9% ... Training loss: 0.425 ... Validation loss: 0.601\r",
      "Progress: 21.9% ... Training loss: 0.447 ... Validation loss: 0.596\r",
      "Progress: 21.9% ... Training loss: 0.329 ... Validation loss: 0.502\r",
      "Progress: 21.9% ... Training loss: 0.298 ... Validation loss: 0.466\r",
      "Progress: 21.9% ... Training loss: 0.298 ... Validation loss: 0.466\r",
      "Progress: 22.0% ... Training loss: 0.304 ... Validation loss: 0.469\r",
      "Progress: 22.0% ... Training loss: 0.305 ... Validation loss: 0.472\r",
      "Progress: 22.0% ... Training loss: 0.320 ... Validation loss: 0.483\r",
      "Progress: 22.0% ... Training loss: 0.304 ... Validation loss: 0.468\r",
      "Progress: 22.0% ... Training loss: 0.368 ... Validation loss: 0.535\r",
      "Progress: 22.1% ... Training loss: 0.325 ... Validation loss: 0.485\r",
      "Progress: 22.1% ... Training loss: 0.319 ... Validation loss: 0.488\r",
      "Progress: 22.1% ... Training loss: 0.300 ... Validation loss: 0.465\r",
      "Progress: 22.1% ... Training loss: 0.306 ... Validation loss: 0.470\r",
      "Progress: 22.1% ... Training loss: 0.316 ... Validation loss: 0.482\r",
      "Progress: 22.1% ... Training loss: 0.297 ... Validation loss: 0.460\r",
      "Progress: 22.2% ... Training loss: 0.297 ... Validation loss: 0.459\r",
      "Progress: 22.2% ... Training loss: 0.298 ... Validation loss: 0.459\r",
      "Progress: 22.2% ... Training loss: 0.298 ... Validation loss: 0.459\r",
      "Progress: 22.2% ... Training loss: 0.306 ... Validation loss: 0.463\r",
      "Progress: 22.2% ... Training loss: 0.297 ... Validation loss: 0.459\r",
      "Progress: 22.3% ... Training loss: 0.297 ... Validation loss: 0.459\r",
      "Progress: 22.3% ... Training loss: 0.314 ... Validation loss: 0.469\r",
      "Progress: 22.3% ... Training loss: 0.325 ... Validation loss: 0.495\r",
      "Progress: 22.3% ... Training loss: 0.344 ... Validation loss: 0.491\r",
      "Progress: 22.3% ... Training loss: 0.313 ... Validation loss: 0.484\r",
      "Progress: 22.3% ... Training loss: 0.297 ... Validation loss: 0.457\r",
      "Progress: 22.4% ... Training loss: 0.301 ... Validation loss: 0.458\r",
      "Progress: 22.4% ... Training loss: 0.297 ... Validation loss: 0.464\r",
      "Progress: 22.4% ... Training loss: 0.303 ... Validation loss: 0.463\r",
      "Progress: 22.4% ... Training loss: 0.297 ... Validation loss: 0.465\r",
      "Progress: 22.4% ... Training loss: 0.300 ... Validation loss: 0.471\r",
      "Progress: 22.5% ... Training loss: 0.296 ... Validation loss: 0.462\r",
      "Progress: 22.5% ... Training loss: 0.303 ... Validation loss: 0.470\r",
      "Progress: 22.5% ... Training loss: 0.301 ... Validation loss: 0.467\r",
      "Progress: 22.5% ... Training loss: 0.334 ... Validation loss: 0.487\r",
      "Progress: 22.5% ... Training loss: 0.297 ... Validation loss: 0.464\r",
      "Progress: 22.5% ... Training loss: 0.318 ... Validation loss: 0.492\r",
      "Progress: 22.6% ... Training loss: 0.400 ... Validation loss: 0.540\r",
      "Progress: 22.6% ... Training loss: 0.353 ... Validation loss: 0.537\r",
      "Progress: 22.6% ... Training loss: 0.314 ... Validation loss: 0.472\r",
      "Progress: 22.6% ... Training loss: 0.307 ... Validation loss: 0.488\r",
      "Progress: 22.6% ... Training loss: 0.299 ... Validation loss: 0.463\r",
      "Progress: 22.7% ... Training loss: 0.299 ... Validation loss: 0.471\r",
      "Progress: 22.7% ... Training loss: 0.297 ... Validation loss: 0.465\r",
      "Progress: 22.7% ... Training loss: 0.301 ... Validation loss: 0.461\r",
      "Progress: 22.7% ... Training loss: 0.299 ... Validation loss: 0.462\r",
      "Progress: 22.7% ... Training loss: 0.305 ... Validation loss: 0.475\r",
      "Progress: 22.7% ... Training loss: 0.330 ... Validation loss: 0.483\r",
      "Progress: 22.8% ... Training loss: 0.308 ... Validation loss: 0.483\r",
      "Progress: 22.8% ... Training loss: 0.304 ... Validation loss: 0.467\r",
      "Progress: 22.8% ... Training loss: 0.325 ... Validation loss: 0.493\r",
      "Progress: 22.8% ... Training loss: 0.296 ... Validation loss: 0.460\r",
      "Progress: 22.8% ... Training loss: 0.315 ... Validation loss: 0.476\r",
      "Progress: 22.9% ... Training loss: 0.338 ... Validation loss: 0.493\r",
      "Progress: 22.9% ... Training loss: 0.299 ... Validation loss: 0.463\r",
      "Progress: 22.9% ... Training loss: 0.296 ... Validation loss: 0.461\r",
      "Progress: 22.9% ... Training loss: 0.298 ... Validation loss: 0.463\r",
      "Progress: 22.9% ... Training loss: 0.303 ... Validation loss: 0.474\r",
      "Progress: 22.9% ... Training loss: 0.296 ... Validation loss: 0.462\r",
      "Progress: 23.0% ... Training loss: 0.309 ... Validation loss: 0.472\r",
      "Progress: 23.0% ... Training loss: 0.309 ... Validation loss: 0.470\r",
      "Progress: 23.0% ... Training loss: 0.333 ... Validation loss: 0.487\r",
      "Progress: 23.0% ... Training loss: 0.337 ... Validation loss: 0.513\r",
      "Progress: 23.0% ... Training loss: 0.303 ... Validation loss: 0.465\r",
      "Progress: 23.1% ... Training loss: 0.314 ... Validation loss: 0.492\r",
      "Progress: 23.1% ... Training loss: 0.304 ... Validation loss: 0.467\r",
      "Progress: 23.1% ... Training loss: 0.303 ... Validation loss: 0.476\r",
      "Progress: 23.1% ... Training loss: 0.311 ... Validation loss: 0.474\r",
      "Progress: 23.1% ... Training loss: 0.336 ... Validation loss: 0.510\r",
      "Progress: 23.1% ... Training loss: 0.406 ... Validation loss: 0.560\r",
      "Progress: 23.2% ... Training loss: 0.405 ... Validation loss: 0.580\r",
      "Progress: 23.2% ... Training loss: 0.371 ... Validation loss: 0.530\r",
      "Progress: 23.2% ... Training loss: 0.366 ... Validation loss: 0.538\r",
      "Progress: 23.2% ... Training loss: 0.388 ... Validation loss: 0.542\r",
      "Progress: 23.2% ... Training loss: 0.335 ... Validation loss: 0.508\r",
      "Progress: 23.3% ... Training loss: 0.318 ... Validation loss: 0.478\r",
      "Progress: 23.3% ... Training loss: 0.302 ... Validation loss: 0.466\r",
      "Progress: 23.3% ... Training loss: 0.297 ... Validation loss: 0.462\r",
      "Progress: 23.3% ... Training loss: 0.303 ... Validation loss: 0.470\r",
      "Progress: 23.3% ... Training loss: 0.304 ... Validation loss: 0.467\r",
      "Progress: 23.3% ... Training loss: 0.302 ... Validation loss: 0.472\r",
      "Progress: 23.4% ... Training loss: 0.300 ... Validation loss: 0.466\r",
      "Progress: 23.4% ... Training loss: 0.305 ... Validation loss: 0.471\r",
      "Progress: 23.4% ... Training loss: 0.319 ... Validation loss: 0.485\r",
      "Progress: 23.4% ... Training loss: 0.308 ... Validation loss: 0.472\r",
      "Progress: 23.4% ... Training loss: 0.329 ... Validation loss: 0.492\r",
      "Progress: 23.5% ... Training loss: 0.324 ... Validation loss: 0.496\r",
      "Progress: 23.5% ... Training loss: 0.395 ... Validation loss: 0.555\r",
      "Progress: 23.5% ... Training loss: 0.428 ... Validation loss: 0.597\r",
      "Progress: 23.5% ... Training loss: 0.330 ... Validation loss: 0.491\r",
      "Progress: 23.5% ... Training loss: 0.306 ... Validation loss: 0.477\r",
      "Progress: 23.5% ... Training loss: 0.326 ... Validation loss: 0.492\r",
      "Progress: 23.6% ... Training loss: 0.333 ... Validation loss: 0.503\r",
      "Progress: 23.6% ... Training loss: 0.347 ... Validation loss: 0.510\r",
      "Progress: 23.6% ... Training loss: 0.381 ... Validation loss: 0.548\r",
      "Progress: 23.6% ... Training loss: 0.319 ... Validation loss: 0.486\r",
      "Progress: 23.6% ... Training loss: 0.333 ... Validation loss: 0.503\r",
      "Progress: 23.7% ... Training loss: 0.368 ... Validation loss: 0.535\r",
      "Progress: 23.7% ... Training loss: 0.314 ... Validation loss: 0.491\r",
      "Progress: 23.7% ... Training loss: 0.315 ... Validation loss: 0.485\r",
      "Progress: 23.7% ... Training loss: 0.333 ... Validation loss: 0.503\r",
      "Progress: 23.7% ... Training loss: 0.373 ... Validation loss: 0.535\r",
      "Progress: 23.7% ... Training loss: 0.297 ... Validation loss: 0.469\r",
      "Progress: 23.8% ... Training loss: 0.298 ... Validation loss: 0.471\r",
      "Progress: 23.8% ... Training loss: 0.298 ... Validation loss: 0.472\r",
      "Progress: 23.8% ... Training loss: 0.301 ... Validation loss: 0.474\r",
      "Progress: 23.8% ... Training loss: 0.297 ... Validation loss: 0.469\r",
      "Progress: 23.8% ... Training loss: 0.328 ... Validation loss: 0.498\r",
      "Progress: 23.9% ... Training loss: 0.305 ... Validation loss: 0.479\r",
      "Progress: 23.9% ... Training loss: 0.301 ... Validation loss: 0.474\r",
      "Progress: 23.9% ... Training loss: 0.302 ... Validation loss: 0.472\r",
      "Progress: 23.9% ... Training loss: 0.316 ... Validation loss: 0.488\r",
      "Progress: 23.9% ... Training loss: 0.320 ... Validation loss: 0.490\r",
      "Progress: 23.9% ... Training loss: 0.299 ... Validation loss: 0.471\r",
      "Progress: 24.0% ... Training loss: 0.328 ... Validation loss: 0.498\r",
      "Progress: 24.0% ... Training loss: 0.322 ... Validation loss: 0.492\r",
      "Progress: 24.0% ... Training loss: 0.309 ... Validation loss: 0.476\r",
      "Progress: 24.0% ... Training loss: 0.303 ... Validation loss: 0.474\r",
      "Progress: 24.0% ... Training loss: 0.297 ... Validation loss: 0.465\r",
      "Progress: 24.1% ... Training loss: 0.299 ... Validation loss: 0.468\r",
      "Progress: 24.1% ... Training loss: 0.296 ... Validation loss: 0.462\r",
      "Progress: 24.1% ... Training loss: 0.303 ... Validation loss: 0.471\r",
      "Progress: 24.1% ... Training loss: 0.304 ... Validation loss: 0.468\r",
      "Progress: 24.1% ... Training loss: 0.315 ... Validation loss: 0.483\r",
      "Progress: 24.1% ... Training loss: 0.303 ... Validation loss: 0.466\r",
      "Progress: 24.2% ... Training loss: 0.298 ... Validation loss: 0.465\r",
      "Progress: 24.2% ... Training loss: 0.299 ... Validation loss: 0.466\r",
      "Progress: 24.2% ... Training loss: 0.304 ... Validation loss: 0.472\r",
      "Progress: 24.2% ... Training loss: 0.310 ... Validation loss: 0.476\r",
      "Progress: 24.2% ... Training loss: 0.363 ... Validation loss: 0.533\r",
      "Progress: 24.3% ... Training loss: 0.359 ... Validation loss: 0.524\r",
      "Progress: 24.3% ... Training loss: 0.347 ... Validation loss: 0.516\r",
      "Progress: 24.3% ... Training loss: 0.343 ... Validation loss: 0.504\r",
      "Progress: 24.3% ... Training loss: 0.296 ... Validation loss: 0.460\r",
      "Progress: 24.3% ... Training loss: 0.303 ... Validation loss: 0.469\r",
      "Progress: 24.3% ... Training loss: 0.325 ... Validation loss: 0.479\r",
      "Progress: 24.4% ... Training loss: 0.302 ... Validation loss: 0.468\r",
      "Progress: 24.4% ... Training loss: 0.312 ... Validation loss: 0.469\r",
      "Progress: 24.4% ... Training loss: 0.303 ... Validation loss: 0.472\r",
      "Progress: 24.4% ... Training loss: 0.300 ... Validation loss: 0.464\r",
      "Progress: 24.4% ... Training loss: 0.295 ... Validation loss: 0.463\r",
      "Progress: 24.5% ... Training loss: 0.296 ... Validation loss: 0.461\r",
      "Progress: 24.5% ... Training loss: 0.299 ... Validation loss: 0.459\r",
      "Progress: 24.5% ... Training loss: 0.312 ... Validation loss: 0.482\r",
      "Progress: 24.5% ... Training loss: 0.301 ... Validation loss: 0.467\r",
      "Progress: 24.5% ... Training loss: 0.317 ... Validation loss: 0.489\r",
      "Progress: 24.5% ... Training loss: 0.345 ... Validation loss: 0.509\r",
      "Progress: 24.6% ... Training loss: 0.312 ... Validation loss: 0.483\r",
      "Progress: 24.6% ... Training loss: 0.313 ... Validation loss: 0.478\r",
      "Progress: 24.6% ... Training loss: 0.295 ... Validation loss: 0.462\r",
      "Progress: 24.6% ... Training loss: 0.295 ... Validation loss: 0.461\r",
      "Progress: 24.6% ... Training loss: 0.299 ... Validation loss: 0.466\r",
      "Progress: 24.7% ... Training loss: 0.297 ... Validation loss: 0.462\r",
      "Progress: 24.7% ... Training loss: 0.295 ... Validation loss: 0.460\r",
      "Progress: 24.7% ... Training loss: 0.296 ... Validation loss: 0.461\r",
      "Progress: 24.7% ... Training loss: 0.299 ... Validation loss: 0.464\r",
      "Progress: 24.7% ... Training loss: 0.296 ... Validation loss: 0.464\r",
      "Progress: 24.7% ... Training loss: 0.297 ... Validation loss: 0.464\r",
      "Progress: 24.8% ... Training loss: 0.300 ... Validation loss: 0.467\r",
      "Progress: 24.8% ... Training loss: 0.296 ... Validation loss: 0.462\r",
      "Progress: 24.8% ... Training loss: 0.297 ... Validation loss: 0.467\r",
      "Progress: 24.8% ... Training loss: 0.296 ... Validation loss: 0.465\r",
      "Progress: 24.8% ... Training loss: 0.319 ... Validation loss: 0.482\r",
      "Progress: 24.9% ... Training loss: 0.305 ... Validation loss: 0.474\r",
      "Progress: 24.9% ... Training loss: 0.300 ... Validation loss: 0.464\r",
      "Progress: 24.9% ... Training loss: 0.305 ... Validation loss: 0.469\r",
      "Progress: 24.9% ... Training loss: 0.300 ... Validation loss: 0.460\r",
      "Progress: 24.9% ... Training loss: 0.300 ... Validation loss: 0.459\r",
      "Progress: 24.9% ... Training loss: 0.314 ... Validation loss: 0.472\r",
      "Progress: 25.0% ... Training loss: 0.301 ... Validation loss: 0.460\r",
      "Progress: 25.0% ... Training loss: 0.306 ... Validation loss: 0.467\r",
      "Progress: 25.0% ... Training loss: 0.296 ... Validation loss: 0.458\r",
      "Progress: 25.0% ... Training loss: 0.303 ... Validation loss: 0.463\r",
      "Progress: 25.0% ... Training loss: 0.302 ... Validation loss: 0.456\r",
      "Progress: 25.1% ... Training loss: 0.297 ... Validation loss: 0.454\r",
      "Progress: 25.1% ... Training loss: 0.309 ... Validation loss: 0.464\r",
      "Progress: 25.1% ... Training loss: 0.305 ... Validation loss: 0.466\r",
      "Progress: 25.1% ... Training loss: 0.295 ... Validation loss: 0.457\r",
      "Progress: 25.1% ... Training loss: 0.297 ... Validation loss: 0.461\r",
      "Progress: 25.1% ... Training loss: 0.301 ... Validation loss: 0.460\r",
      "Progress: 25.2% ... Training loss: 0.311 ... Validation loss: 0.471\r",
      "Progress: 25.2% ... Training loss: 0.295 ... Validation loss: 0.458\r",
      "Progress: 25.2% ... Training loss: 0.296 ... Validation loss: 0.458\r",
      "Progress: 25.2% ... Training loss: 0.295 ... Validation loss: 0.458\r",
      "Progress: 25.2% ... Training loss: 0.309 ... Validation loss: 0.470\r",
      "Progress: 25.3% ... Training loss: 0.301 ... Validation loss: 0.460\r",
      "Progress: 25.3% ... Training loss: 0.314 ... Validation loss: 0.479\r",
      "Progress: 25.3% ... Training loss: 0.319 ... Validation loss: 0.470\r",
      "Progress: 25.3% ... Training loss: 0.325 ... Validation loss: 0.490\r",
      "Progress: 25.3% ... Training loss: 0.403 ... Validation loss: 0.548\r",
      "Progress: 25.3% ... Training loss: 0.460 ... Validation loss: 0.631\r",
      "Progress: 25.4% ... Training loss: 0.398 ... Validation loss: 0.552\r",
      "Progress: 25.4% ... Training loss: 0.311 ... Validation loss: 0.475\r",
      "Progress: 25.4% ... Training loss: 0.302 ... Validation loss: 0.466\r",
      "Progress: 25.4% ... Training loss: 0.357 ... Validation loss: 0.521\r",
      "Progress: 25.4% ... Training loss: 0.406 ... Validation loss: 0.564\r",
      "Progress: 25.5% ... Training loss: 0.381 ... Validation loss: 0.551\r",
      "Progress: 25.5% ... Training loss: 0.365 ... Validation loss: 0.523\r",
      "Progress: 25.5% ... Training loss: 0.524 ... Validation loss: 0.695\r",
      "Progress: 25.5% ... Training loss: 0.466 ... Validation loss: 0.622\r",
      "Progress: 25.5% ... Training loss: 0.409 ... Validation loss: 0.572\r",
      "Progress: 25.5% ... Training loss: 0.382 ... Validation loss: 0.542\r",
      "Progress: 25.6% ... Training loss: 0.433 ... Validation loss: 0.600\r",
      "Progress: 25.6% ... Training loss: 0.386 ... Validation loss: 0.543\r",
      "Progress: 25.6% ... Training loss: 0.395 ... Validation loss: 0.559\r",
      "Progress: 25.6% ... Training loss: 0.418 ... Validation loss: 0.572\r",
      "Progress: 25.6% ... Training loss: 0.303 ... Validation loss: 0.471\r",
      "Progress: 25.7% ... Training loss: 0.298 ... Validation loss: 0.466\r",
      "Progress: 25.7% ... Training loss: 0.311 ... Validation loss: 0.480\r",
      "Progress: 25.7% ... Training loss: 0.310 ... Validation loss: 0.474\r",
      "Progress: 25.7% ... Training loss: 0.296 ... Validation loss: 0.464\r",
      "Progress: 25.7% ... Training loss: 0.299 ... Validation loss: 0.466\r",
      "Progress: 25.7% ... Training loss: 0.296 ... Validation loss: 0.461\r",
      "Progress: 25.8% ... Training loss: 0.296 ... Validation loss: 0.461\r",
      "Progress: 25.8% ... Training loss: 0.301 ... Validation loss: 0.465\r",
      "Progress: 25.8% ... Training loss: 0.314 ... Validation loss: 0.476\r",
      "Progress: 25.8% ... Training loss: 0.299 ... Validation loss: 0.466\r",
      "Progress: 25.8% ... Training loss: 0.296 ... Validation loss: 0.463\r",
      "Progress: 25.9% ... Training loss: 0.295 ... Validation loss: 0.464\r",
      "Progress: 25.9% ... Training loss: 0.302 ... Validation loss: 0.469\r",
      "Progress: 25.9% ... Training loss: 0.296 ... Validation loss: 0.464\r",
      "Progress: 25.9% ... Training loss: 0.295 ... Validation loss: 0.463\r",
      "Progress: 25.9% ... Training loss: 0.306 ... Validation loss: 0.475\r",
      "Progress: 25.9% ... Training loss: 0.397 ... Validation loss: 0.563\r",
      "Progress: 26.0% ... Training loss: 0.394 ... Validation loss: 0.561\r",
      "Progress: 26.0% ... Training loss: 0.406 ... Validation loss: 0.574\r",
      "Progress: 26.0% ... Training loss: 0.330 ... Validation loss: 0.499\r",
      "Progress: 26.0% ... Training loss: 0.354 ... Validation loss: 0.523\r",
      "Progress: 26.0% ... Training loss: 0.295 ... Validation loss: 0.462\r",
      "Progress: 26.1% ... Training loss: 0.295 ... Validation loss: 0.464\r",
      "Progress: 26.1% ... Training loss: 0.295 ... Validation loss: 0.462\r",
      "Progress: 26.1% ... Training loss: 0.298 ... Validation loss: 0.468\r",
      "Progress: 26.1% ... Training loss: 0.295 ... Validation loss: 0.467\r",
      "Progress: 26.1% ... Training loss: 0.298 ... Validation loss: 0.466\r",
      "Progress: 26.1% ... Training loss: 0.317 ... Validation loss: 0.482\r",
      "Progress: 26.2% ... Training loss: 0.295 ... Validation loss: 0.463\r",
      "Progress: 26.2% ... Training loss: 0.301 ... Validation loss: 0.464\r",
      "Progress: 26.2% ... Training loss: 0.295 ... Validation loss: 0.459\r",
      "Progress: 26.2% ... Training loss: 0.294 ... Validation loss: 0.459\r",
      "Progress: 26.2% ... Training loss: 0.304 ... Validation loss: 0.472\r",
      "Progress: 26.3% ... Training loss: 0.294 ... Validation loss: 0.461\r",
      "Progress: 26.3% ... Training loss: 0.294 ... Validation loss: 0.463\r",
      "Progress: 26.3% ... Training loss: 0.305 ... Validation loss: 0.467\r",
      "Progress: 26.3% ... Training loss: 0.317 ... Validation loss: 0.486\r",
      "Progress: 26.3% ... Training loss: 0.402 ... Validation loss: 0.550\r",
      "Progress: 26.3% ... Training loss: 0.428 ... Validation loss: 0.601\r",
      "Progress: 26.4% ... Training loss: 0.381 ... Validation loss: 0.526\r",
      "Progress: 26.4% ... Training loss: 0.429 ... Validation loss: 0.596\r",
      "Progress: 26.4% ... Training loss: 0.481 ... Validation loss: 0.627\r",
      "Progress: 26.4% ... Training loss: 0.443 ... Validation loss: 0.608\r",
      "Progress: 26.4% ... Training loss: 0.356 ... Validation loss: 0.515\r",
      "Progress: 26.5% ... Training loss: 0.305 ... Validation loss: 0.470\r",
      "Progress: 26.5% ... Training loss: 0.312 ... Validation loss: 0.473\r",
      "Progress: 26.5% ... Training loss: 0.299 ... Validation loss: 0.466\r",
      "Progress: 26.5% ... Training loss: 0.296 ... Validation loss: 0.465\r",
      "Progress: 26.5% ... Training loss: 0.316 ... Validation loss: 0.482\r",
      "Progress: 26.5% ... Training loss: 0.307 ... Validation loss: 0.477\r",
      "Progress: 26.6% ... Training loss: 0.315 ... Validation loss: 0.474\r",
      "Progress: 26.6% ... Training loss: 0.313 ... Validation loss: 0.484\r",
      "Progress: 26.6% ... Training loss: 0.312 ... Validation loss: 0.473\r",
      "Progress: 26.6% ... Training loss: 0.330 ... Validation loss: 0.504\r",
      "Progress: 26.6% ... Training loss: 0.294 ... Validation loss: 0.463\r",
      "Progress: 26.7% ... Training loss: 0.319 ... Validation loss: 0.480\r",
      "Progress: 26.7% ... Training loss: 0.312 ... Validation loss: 0.482\r",
      "Progress: 26.7% ... Training loss: 0.399 ... Validation loss: 0.539\r",
      "Progress: 26.7% ... Training loss: 0.327 ... Validation loss: 0.496\r",
      "Progress: 26.7% ... Training loss: 0.328 ... Validation loss: 0.477\r",
      "Progress: 26.7% ... Training loss: 0.341 ... Validation loss: 0.510\r",
      "Progress: 26.8% ... Training loss: 0.354 ... Validation loss: 0.510\r",
      "Progress: 26.8% ... Training loss: 0.382 ... Validation loss: 0.550\r",
      "Progress: 26.8% ... Training loss: 0.322 ... Validation loss: 0.487\r",
      "Progress: 26.8% ... Training loss: 0.349 ... Validation loss: 0.518\r",
      "Progress: 26.8% ... Training loss: 0.318 ... Validation loss: 0.490\r",
      "Progress: 26.9% ... Training loss: 0.295 ... Validation loss: 0.465\r",
      "Progress: 26.9% ... Training loss: 0.294 ... Validation loss: 0.464\r",
      "Progress: 26.9% ... Training loss: 0.315 ... Validation loss: 0.477\r",
      "Progress: 26.9% ... Training loss: 0.297 ... Validation loss: 0.463\r",
      "Progress: 26.9% ... Training loss: 0.294 ... Validation loss: 0.460\r",
      "Progress: 26.9% ... Training loss: 0.301 ... Validation loss: 0.471\r",
      "Progress: 27.0% ... Training loss: 0.295 ... Validation loss: 0.462\r",
      "Progress: 27.0% ... Training loss: 0.300 ... Validation loss: 0.472\r",
      "Progress: 27.0% ... Training loss: 0.297 ... Validation loss: 0.469\r",
      "Progress: 27.0% ... Training loss: 0.300 ... Validation loss: 0.474\r",
      "Progress: 27.0% ... Training loss: 0.304 ... Validation loss: 0.472\r",
      "Progress: 27.1% ... Training loss: 0.313 ... Validation loss: 0.477\r",
      "Progress: 27.1% ... Training loss: 0.296 ... Validation loss: 0.469\r",
      "Progress: 27.1% ... Training loss: 0.294 ... Validation loss: 0.463\r",
      "Progress: 27.1% ... Training loss: 0.321 ... Validation loss: 0.500\r",
      "Progress: 27.1% ... Training loss: 0.296 ... Validation loss: 0.469\r",
      "Progress: 27.1% ... Training loss: 0.298 ... Validation loss: 0.469\r",
      "Progress: 27.2% ... Training loss: 0.297 ... Validation loss: 0.469\r",
      "Progress: 27.2% ... Training loss: 0.294 ... Validation loss: 0.465\r",
      "Progress: 27.2% ... Training loss: 0.323 ... Validation loss: 0.504\r",
      "Progress: 27.2% ... Training loss: 0.354 ... Validation loss: 0.507\r",
      "Progress: 27.2% ... Training loss: 0.318 ... Validation loss: 0.494\r",
      "Progress: 27.3% ... Training loss: 0.322 ... Validation loss: 0.480\r",
      "Progress: 27.3% ... Training loss: 0.306 ... Validation loss: 0.479\r",
      "Progress: 27.3% ... Training loss: 0.313 ... Validation loss: 0.467\r",
      "Progress: 27.3% ... Training loss: 0.297 ... Validation loss: 0.467\r",
      "Progress: 27.3% ... Training loss: 0.339 ... Validation loss: 0.492\r",
      "Progress: 27.3% ... Training loss: 0.403 ... Validation loss: 0.586\r",
      "Progress: 27.4% ... Training loss: 0.412 ... Validation loss: 0.555\r",
      "Progress: 27.4% ... Training loss: 0.464 ... Validation loss: 0.642\r",
      "Progress: 27.4% ... Training loss: 0.395 ... Validation loss: 0.557\r",
      "Progress: 27.4% ... Training loss: 0.369 ... Validation loss: 0.543\r",
      "Progress: 27.4% ... Training loss: 0.307 ... Validation loss: 0.470\r",
      "Progress: 27.5% ... Training loss: 0.301 ... Validation loss: 0.472\r",
      "Progress: 27.5% ... Training loss: 0.302 ... Validation loss: 0.466\r",
      "Progress: 27.5% ... Training loss: 0.297 ... Validation loss: 0.462\r",
      "Progress: 27.5% ... Training loss: 0.304 ... Validation loss: 0.469\r",
      "Progress: 27.5% ... Training loss: 0.319 ... Validation loss: 0.489\r",
      "Progress: 27.5% ... Training loss: 0.368 ... Validation loss: 0.530\r",
      "Progress: 27.6% ... Training loss: 0.342 ... Validation loss: 0.511\r",
      "Progress: 27.6% ... Training loss: 0.316 ... Validation loss: 0.488\r",
      "Progress: 27.6% ... Training loss: 0.298 ... Validation loss: 0.468\r",
      "Progress: 27.6% ... Training loss: 0.299 ... Validation loss: 0.468\r",
      "Progress: 27.6% ... Training loss: 0.336 ... Validation loss: 0.506\r",
      "Progress: 27.7% ... Training loss: 0.296 ... Validation loss: 0.469\r",
      "Progress: 27.7% ... Training loss: 0.294 ... Validation loss: 0.461\r",
      "Progress: 27.7% ... Training loss: 0.300 ... Validation loss: 0.467\r",
      "Progress: 27.7% ... Training loss: 0.305 ... Validation loss: 0.473\r",
      "Progress: 27.7% ... Training loss: 0.294 ... Validation loss: 0.466\r",
      "Progress: 27.7% ... Training loss: 0.294 ... Validation loss: 0.467\r",
      "Progress: 27.8% ... Training loss: 0.329 ... Validation loss: 0.499\r",
      "Progress: 27.8% ... Training loss: 0.338 ... Validation loss: 0.515\r",
      "Progress: 27.8% ... Training loss: 0.321 ... Validation loss: 0.489\r",
      "Progress: 27.8% ... Training loss: 0.315 ... Validation loss: 0.490\r",
      "Progress: 27.8% ... Training loss: 0.297 ... Validation loss: 0.468\r",
      "Progress: 27.9% ... Training loss: 0.308 ... Validation loss: 0.478\r",
      "Progress: 27.9% ... Training loss: 0.293 ... Validation loss: 0.466\r",
      "Progress: 27.9% ... Training loss: 0.293 ... Validation loss: 0.466\r",
      "Progress: 27.9% ... Training loss: 0.294 ... Validation loss: 0.467\r",
      "Progress: 27.9% ... Training loss: 0.314 ... Validation loss: 0.484\r",
      "Progress: 27.9% ... Training loss: 0.293 ... Validation loss: 0.462\r",
      "Progress: 28.0% ... Training loss: 0.296 ... Validation loss: 0.468\r",
      "Progress: 28.0% ... Training loss: 0.340 ... Validation loss: 0.503\r",
      "Progress: 28.0% ... Training loss: 0.358 ... Validation loss: 0.527\r",
      "Progress: 28.0% ... Training loss: 0.350 ... Validation loss: 0.518\r",
      "Progress: 28.0% ... Training loss: 0.332 ... Validation loss: 0.500\r",
      "Progress: 28.1% ... Training loss: 0.417 ... Validation loss: 0.580\r",
      "Progress: 28.1% ... Training loss: 0.403 ... Validation loss: 0.568\r",
      "Progress: 28.1% ... Training loss: 0.341 ... Validation loss: 0.510\r",
      "Progress: 28.1% ... Training loss: 0.327 ... Validation loss: 0.495\r",
      "Progress: 28.1% ... Training loss: 0.297 ... Validation loss: 0.465\r",
      "Progress: 28.1% ... Training loss: 0.294 ... Validation loss: 0.463\r",
      "Progress: 28.2% ... Training loss: 0.310 ... Validation loss: 0.479\r",
      "Progress: 28.2% ... Training loss: 0.293 ... Validation loss: 0.462\r",
      "Progress: 28.2% ... Training loss: 0.303 ... Validation loss: 0.474\r",
      "Progress: 28.2% ... Training loss: 0.303 ... Validation loss: 0.473\r",
      "Progress: 28.2% ... Training loss: 0.294 ... Validation loss: 0.466\r",
      "Progress: 28.3% ... Training loss: 0.310 ... Validation loss: 0.483\r",
      "Progress: 28.3% ... Training loss: 0.296 ... Validation loss: 0.469\r",
      "Progress: 28.3% ... Training loss: 0.293 ... Validation loss: 0.466\r",
      "Progress: 28.3% ... Training loss: 0.294 ... Validation loss: 0.467\r",
      "Progress: 28.3% ... Training loss: 0.294 ... Validation loss: 0.467\r",
      "Progress: 28.3% ... Training loss: 0.306 ... Validation loss: 0.474\r",
      "Progress: 28.4% ... Training loss: 0.328 ... Validation loss: 0.502\r",
      "Progress: 28.4% ... Training loss: 0.304 ... Validation loss: 0.471\r",
      "Progress: 28.4% ... Training loss: 0.305 ... Validation loss: 0.479\r",
      "Progress: 28.4% ... Training loss: 0.298 ... Validation loss: 0.465\r",
      "Progress: 28.4% ... Training loss: 0.294 ... Validation loss: 0.461\r",
      "Progress: 28.5% ... Training loss: 0.292 ... Validation loss: 0.462\r",
      "Progress: 28.5% ... Training loss: 0.297 ... Validation loss: 0.468\r",
      "Progress: 28.5% ... Training loss: 0.293 ... Validation loss: 0.465\r",
      "Progress: 28.5% ... Training loss: 0.295 ... Validation loss: 0.464\r",
      "Progress: 28.5% ... Training loss: 0.294 ... Validation loss: 0.464\r",
      "Progress: 28.5% ... Training loss: 0.295 ... Validation loss: 0.467\r",
      "Progress: 28.6% ... Training loss: 0.302 ... Validation loss: 0.471\r",
      "Progress: 28.6% ... Training loss: 0.309 ... Validation loss: 0.477\r",
      "Progress: 28.6% ... Training loss: 0.297 ... Validation loss: 0.467\r",
      "Progress: 28.6% ... Training loss: 0.330 ... Validation loss: 0.500\r",
      "Progress: 28.6% ... Training loss: 0.293 ... Validation loss: 0.463\r",
      "Progress: 28.7% ... Training loss: 0.327 ... Validation loss: 0.493\r",
      "Progress: 28.7% ... Training loss: 0.324 ... Validation loss: 0.492\r",
      "Progress: 28.7% ... Training loss: 0.294 ... Validation loss: 0.466\r",
      "Progress: 28.7% ... Training loss: 0.296 ... Validation loss: 0.467\r",
      "Progress: 28.7% ... Training loss: 0.302 ... Validation loss: 0.472\r",
      "Progress: 28.7% ... Training loss: 0.292 ... Validation loss: 0.462\r",
      "Progress: 28.8% ... Training loss: 0.297 ... Validation loss: 0.467\r",
      "Progress: 28.8% ... Training loss: 0.311 ... Validation loss: 0.484\r",
      "Progress: 28.8% ... Training loss: 0.292 ... Validation loss: 0.461\r",
      "Progress: 28.8% ... Training loss: 0.293 ... Validation loss: 0.462\r",
      "Progress: 28.8% ... Training loss: 0.293 ... Validation loss: 0.459\r",
      "Progress: 28.9% ... Training loss: 0.293 ... Validation loss: 0.460\r",
      "Progress: 28.9% ... Training loss: 0.293 ... Validation loss: 0.461\r",
      "Progress: 28.9% ... Training loss: 0.294 ... Validation loss: 0.464\r",
      "Progress: 28.9% ... Training loss: 0.296 ... Validation loss: 0.465\r",
      "Progress: 28.9% ... Training loss: 0.309 ... Validation loss: 0.482\r",
      "Progress: 28.9% ... Training loss: 0.292 ... Validation loss: 0.464\r",
      "Progress: 29.0% ... Training loss: 0.294 ... Validation loss: 0.465\r",
      "Progress: 29.0% ... Training loss: 0.292 ... Validation loss: 0.463\r",
      "Progress: 29.0% ... Training loss: 0.301 ... Validation loss: 0.471\r",
      "Progress: 29.0% ... Training loss: 0.292 ... Validation loss: 0.461\r",
      "Progress: 29.0% ... Training loss: 0.293 ... Validation loss: 0.462\r",
      "Progress: 29.1% ... Training loss: 0.295 ... Validation loss: 0.462\r",
      "Progress: 29.1% ... Training loss: 0.292 ... Validation loss: 0.459\r",
      "Progress: 29.1% ... Training loss: 0.292 ... Validation loss: 0.458\r",
      "Progress: 29.1% ... Training loss: 0.297 ... Validation loss: 0.463\r",
      "Progress: 29.1% ... Training loss: 0.329 ... Validation loss: 0.492\r",
      "Progress: 29.1% ... Training loss: 0.296 ... Validation loss: 0.459\r",
      "Progress: 29.2% ... Training loss: 0.293 ... Validation loss: 0.459\r",
      "Progress: 29.2% ... Training loss: 0.306 ... Validation loss: 0.474\r",
      "Progress: 29.2% ... Training loss: 0.292 ... Validation loss: 0.459\r",
      "Progress: 29.2% ... Training loss: 0.300 ... Validation loss: 0.466\r",
      "Progress: 29.2% ... Training loss: 0.295 ... Validation loss: 0.460\r",
      "Progress: 29.3% ... Training loss: 0.304 ... Validation loss: 0.473\r",
      "Progress: 29.3% ... Training loss: 0.293 ... Validation loss: 0.463\r",
      "Progress: 29.3% ... Training loss: 0.294 ... Validation loss: 0.464\r",
      "Progress: 29.3% ... Training loss: 0.301 ... Validation loss: 0.471\r",
      "Progress: 29.3% ... Training loss: 0.293 ... Validation loss: 0.462\r",
      "Progress: 29.3% ... Training loss: 0.304 ... Validation loss: 0.474\r",
      "Progress: 29.4% ... Training loss: 0.295 ... Validation loss: 0.464\r",
      "Progress: 29.4% ... Training loss: 0.299 ... Validation loss: 0.468\r",
      "Progress: 29.4% ... Training loss: 0.296 ... Validation loss: 0.466\r",
      "Progress: 29.4% ... Training loss: 0.325 ... Validation loss: 0.493\r",
      "Progress: 29.4% ... Training loss: 0.351 ... Validation loss: 0.519\r",
      "Progress: 29.5% ... Training loss: 0.348 ... Validation loss: 0.516\r",
      "Progress: 29.5% ... Training loss: 0.315 ... Validation loss: 0.485\r",
      "Progress: 29.5% ... Training loss: 0.292 ... Validation loss: 0.460\r",
      "Progress: 29.5% ... Training loss: 0.294 ... Validation loss: 0.464\r",
      "Progress: 29.5% ... Training loss: 0.292 ... Validation loss: 0.466\r",
      "Progress: 29.5% ... Training loss: 0.297 ... Validation loss: 0.469\r",
      "Progress: 29.6% ... Training loss: 0.294 ... Validation loss: 0.467\r",
      "Progress: 29.6% ... Training loss: 0.296 ... Validation loss: 0.466\r",
      "Progress: 29.6% ... Training loss: 0.297 ... Validation loss: 0.471\r",
      "Progress: 29.6% ... Training loss: 0.294 ... Validation loss: 0.465\r",
      "Progress: 29.6% ... Training loss: 0.306 ... Validation loss: 0.476\r",
      "Progress: 29.7% ... Training loss: 0.317 ... Validation loss: 0.488\r",
      "Progress: 29.7% ... Training loss: 0.315 ... Validation loss: 0.482\r",
      "Progress: 29.7% ... Training loss: 0.292 ... Validation loss: 0.467\r",
      "Progress: 29.7% ... Training loss: 0.291 ... Validation loss: 0.465\r",
      "Progress: 29.7% ... Training loss: 0.291 ... Validation loss: 0.463\r",
      "Progress: 29.7% ... Training loss: 0.302 ... Validation loss: 0.473\r",
      "Progress: 29.8% ... Training loss: 0.319 ... Validation loss: 0.496\r",
      "Progress: 29.8% ... Training loss: 0.408 ... Validation loss: 0.573\r",
      "Progress: 29.8% ... Training loss: 0.430 ... Validation loss: 0.606\r",
      "Progress: 29.8% ... Training loss: 0.449 ... Validation loss: 0.612\r",
      "Progress: 29.8% ... Training loss: 0.374 ... Validation loss: 0.546\r",
      "Progress: 29.9% ... Training loss: 0.332 ... Validation loss: 0.499\r",
      "Progress: 29.9% ... Training loss: 0.382 ... Validation loss: 0.551\r",
      "Progress: 29.9% ... Training loss: 0.318 ... Validation loss: 0.483\r",
      "Progress: 29.9% ... Training loss: 0.314 ... Validation loss: 0.483\r",
      "Progress: 29.9% ... Training loss: 0.346 ... Validation loss: 0.509\r",
      "Progress: 29.9% ... Training loss: 0.345 ... Validation loss: 0.512\r",
      "Progress: 30.0% ... Training loss: 0.307 ... Validation loss: 0.473\r",
      "Progress: 30.0% ... Training loss: 0.323 ... Validation loss: 0.487\r",
      "Progress: 30.0% ... Training loss: 0.340 ... Validation loss: 0.503\r",
      "Progress: 30.0% ... Training loss: 0.302 ... Validation loss: 0.467\r",
      "Progress: 30.0% ... Training loss: 0.291 ... Validation loss: 0.458\r",
      "Progress: 30.1% ... Training loss: 0.291 ... Validation loss: 0.459\r",
      "Progress: 30.1% ... Training loss: 0.301 ... Validation loss: 0.469\r",
      "Progress: 30.1% ... Training loss: 0.350 ... Validation loss: 0.511\r",
      "Progress: 30.1% ... Training loss: 0.308 ... Validation loss: 0.473\r",
      "Progress: 30.1% ... Training loss: 0.333 ... Validation loss: 0.500\r",
      "Progress: 30.1% ... Training loss: 0.369 ... Validation loss: 0.529\r",
      "Progress: 30.2% ... Training loss: 0.355 ... Validation loss: 0.536\r",
      "Progress: 30.2% ... Training loss: 0.362 ... Validation loss: 0.523\r",
      "Progress: 30.2% ... Training loss: 0.399 ... Validation loss: 0.575\r",
      "Progress: 30.2% ... Training loss: 0.334 ... Validation loss: 0.496\r",
      "Progress: 30.2% ... Training loss: 0.296 ... Validation loss: 0.469\r",
      "Progress: 30.3% ... Training loss: 0.305 ... Validation loss: 0.474\r",
      "Progress: 30.3% ... Training loss: 0.295 ... Validation loss: 0.469\r",
      "Progress: 30.3% ... Training loss: 0.294 ... Validation loss: 0.465\r",
      "Progress: 30.3% ... Training loss: 0.291 ... Validation loss: 0.461\r",
      "Progress: 30.3% ... Training loss: 0.291 ... Validation loss: 0.461\r",
      "Progress: 30.3% ... Training loss: 0.291 ... Validation loss: 0.459\r",
      "Progress: 30.4% ... Training loss: 0.293 ... Validation loss: 0.461\r",
      "Progress: 30.4% ... Training loss: 0.326 ... Validation loss: 0.494\r",
      "Progress: 30.4% ... Training loss: 0.317 ... Validation loss: 0.491\r",
      "Progress: 30.4% ... Training loss: 0.337 ... Validation loss: 0.502\r",
      "Progress: 30.4% ... Training loss: 0.338 ... Validation loss: 0.515\r",
      "Progress: 30.5% ... Training loss: 0.296 ... Validation loss: 0.468\r",
      "Progress: 30.5% ... Training loss: 0.296 ... Validation loss: 0.468\r",
      "Progress: 30.5% ... Training loss: 0.293 ... Validation loss: 0.465\r",
      "Progress: 30.5% ... Training loss: 0.292 ... Validation loss: 0.464\r",
      "Progress: 30.5% ... Training loss: 0.342 ... Validation loss: 0.505\r",
      "Progress: 30.5% ... Training loss: 0.353 ... Validation loss: 0.521\r",
      "Progress: 30.6% ... Training loss: 0.329 ... Validation loss: 0.503\r",
      "Progress: 30.6% ... Training loss: 0.333 ... Validation loss: 0.501\r",
      "Progress: 30.6% ... Training loss: 0.330 ... Validation loss: 0.500\r",
      "Progress: 30.6% ... Training loss: 0.368 ... Validation loss: 0.539\r",
      "Progress: 30.6% ... Training loss: 0.321 ... Validation loss: 0.491\r",
      "Progress: 30.7% ... Training loss: 0.317 ... Validation loss: 0.488\r",
      "Progress: 30.7% ... Training loss: 0.294 ... Validation loss: 0.465\r",
      "Progress: 30.7% ... Training loss: 0.291 ... Validation loss: 0.463\r",
      "Progress: 30.7% ... Training loss: 0.292 ... Validation loss: 0.465\r",
      "Progress: 30.7% ... Training loss: 0.292 ... Validation loss: 0.466\r",
      "Progress: 30.7% ... Training loss: 0.302 ... Validation loss: 0.471\r",
      "Progress: 30.8% ... Training loss: 0.293 ... Validation loss: 0.459\r",
      "Progress: 30.8% ... Training loss: 0.293 ... Validation loss: 0.464\r",
      "Progress: 30.8% ... Training loss: 0.309 ... Validation loss: 0.476\r",
      "Progress: 30.8% ... Training loss: 0.371 ... Validation loss: 0.543\r",
      "Progress: 30.8% ... Training loss: 0.406 ... Validation loss: 0.562\r",
      "Progress: 30.9% ... Training loss: 0.365 ... Validation loss: 0.533\r",
      "Progress: 30.9% ... Training loss: 0.417 ... Validation loss: 0.572\r",
      "Progress: 30.9% ... Training loss: 0.398 ... Validation loss: 0.562\r",
      "Progress: 30.9% ... Training loss: 0.338 ... Validation loss: 0.508\r",
      "Progress: 30.9% ... Training loss: 0.329 ... Validation loss: 0.494\r",
      "Progress: 30.9% ... Training loss: 0.341 ... Validation loss: 0.512\r",
      "Progress: 31.0% ... Training loss: 0.291 ... Validation loss: 0.461\r",
      "Progress: 31.0% ... Training loss: 0.298 ... Validation loss: 0.466\r",
      "Progress: 31.0% ... Training loss: 0.311 ... Validation loss: 0.477\r",
      "Progress: 31.0% ... Training loss: 0.292 ... Validation loss: 0.461\r",
      "Progress: 31.0% ... Training loss: 0.290 ... Validation loss: 0.460\r",
      "Progress: 31.1% ... Training loss: 0.298 ... Validation loss: 0.466\r",
      "Progress: 31.1% ... Training loss: 0.290 ... Validation loss: 0.461\r",
      "Progress: 31.1% ... Training loss: 0.313 ... Validation loss: 0.479\r",
      "Progress: 31.1% ... Training loss: 0.350 ... Validation loss: 0.519\r",
      "Progress: 31.1% ... Training loss: 0.360 ... Validation loss: 0.517\r",
      "Progress: 31.1% ... Training loss: 0.342 ... Validation loss: 0.514\r",
      "Progress: 31.2% ... Training loss: 0.410 ... Validation loss: 0.575\r",
      "Progress: 31.2% ... Training loss: 0.350 ... Validation loss: 0.524\r",
      "Progress: 31.2% ... Training loss: 0.321 ... Validation loss: 0.485\r",
      "Progress: 31.2% ... Training loss: 0.294 ... Validation loss: 0.465\r",
      "Progress: 31.2% ... Training loss: 0.298 ... Validation loss: 0.469\r",
      "Progress: 31.3% ... Training loss: 0.311 ... Validation loss: 0.474\r",
      "Progress: 31.3% ... Training loss: 0.292 ... Validation loss: 0.459\r",
      "Progress: 31.3% ... Training loss: 0.292 ... Validation loss: 0.458\r",
      "Progress: 31.3% ... Training loss: 0.292 ... Validation loss: 0.459\r",
      "Progress: 31.3% ... Training loss: 0.306 ... Validation loss: 0.471\r",
      "Progress: 31.3% ... Training loss: 0.341 ... Validation loss: 0.510\r",
      "Progress: 31.4% ... Training loss: 0.312 ... Validation loss: 0.483\r",
      "Progress: 31.4% ... Training loss: 0.293 ... Validation loss: 0.461\r",
      "Progress: 31.4% ... Training loss: 0.289 ... Validation loss: 0.457\r",
      "Progress: 31.4% ... Training loss: 0.290 ... Validation loss: 0.460\r",
      "Progress: 31.4% ... Training loss: 0.307 ... Validation loss: 0.479\r",
      "Progress: 31.5% ... Training loss: 0.293 ... Validation loss: 0.466\r",
      "Progress: 31.5% ... Training loss: 0.314 ... Validation loss: 0.487\r",
      "Progress: 31.5% ... Training loss: 0.320 ... Validation loss: 0.489\r",
      "Progress: 31.5% ... Training loss: 0.294 ... Validation loss: 0.465\r",
      "Progress: 31.5% ... Training loss: 0.295 ... Validation loss: 0.464\r",
      "Progress: 31.5% ... Training loss: 0.310 ... Validation loss: 0.480\r",
      "Progress: 31.6% ... Training loss: 0.318 ... Validation loss: 0.481\r",
      "Progress: 31.6% ... Training loss: 0.321 ... Validation loss: 0.486\r",
      "Progress: 31.6% ... Training loss: 0.293 ... Validation loss: 0.464\r",
      "Progress: 31.6% ... Training loss: 0.290 ... Validation loss: 0.461\r",
      "Progress: 31.6% ... Training loss: 0.293 ... Validation loss: 0.467\r",
      "Progress: 31.7% ... Training loss: 0.371 ... Validation loss: 0.532\r",
      "Progress: 31.7% ... Training loss: 0.329 ... Validation loss: 0.510\r",
      "Progress: 31.7% ... Training loss: 0.343 ... Validation loss: 0.508\r",
      "Progress: 31.7% ... Training loss: 0.346 ... Validation loss: 0.519\r",
      "Progress: 31.7% ... Training loss: 0.293 ... Validation loss: 0.460\r",
      "Progress: 31.7% ... Training loss: 0.293 ... Validation loss: 0.462\r",
      "Progress: 31.8% ... Training loss: 0.298 ... Validation loss: 0.466\r",
      "Progress: 31.8% ... Training loss: 0.294 ... Validation loss: 0.461\r",
      "Progress: 31.8% ... Training loss: 0.290 ... Validation loss: 0.455\r",
      "Progress: 31.8% ... Training loss: 0.296 ... Validation loss: 0.458\r",
      "Progress: 31.8% ... Training loss: 0.304 ... Validation loss: 0.470\r",
      "Progress: 31.9% ... Training loss: 0.321 ... Validation loss: 0.482\r",
      "Progress: 31.9% ... Training loss: 0.421 ... Validation loss: 0.592\r",
      "Progress: 31.9% ... Training loss: 0.404 ... Validation loss: 0.553\r",
      "Progress: 31.9% ... Training loss: 0.311 ... Validation loss: 0.480\r",
      "Progress: 31.9% ... Training loss: 0.319 ... Validation loss: 0.473\r",
      "Progress: 31.9% ... Training loss: 0.318 ... Validation loss: 0.489\r",
      "Progress: 32.0% ... Training loss: 0.289 ... Validation loss: 0.458\r",
      "Progress: 32.0% ... Training loss: 0.292 ... Validation loss: 0.457\r",
      "Progress: 32.0% ... Training loss: 0.289 ... Validation loss: 0.456\r",
      "Progress: 32.0% ... Training loss: 0.342 ... Validation loss: 0.516\r",
      "Progress: 32.0% ... Training loss: 0.307 ... Validation loss: 0.470\r",
      "Progress: 32.1% ... Training loss: 0.291 ... Validation loss: 0.460\r",
      "Progress: 32.1% ... Training loss: 0.290 ... Validation loss: 0.457\r",
      "Progress: 32.1% ... Training loss: 0.292 ... Validation loss: 0.458\r",
      "Progress: 32.1% ... Training loss: 0.294 ... Validation loss: 0.464\r",
      "Progress: 32.1% ... Training loss: 0.289 ... Validation loss: 0.458\r",
      "Progress: 32.1% ... Training loss: 0.308 ... Validation loss: 0.473\r",
      "Progress: 32.2% ... Training loss: 0.290 ... Validation loss: 0.458\r",
      "Progress: 32.2% ... Training loss: 0.289 ... Validation loss: 0.459\r",
      "Progress: 32.2% ... Training loss: 0.292 ... Validation loss: 0.462\r",
      "Progress: 32.2% ... Training loss: 0.289 ... Validation loss: 0.456\r",
      "Progress: 32.2% ... Training loss: 0.291 ... Validation loss: 0.461\r",
      "Progress: 32.3% ... Training loss: 0.289 ... Validation loss: 0.458\r",
      "Progress: 32.3% ... Training loss: 0.303 ... Validation loss: 0.478\r",
      "Progress: 32.3% ... Training loss: 0.290 ... Validation loss: 0.464\r",
      "Progress: 32.3% ... Training loss: 0.310 ... Validation loss: 0.478\r",
      "Progress: 32.3% ... Training loss: 0.289 ... Validation loss: 0.462\r",
      "Progress: 32.3% ... Training loss: 0.306 ... Validation loss: 0.480\r",
      "Progress: 32.4% ... Training loss: 0.322 ... Validation loss: 0.484\r",
      "Progress: 32.4% ... Training loss: 0.304 ... Validation loss: 0.476\r",
      "Progress: 32.4% ... Training loss: 0.310 ... Validation loss: 0.475\r",
      "Progress: 32.4% ... Training loss: 0.294 ... Validation loss: 0.467\r",
      "Progress: 32.4% ... Training loss: 0.292 ... Validation loss: 0.467\r",
      "Progress: 32.5% ... Training loss: 0.298 ... Validation loss: 0.472\r",
      "Progress: 32.5% ... Training loss: 0.295 ... Validation loss: 0.469\r",
      "Progress: 32.5% ... Training loss: 0.294 ... Validation loss: 0.469\r",
      "Progress: 32.5% ... Training loss: 0.313 ... Validation loss: 0.484\r",
      "Progress: 32.5% ... Training loss: 0.295 ... Validation loss: 0.473\r",
      "Progress: 32.5% ... Training loss: 0.293 ... Validation loss: 0.468\r",
      "Progress: 32.6% ... Training loss: 0.302 ... Validation loss: 0.481\r",
      "Progress: 32.6% ... Training loss: 0.294 ... Validation loss: 0.472\r",
      "Progress: 32.6% ... Training loss: 0.289 ... Validation loss: 0.462\r",
      "Progress: 32.6% ... Training loss: 0.288 ... Validation loss: 0.460\r",
      "Progress: 32.6% ... Training loss: 0.302 ... Validation loss: 0.470\r",
      "Progress: 32.7% ... Training loss: 0.339 ... Validation loss: 0.515\r",
      "Progress: 32.7% ... Training loss: 0.424 ... Validation loss: 0.579\r",
      "Progress: 32.7% ... Training loss: 0.418 ... Validation loss: 0.590\r",
      "Progress: 32.7% ... Training loss: 0.348 ... Validation loss: 0.513\r",
      "Progress: 32.7% ... Training loss: 0.308 ... Validation loss: 0.479\r",
      "Progress: 32.7% ... Training loss: 0.308 ... Validation loss: 0.477\r",
      "Progress: 32.8% ... Training loss: 0.305 ... Validation loss: 0.476\r",
      "Progress: 32.8% ... Training loss: 0.290 ... Validation loss: 0.460\r",
      "Progress: 32.8% ... Training loss: 0.289 ... Validation loss: 0.458\r",
      "Progress: 32.8% ... Training loss: 0.289 ... Validation loss: 0.459\r",
      "Progress: 32.8% ... Training loss: 0.299 ... Validation loss: 0.470\r",
      "Progress: 32.9% ... Training loss: 0.298 ... Validation loss: 0.465\r",
      "Progress: 32.9% ... Training loss: 0.327 ... Validation loss: 0.497\r",
      "Progress: 32.9% ... Training loss: 0.448 ... Validation loss: 0.617\r",
      "Progress: 32.9% ... Training loss: 0.402 ... Validation loss: 0.562\r",
      "Progress: 32.9% ... Training loss: 0.395 ... Validation loss: 0.569\r",
      "Progress: 32.9% ... Training loss: 0.368 ... Validation loss: 0.528\r",
      "Progress: 33.0% ... Training loss: 0.370 ... Validation loss: 0.552\r",
      "Progress: 33.0% ... Training loss: 0.461 ... Validation loss: 0.607\r",
      "Progress: 33.0% ... Training loss: 0.358 ... Validation loss: 0.547\r",
      "Progress: 33.0% ... Training loss: 0.304 ... Validation loss: 0.471\r",
      "Progress: 33.0% ... Training loss: 0.354 ... Validation loss: 0.539\r",
      "Progress: 33.1% ... Training loss: 0.363 ... Validation loss: 0.515\r",
      "Progress: 33.1% ... Training loss: 0.342 ... Validation loss: 0.524\r",
      "Progress: 33.1% ... Training loss: 0.346 ... Validation loss: 0.506\r",
      "Progress: 33.1% ... Training loss: 0.293 ... Validation loss: 0.465\r",
      "Progress: 33.1% ... Training loss: 0.301 ... Validation loss: 0.469\r",
      "Progress: 33.1% ... Training loss: 0.315 ... Validation loss: 0.491\r",
      "Progress: 33.2% ... Training loss: 0.292 ... Validation loss: 0.461\r",
      "Progress: 33.2% ... Training loss: 0.288 ... Validation loss: 0.462\r",
      "Progress: 33.2% ... Training loss: 0.313 ... Validation loss: 0.480\r",
      "Progress: 33.2% ... Training loss: 0.293 ... Validation loss: 0.468\r",
      "Progress: 33.2% ... Training loss: 0.288 ... Validation loss: 0.461\r",
      "Progress: 33.3% ... Training loss: 0.295 ... Validation loss: 0.467\r",
      "Progress: 33.3% ... Training loss: 0.306 ... Validation loss: 0.474\r",
      "Progress: 33.3% ... Training loss: 0.291 ... Validation loss: 0.463\r",
      "Progress: 33.3% ... Training loss: 0.328 ... Validation loss: 0.514\r",
      "Progress: 33.3% ... Training loss: 0.303 ... Validation loss: 0.471\r",
      "Progress: 33.3% ... Training loss: 0.290 ... Validation loss: 0.461\r",
      "Progress: 33.4% ... Training loss: 0.287 ... Validation loss: 0.462\r",
      "Progress: 33.4% ... Training loss: 0.297 ... Validation loss: 0.466\r",
      "Progress: 33.4% ... Training loss: 0.331 ... Validation loss: 0.515\r",
      "Progress: 33.4% ... Training loss: 0.322 ... Validation loss: 0.485\r",
      "Progress: 33.4% ... Training loss: 0.288 ... Validation loss: 0.463\r",
      "Progress: 33.5% ... Training loss: 0.289 ... Validation loss: 0.460\r",
      "Progress: 33.5% ... Training loss: 0.295 ... Validation loss: 0.473\r",
      "Progress: 33.5% ... Training loss: 0.288 ... Validation loss: 0.458\r",
      "Progress: 33.5% ... Training loss: 0.290 ... Validation loss: 0.465\r",
      "Progress: 33.5% ... Training loss: 0.287 ... Validation loss: 0.460\r",
      "Progress: 33.5% ... Training loss: 0.288 ... Validation loss: 0.462\r",
      "Progress: 33.6% ... Training loss: 0.294 ... Validation loss: 0.467\r",
      "Progress: 33.6% ... Training loss: 0.297 ... Validation loss: 0.463\r",
      "Progress: 33.6% ... Training loss: 0.305 ... Validation loss: 0.479\r",
      "Progress: 33.6% ... Training loss: 0.298 ... Validation loss: 0.465\r",
      "Progress: 33.6% ... Training loss: 0.287 ... Validation loss: 0.459\r",
      "Progress: 33.7% ... Training loss: 0.287 ... Validation loss: 0.460\r",
      "Progress: 33.7% ... Training loss: 0.288 ... Validation loss: 0.459\r",
      "Progress: 33.7% ... Training loss: 0.288 ... Validation loss: 0.455\r",
      "Progress: 33.7% ... Training loss: 0.288 ... Validation loss: 0.454\r",
      "Progress: 33.7% ... Training loss: 0.292 ... Validation loss: 0.455\r",
      "Progress: 33.7% ... Training loss: 0.289 ... Validation loss: 0.452\r",
      "Progress: 33.8% ... Training loss: 0.289 ... Validation loss: 0.454\r",
      "Progress: 33.8% ... Training loss: 0.291 ... Validation loss: 0.457\r",
      "Progress: 33.8% ... Training loss: 0.288 ... Validation loss: 0.456\r",
      "Progress: 33.8% ... Training loss: 0.297 ... Validation loss: 0.465\r",
      "Progress: 33.8% ... Training loss: 0.335 ... Validation loss: 0.511\r",
      "Progress: 33.9% ... Training loss: 0.321 ... Validation loss: 0.485\r",
      "Progress: 33.9% ... Training loss: 0.306 ... Validation loss: 0.486\r",
      "Progress: 33.9% ... Training loss: 0.287 ... Validation loss: 0.460\r",
      "Progress: 33.9% ... Training loss: 0.288 ... Validation loss: 0.465\r",
      "Progress: 33.9% ... Training loss: 0.291 ... Validation loss: 0.461\r",
      "Progress: 33.9% ... Training loss: 0.306 ... Validation loss: 0.473\r",
      "Progress: 34.0% ... Training loss: 0.311 ... Validation loss: 0.494\r",
      "Progress: 34.0% ... Training loss: 0.347 ... Validation loss: 0.509\r",
      "Progress: 34.0% ... Training loss: 0.338 ... Validation loss: 0.523\r",
      "Progress: 34.0% ... Training loss: 0.344 ... Validation loss: 0.507\r",
      "Progress: 34.0% ... Training loss: 0.324 ... Validation loss: 0.503\r",
      "Progress: 34.1% ... Training loss: 0.336 ... Validation loss: 0.499\r",
      "Progress: 34.1% ... Training loss: 0.295 ... Validation loss: 0.475\r",
      "Progress: 34.1% ... Training loss: 0.287 ... Validation loss: 0.465\r",
      "Progress: 34.1% ... Training loss: 0.290 ... Validation loss: 0.469\r",
      "Progress: 34.1% ... Training loss: 0.288 ... Validation loss: 0.463\r",
      "Progress: 34.1% ... Training loss: 0.297 ... Validation loss: 0.463\r",
      "Progress: 34.2% ... Training loss: 0.290 ... Validation loss: 0.459\r",
      "Progress: 34.2% ... Training loss: 0.294 ... Validation loss: 0.469\r",
      "Progress: 34.2% ... Training loss: 0.287 ... Validation loss: 0.460\r",
      "Progress: 34.2% ... Training loss: 0.298 ... Validation loss: 0.461\r",
      "Progress: 34.2% ... Training loss: 0.308 ... Validation loss: 0.490\r",
      "Progress: 34.3% ... Training loss: 0.318 ... Validation loss: 0.476\r",
      "Progress: 34.3% ... Training loss: 0.323 ... Validation loss: 0.512\r",
      "Progress: 34.3% ... Training loss: 0.358 ... Validation loss: 0.510\r",
      "Progress: 34.3% ... Training loss: 0.397 ... Validation loss: 0.591\r",
      "Progress: 34.3% ... Training loss: 0.334 ... Validation loss: 0.492\r",
      "Progress: 34.3% ... Training loss: 0.297 ... Validation loss: 0.480\r",
      "Progress: 34.4% ... Training loss: 0.287 ... Validation loss: 0.463\r",
      "Progress: 34.4% ... Training loss: 0.304 ... Validation loss: 0.491\r",
      "Progress: 34.4% ... Training loss: 0.288 ... Validation loss: 0.459\r",
      "Progress: 34.4% ... Training loss: 0.301 ... Validation loss: 0.467\r",
      "Progress: 34.4% ... Training loss: 0.287 ... Validation loss: 0.459\r",
      "Progress: 34.5% ... Training loss: 0.293 ... Validation loss: 0.464\r",
      "Progress: 34.5% ... Training loss: 0.296 ... Validation loss: 0.482\r",
      "Progress: 34.5% ... Training loss: 0.293 ... Validation loss: 0.467\r",
      "Progress: 34.5% ... Training loss: 0.296 ... Validation loss: 0.480\r",
      "Progress: 34.5% ... Training loss: 0.300 ... Validation loss: 0.469\r",
      "Progress: 34.5% ... Training loss: 0.287 ... Validation loss: 0.461\r",
      "Progress: 34.6% ... Training loss: 0.288 ... Validation loss: 0.454\r",
      "Progress: 34.6% ... Training loss: 0.288 ... Validation loss: 0.456\r",
      "Progress: 34.6% ... Training loss: 0.286 ... Validation loss: 0.454\r",
      "Progress: 34.6% ... Training loss: 0.287 ... Validation loss: 0.455\r",
      "Progress: 34.6% ... Training loss: 0.297 ... Validation loss: 0.464\r",
      "Progress: 34.7% ... Training loss: 0.317 ... Validation loss: 0.481\r",
      "Progress: 34.7% ... Training loss: 0.315 ... Validation loss: 0.478\r",
      "Progress: 34.7% ... Training loss: 0.298 ... Validation loss: 0.463\r",
      "Progress: 34.7% ... Training loss: 0.292 ... Validation loss: 0.456\r",
      "Progress: 34.7% ... Training loss: 0.294 ... Validation loss: 0.461\r",
      "Progress: 34.7% ... Training loss: 0.334 ... Validation loss: 0.496\r",
      "Progress: 34.8% ... Training loss: 0.301 ... Validation loss: 0.471\r",
      "Progress: 34.8% ... Training loss: 0.326 ... Validation loss: 0.486\r",
      "Progress: 34.8% ... Training loss: 0.314 ... Validation loss: 0.483\r",
      "Progress: 34.8% ... Training loss: 0.299 ... Validation loss: 0.466\r",
      "Progress: 34.8% ... Training loss: 0.315 ... Validation loss: 0.483\r",
      "Progress: 34.9% ... Training loss: 0.321 ... Validation loss: 0.485\r",
      "Progress: 34.9% ... Training loss: 0.320 ... Validation loss: 0.487\r",
      "Progress: 34.9% ... Training loss: 0.296 ... Validation loss: 0.463\r",
      "Progress: 34.9% ... Training loss: 0.289 ... Validation loss: 0.453\r",
      "Progress: 34.9% ... Training loss: 0.292 ... Validation loss: 0.459\r",
      "Progress: 34.9% ... Training loss: 0.332 ... Validation loss: 0.480\r",
      "Progress: 35.0% ... Training loss: 0.328 ... Validation loss: 0.500\r",
      "Progress: 35.0% ... Training loss: 0.294 ... Validation loss: 0.454\r",
      "Progress: 35.0% ... Training loss: 0.294 ... Validation loss: 0.454\r",
      "Progress: 35.0% ... Training loss: 0.322 ... Validation loss: 0.493\r",
      "Progress: 35.0% ... Training loss: 0.346 ... Validation loss: 0.500\r",
      "Progress: 35.1% ... Training loss: 0.326 ... Validation loss: 0.495\r",
      "Progress: 35.1% ... Training loss: 0.391 ... Validation loss: 0.553\r",
      "Progress: 35.1% ... Training loss: 0.288 ... Validation loss: 0.452\r",
      "Progress: 35.1% ... Training loss: 0.287 ... Validation loss: 0.451\r",
      "Progress: 35.1% ... Training loss: 0.293 ... Validation loss: 0.455\r",
      "Progress: 35.1% ... Training loss: 0.292 ... Validation loss: 0.461\r",
      "Progress: 35.2% ... Training loss: 0.286 ... Validation loss: 0.453\r",
      "Progress: 35.2% ... Training loss: 0.292 ... Validation loss: 0.462\r",
      "Progress: 35.2% ... Training loss: 0.292 ... Validation loss: 0.463\r",
      "Progress: 35.2% ... Training loss: 0.286 ... Validation loss: 0.454\r",
      "Progress: 35.2% ... Training loss: 0.290 ... Validation loss: 0.460\r",
      "Progress: 35.3% ... Training loss: 0.295 ... Validation loss: 0.462\r",
      "Progress: 35.3% ... Training loss: 0.300 ... Validation loss: 0.469\r",
      "Progress: 35.3% ... Training loss: 0.310 ... Validation loss: 0.483\r",
      "Progress: 35.3% ... Training loss: 0.335 ... Validation loss: 0.502\r",
      "Progress: 35.3% ... Training loss: 0.367 ... Validation loss: 0.550\r",
      "Progress: 35.3% ... Training loss: 0.298 ... Validation loss: 0.468\r",
      "Progress: 35.4% ... Training loss: 0.288 ... Validation loss: 0.456\r",
      "Progress: 35.4% ... Training loss: 0.293 ... Validation loss: 0.461\r",
      "Progress: 35.4% ... Training loss: 0.295 ... Validation loss: 0.468\r",
      "Progress: 35.4% ... Training loss: 0.292 ... Validation loss: 0.459\r",
      "Progress: 35.4% ... Training loss: 0.285 ... Validation loss: 0.460\r",
      "Progress: 35.5% ... Training loss: 0.296 ... Validation loss: 0.464\r",
      "Progress: 35.5% ... Training loss: 0.345 ... Validation loss: 0.534\r",
      "Progress: 35.5% ... Training loss: 0.335 ... Validation loss: 0.492\r",
      "Progress: 35.5% ... Training loss: 0.319 ... Validation loss: 0.503\r",
      "Progress: 35.5% ... Training loss: 0.291 ... Validation loss: 0.459\r",
      "Progress: 35.5% ... Training loss: 0.304 ... Validation loss: 0.488\r",
      "Progress: 35.6% ... Training loss: 0.302 ... Validation loss: 0.464\r",
      "Progress: 35.6% ... Training loss: 0.285 ... Validation loss: 0.459\r",
      "Progress: 35.6% ... Training loss: 0.287 ... Validation loss: 0.463\r",
      "Progress: 35.6% ... Training loss: 0.303 ... Validation loss: 0.464\r",
      "Progress: 35.6% ... Training loss: 0.310 ... Validation loss: 0.492\r",
      "Progress: 35.7% ... Training loss: 0.300 ... Validation loss: 0.461\r",
      "Progress: 35.7% ... Training loss: 0.299 ... Validation loss: 0.474\r",
      "Progress: 35.7% ... Training loss: 0.286 ... Validation loss: 0.455\r",
      "Progress: 35.7% ... Training loss: 0.312 ... Validation loss: 0.472\r",
      "Progress: 35.7% ... Training loss: 0.299 ... Validation loss: 0.474\r",
      "Progress: 35.7% ... Training loss: 0.289 ... Validation loss: 0.457\r",
      "Progress: 35.8% ... Training loss: 0.289 ... Validation loss: 0.462\r",
      "Progress: 35.8% ... Training loss: 0.285 ... Validation loss: 0.455\r",
      "Progress: 35.8% ... Training loss: 0.292 ... Validation loss: 0.467\r",
      "Progress: 35.8% ... Training loss: 0.291 ... Validation loss: 0.464\r",
      "Progress: 35.8% ... Training loss: 0.288 ... Validation loss: 0.456\r",
      "Progress: 35.9% ... Training loss: 0.299 ... Validation loss: 0.474\r",
      "Progress: 35.9% ... Training loss: 0.306 ... Validation loss: 0.471\r",
      "Progress: 35.9% ... Training loss: 0.308 ... Validation loss: 0.487\r",
      "Progress: 35.9% ... Training loss: 0.286 ... Validation loss: 0.455\r",
      "Progress: 35.9% ... Training loss: 0.286 ... Validation loss: 0.457\r",
      "Progress: 35.9% ... Training loss: 0.308 ... Validation loss: 0.487\r",
      "Progress: 36.0% ... Training loss: 0.287 ... Validation loss: 0.457\r",
      "Progress: 36.0% ... Training loss: 0.287 ... Validation loss: 0.457\r",
      "Progress: 36.0% ... Training loss: 0.304 ... Validation loss: 0.480\r",
      "Progress: 36.0% ... Training loss: 0.309 ... Validation loss: 0.473\r",
      "Progress: 36.0% ... Training loss: 0.306 ... Validation loss: 0.488\r",
      "Progress: 36.1% ... Training loss: 0.307 ... Validation loss: 0.468\r",
      "Progress: 36.1% ... Training loss: 0.312 ... Validation loss: 0.491\r",
      "Progress: 36.1% ... Training loss: 0.370 ... Validation loss: 0.521\r",
      "Progress: 36.1% ... Training loss: 0.300 ... Validation loss: 0.479\r",
      "Progress: 36.1% ... Training loss: 0.294 ... Validation loss: 0.460\r",
      "Progress: 36.1% ... Training loss: 0.286 ... Validation loss: 0.458\r",
      "Progress: 36.2% ... Training loss: 0.293 ... Validation loss: 0.472\r",
      "Progress: 36.2% ... Training loss: 0.314 ... Validation loss: 0.476\r",
      "Progress: 36.2% ... Training loss: 0.337 ... Validation loss: 0.536\r",
      "Progress: 36.2% ... Training loss: 0.306 ... Validation loss: 0.472\r",
      "Progress: 36.2% ... Training loss: 0.289 ... Validation loss: 0.478\r",
      "Progress: 36.3% ... Training loss: 0.290 ... Validation loss: 0.463\r",
      "Progress: 36.3% ... Training loss: 0.284 ... Validation loss: 0.464\r",
      "Progress: 36.3% ... Training loss: 0.292 ... Validation loss: 0.480\r",
      "Progress: 36.3% ... Training loss: 0.294 ... Validation loss: 0.462\r",
      "Progress: 36.3% ... Training loss: 0.290 ... Validation loss: 0.475\r",
      "Progress: 36.3% ... Training loss: 0.291 ... Validation loss: 0.473\r",
      "Progress: 36.4% ... Training loss: 0.296 ... Validation loss: 0.461\r",
      "Progress: 36.4% ... Training loss: 0.301 ... Validation loss: 0.479\r",
      "Progress: 36.4% ... Training loss: 0.367 ... Validation loss: 0.517\r",
      "Progress: 36.4% ... Training loss: 0.313 ... Validation loss: 0.506\r",
      "Progress: 36.4% ... Training loss: 0.302 ... Validation loss: 0.467\r",
      "Progress: 36.5% ... Training loss: 0.357 ... Validation loss: 0.559\r",
      "Progress: 36.5% ... Training loss: 0.367 ... Validation loss: 0.513\r",
      "Progress: 36.5% ... Training loss: 0.351 ... Validation loss: 0.560\r",
      "Progress: 36.5% ... Training loss: 0.309 ... Validation loss: 0.469\r",
      "Progress: 36.5% ... Training loss: 0.309 ... Validation loss: 0.510\r",
      "Progress: 36.5% ... Training loss: 0.293 ... Validation loss: 0.462\r",
      "Progress: 36.6% ... Training loss: 0.285 ... Validation loss: 0.469\r",
      "Progress: 36.6% ... Training loss: 0.284 ... Validation loss: 0.463\r",
      "Progress: 36.6% ... Training loss: 0.294 ... Validation loss: 0.462\r",
      "Progress: 36.6% ... Training loss: 0.313 ... Validation loss: 0.508\r",
      "Progress: 36.6% ... Training loss: 0.300 ... Validation loss: 0.464\r",
      "Progress: 36.7% ... Training loss: 0.324 ... Validation loss: 0.526\r",
      "Progress: 36.7% ... Training loss: 0.301 ... Validation loss: 0.465\r",
      "Progress: 36.7% ... Training loss: 0.330 ... Validation loss: 0.530\r",
      "Progress: 36.7% ... Training loss: 0.343 ... Validation loss: 0.492\r",
      "Progress: 36.7% ... Training loss: 0.383 ... Validation loss: 0.593\r",
      "Progress: 36.7% ... Training loss: 0.426 ... Validation loss: 0.554\r",
      "Progress: 36.8% ... Training loss: 0.408 ... Validation loss: 0.613\r",
      "Progress: 36.8% ... Training loss: 0.360 ... Validation loss: 0.503\r",
      "Progress: 36.8% ... Training loss: 0.399 ... Validation loss: 0.611\r",
      "Progress: 36.8% ... Training loss: 0.462 ... Validation loss: 0.584\r",
      "Progress: 36.8% ... Training loss: 0.352 ... Validation loss: 0.563\r",
      "Progress: 36.9% ... Training loss: 0.307 ... Validation loss: 0.467\r",
      "Progress: 36.9% ... Training loss: 0.295 ... Validation loss: 0.481\r",
      "Progress: 36.9% ... Training loss: 0.292 ... Validation loss: 0.456\r",
      "Progress: 36.9% ... Training loss: 0.287 ... Validation loss: 0.454\r",
      "Progress: 36.9% ... Training loss: 0.285 ... Validation loss: 0.456\r",
      "Progress: 36.9% ... Training loss: 0.293 ... Validation loss: 0.454\r",
      "Progress: 37.0% ... Training loss: 0.308 ... Validation loss: 0.489\r",
      "Progress: 37.0% ... Training loss: 0.425 ... Validation loss: 0.561\r",
      "Progress: 37.0% ... Training loss: 0.365 ... Validation loss: 0.559\r",
      "Progress: 37.0% ... Training loss: 0.409 ... Validation loss: 0.547\r",
      "Progress: 37.0% ... Training loss: 0.307 ... Validation loss: 0.498\r",
      "Progress: 37.1% ... Training loss: 0.309 ... Validation loss: 0.468\r",
      "Progress: 37.1% ... Training loss: 0.320 ... Validation loss: 0.514\r",
      "Progress: 37.1% ... Training loss: 0.285 ... Validation loss: 0.455\r",
      "Progress: 37.1% ... Training loss: 0.298 ... Validation loss: 0.479\r",
      "Progress: 37.1% ... Training loss: 0.329 ... Validation loss: 0.481\r",
      "Progress: 37.1% ... Training loss: 0.366 ... Validation loss: 0.548\r",
      "Progress: 37.2% ... Training loss: 0.315 ... Validation loss: 0.472\r",
      "Progress: 37.2% ... Training loss: 0.338 ... Validation loss: 0.513\r",
      "Progress: 37.2% ... Training loss: 0.302 ... Validation loss: 0.459\r",
      "Progress: 37.2% ... Training loss: 0.291 ... Validation loss: 0.466\r",
      "Progress: 37.2% ... Training loss: 0.340 ... Validation loss: 0.488\r",
      "Progress: 37.3% ... Training loss: 0.303 ... Validation loss: 0.490\r",
      "Progress: 37.3% ... Training loss: 0.288 ... Validation loss: 0.455\r",
      "Progress: 37.3% ... Training loss: 0.291 ... Validation loss: 0.467\r",
      "Progress: 37.3% ... Training loss: 0.330 ... Validation loss: 0.511\r",
      "Progress: 37.3% ... Training loss: 0.362 ... Validation loss: 0.510\r",
      "Progress: 37.3% ... Training loss: 0.337 ... Validation loss: 0.525\r",
      "Progress: 37.4% ... Training loss: 0.286 ... Validation loss: 0.461\r",
      "Progress: 37.4% ... Training loss: 0.283 ... Validation loss: 0.453\r",
      "Progress: 37.4% ... Training loss: 0.310 ... Validation loss: 0.492\r",
      "Progress: 37.4% ... Training loss: 0.283 ... Validation loss: 0.455\r",
      "Progress: 37.4% ... Training loss: 0.296 ... Validation loss: 0.461\r",
      "Progress: 37.5% ... Training loss: 0.295 ... Validation loss: 0.477\r",
      "Progress: 37.5% ... Training loss: 0.291 ... Validation loss: 0.458\r",
      "Progress: 37.5% ... Training loss: 0.304 ... Validation loss: 0.486\r",
      "Progress: 37.5% ... Training loss: 0.306 ... Validation loss: 0.469\r",
      "Progress: 37.5% ... Training loss: 0.283 ... Validation loss: 0.458\r",
      "Progress: 37.5% ... Training loss: 0.283 ... Validation loss: 0.458\r",
      "Progress: 37.6% ... Training loss: 0.289 ... Validation loss: 0.469\r",
      "Progress: 37.6% ... Training loss: 0.311 ... Validation loss: 0.475\r",
      "Progress: 37.6% ... Training loss: 0.313 ... Validation loss: 0.494\r",
      "Progress: 37.6% ... Training loss: 0.351 ... Validation loss: 0.511\r",
      "Progress: 37.6% ... Training loss: 0.324 ... Validation loss: 0.506\r",
      "Progress: 37.7% ... Training loss: 0.292 ... Validation loss: 0.464\r",
      "Progress: 37.7% ... Training loss: 0.286 ... Validation loss: 0.467\r",
      "Progress: 37.7% ... Training loss: 0.287 ... Validation loss: 0.464\r",
      "Progress: 37.7% ... Training loss: 0.284 ... Validation loss: 0.460\r",
      "Progress: 37.7% ... Training loss: 0.283 ... Validation loss: 0.459\r",
      "Progress: 37.7% ... Training loss: 0.297 ... Validation loss: 0.472\r",
      "Progress: 37.8% ... Training loss: 0.287 ... Validation loss: 0.465\r",
      "Progress: 37.8% ... Training loss: 0.284 ... Validation loss: 0.459\r",
      "Progress: 37.8% ... Training loss: 0.334 ... Validation loss: 0.510\r",
      "Progress: 37.8% ... Training loss: 0.363 ... Validation loss: 0.528\r",
      "Progress: 37.8% ... Training loss: 0.287 ... Validation loss: 0.461\r",
      "Progress: 37.9% ... Training loss: 0.331 ... Validation loss: 0.500\r",
      "Progress: 37.9% ... Training loss: 0.396 ... Validation loss: 0.579\r",
      "Progress: 37.9% ... Training loss: 0.469 ... Validation loss: 0.628\r",
      "Progress: 37.9% ... Training loss: 0.499 ... Validation loss: 0.674\r",
      "Progress: 37.9% ... Training loss: 0.482 ... Validation loss: 0.635\r",
      "Progress: 37.9% ... Training loss: 0.420 ... Validation loss: 0.605\r",
      "Progress: 38.0% ... Training loss: 0.512 ... Validation loss: 0.659\r",
      "Progress: 38.0% ... Training loss: 0.383 ... Validation loss: 0.572\r",
      "Progress: 38.0% ... Training loss: 0.323 ... Validation loss: 0.492\r",
      "Progress: 38.0% ... Training loss: 0.372 ... Validation loss: 0.563\r",
      "Progress: 38.0% ... Training loss: 0.427 ... Validation loss: 0.584\r",
      "Progress: 38.1% ... Training loss: 0.333 ... Validation loss: 0.519\r",
      "Progress: 38.1% ... Training loss: 0.324 ... Validation loss: 0.496\r",
      "Progress: 38.1% ... Training loss: 0.283 ... Validation loss: 0.462\r",
      "Progress: 38.1% ... Training loss: 0.289 ... Validation loss: 0.467\r",
      "Progress: 38.1% ... Training loss: 0.303 ... Validation loss: 0.475\r",
      "Progress: 38.1% ... Training loss: 0.305 ... Validation loss: 0.486\r",
      "Progress: 38.2% ... Training loss: 0.285 ... Validation loss: 0.461\r",
      "Progress: 38.2% ... Training loss: 0.286 ... Validation loss: 0.464\r",
      "Progress: 38.2% ... Training loss: 0.284 ... Validation loss: 0.458\r",
      "Progress: 38.2% ... Training loss: 0.285 ... Validation loss: 0.456\r",
      "Progress: 38.2% ... Training loss: 0.287 ... Validation loss: 0.457\r",
      "Progress: 38.3% ... Training loss: 0.289 ... Validation loss: 0.463\r",
      "Progress: 38.3% ... Training loss: 0.304 ... Validation loss: 0.477\r",
      "Progress: 38.3% ... Training loss: 0.284 ... Validation loss: 0.458\r",
      "Progress: 38.3% ... Training loss: 0.289 ... Validation loss: 0.461\r",
      "Progress: 38.3% ... Training loss: 0.298 ... Validation loss: 0.474\r",
      "Progress: 38.3% ... Training loss: 0.288 ... Validation loss: 0.466\r",
      "Progress: 38.4% ... Training loss: 0.284 ... Validation loss: 0.462\r",
      "Progress: 38.4% ... Training loss: 0.283 ... Validation loss: 0.458\r",
      "Progress: 38.4% ... Training loss: 0.282 ... Validation loss: 0.460\r",
      "Progress: 38.4% ... Training loss: 0.282 ... Validation loss: 0.460\r",
      "Progress: 38.4% ... Training loss: 0.293 ... Validation loss: 0.469\r",
      "Progress: 38.5% ... Training loss: 0.288 ... Validation loss: 0.469\r",
      "Progress: 38.5% ... Training loss: 0.281 ... Validation loss: 0.458\r",
      "Progress: 38.5% ... Training loss: 0.281 ... Validation loss: 0.458\r",
      "Progress: 38.5% ... Training loss: 0.289 ... Validation loss: 0.462\r",
      "Progress: 38.5% ... Training loss: 0.281 ... Validation loss: 0.456\r",
      "Progress: 38.5% ... Training loss: 0.308 ... Validation loss: 0.483\r",
      "Progress: 38.6% ... Training loss: 0.282 ... Validation loss: 0.461\r",
      "Progress: 38.6% ... Training loss: 0.284 ... Validation loss: 0.462\r",
      "Progress: 38.6% ... Training loss: 0.282 ... Validation loss: 0.460\r",
      "Progress: 38.6% ... Training loss: 0.281 ... Validation loss: 0.457\r",
      "Progress: 38.6% ... Training loss: 0.283 ... Validation loss: 0.459\r",
      "Progress: 38.7% ... Training loss: 0.286 ... Validation loss: 0.465\r",
      "Progress: 38.7% ... Training loss: 0.283 ... Validation loss: 0.460\r",
      "Progress: 38.7% ... Training loss: 0.295 ... Validation loss: 0.471\r",
      "Progress: 38.7% ... Training loss: 0.304 ... Validation loss: 0.484\r",
      "Progress: 38.7% ... Training loss: 0.305 ... Validation loss: 0.481\r",
      "Progress: 38.7% ... Training loss: 0.281 ... Validation loss: 0.460\r",
      "Progress: 38.8% ... Training loss: 0.282 ... Validation loss: 0.461\r",
      "Progress: 38.8% ... Training loss: 0.290 ... Validation loss: 0.467\r",
      "Progress: 38.8% ... Training loss: 0.335 ... Validation loss: 0.511\r",
      "Progress: 38.8% ... Training loss: 0.337 ... Validation loss: 0.510\r",
      "Progress: 38.8% ... Training loss: 0.287 ... Validation loss: 0.464\r",
      "Progress: 38.9% ... Training loss: 0.281 ... Validation loss: 0.458\r",
      "Progress: 38.9% ... Training loss: 0.300 ... Validation loss: 0.476\r",
      "Progress: 38.9% ... Training loss: 0.300 ... Validation loss: 0.476\r",
      "Progress: 38.9% ... Training loss: 0.337 ... Validation loss: 0.514\r",
      "Progress: 38.9% ... Training loss: 0.316 ... Validation loss: 0.488\r",
      "Progress: 38.9% ... Training loss: 0.284 ... Validation loss: 0.458\r",
      "Progress: 39.0% ... Training loss: 0.296 ... Validation loss: 0.465\r",
      "Progress: 39.0% ... Training loss: 0.404 ... Validation loss: 0.572\r",
      "Progress: 39.0% ... Training loss: 0.358 ... Validation loss: 0.542\r",
      "Progress: 39.0% ... Training loss: 0.317 ... Validation loss: 0.486\r",
      "Progress: 39.0% ... Training loss: 0.300 ... Validation loss: 0.486\r",
      "Progress: 39.1% ... Training loss: 0.287 ... Validation loss: 0.462\r",
      "Progress: 39.1% ... Training loss: 0.284 ... Validation loss: 0.464\r",
      "Progress: 39.1% ... Training loss: 0.282 ... Validation loss: 0.457\r",
      "Progress: 39.1% ... Training loss: 0.281 ... Validation loss: 0.458\r",
      "Progress: 39.1% ... Training loss: 0.284 ... Validation loss: 0.465\r",
      "Progress: 39.1% ... Training loss: 0.281 ... Validation loss: 0.462\r",
      "Progress: 39.2% ... Training loss: 0.284 ... Validation loss: 0.467\r",
      "Progress: 39.2% ... Training loss: 0.292 ... Validation loss: 0.468\r",
      "Progress: 39.2% ... Training loss: 0.286 ... Validation loss: 0.472\r",
      "Progress: 39.2% ... Training loss: 0.281 ... Validation loss: 0.462\r",
      "Progress: 39.2% ... Training loss: 0.282 ... Validation loss: 0.462\r",
      "Progress: 39.3% ... Training loss: 0.281 ... Validation loss: 0.463\r",
      "Progress: 39.3% ... Training loss: 0.284 ... Validation loss: 0.467\r",
      "Progress: 39.3% ... Training loss: 0.284 ... Validation loss: 0.467\r",
      "Progress: 39.3% ... Training loss: 0.283 ... Validation loss: 0.469\r",
      "Progress: 39.3% ... Training loss: 0.320 ... Validation loss: 0.496\r",
      "Progress: 39.3% ... Training loss: 0.388 ... Validation loss: 0.582\r",
      "Progress: 39.4% ... Training loss: 0.342 ... Validation loss: 0.516\r",
      "Progress: 39.4% ... Training loss: 0.355 ... Validation loss: 0.552\r",
      "Progress: 39.4% ... Training loss: 0.342 ... Validation loss: 0.518\r",
      "Progress: 39.4% ... Training loss: 0.322 ... Validation loss: 0.510\r",
      "Progress: 39.4% ... Training loss: 0.282 ... Validation loss: 0.463\r",
      "Progress: 39.5% ... Training loss: 0.283 ... Validation loss: 0.463\r",
      "Progress: 39.5% ... Training loss: 0.287 ... Validation loss: 0.464\r",
      "Progress: 39.5% ... Training loss: 0.284 ... Validation loss: 0.461\r",
      "Progress: 39.5% ... Training loss: 0.295 ... Validation loss: 0.474\r",
      "Progress: 39.5% ... Training loss: 0.304 ... Validation loss: 0.477\r",
      "Progress: 39.5% ... Training loss: 0.284 ... Validation loss: 0.460\r",
      "Progress: 39.6% ... Training loss: 0.285 ... Validation loss: 0.462\r",
      "Progress: 39.6% ... Training loss: 0.293 ... Validation loss: 0.467\r",
      "Progress: 39.6% ... Training loss: 0.308 ... Validation loss: 0.485\r",
      "Progress: 39.6% ... Training loss: 0.282 ... Validation loss: 0.458\r",
      "Progress: 39.6% ... Training loss: 0.285 ... Validation loss: 0.460\r",
      "Progress: 39.7% ... Training loss: 0.281 ... Validation loss: 0.454\r",
      "Progress: 39.7% ... Training loss: 0.289 ... Validation loss: 0.459\r",
      "Progress: 39.7% ... Training loss: 0.305 ... Validation loss: 0.482\r",
      "Progress: 39.7% ... Training loss: 0.323 ... Validation loss: 0.494\r",
      "Progress: 39.7% ... Training loss: 0.291 ... Validation loss: 0.466\r",
      "Progress: 39.7% ... Training loss: 0.283 ... Validation loss: 0.457\r",
      "Progress: 39.8% ... Training loss: 0.305 ... Validation loss: 0.469\r",
      "Progress: 39.8% ... Training loss: 0.285 ... Validation loss: 0.455\r",
      "Progress: 39.8% ... Training loss: 0.284 ... Validation loss: 0.454\r",
      "Progress: 39.8% ... Training loss: 0.321 ... Validation loss: 0.490\r",
      "Progress: 39.8% ... Training loss: 0.291 ... Validation loss: 0.462\r",
      "Progress: 39.9% ... Training loss: 0.281 ... Validation loss: 0.456\r",
      "Progress: 39.9% ... Training loss: 0.285 ... Validation loss: 0.458\r",
      "Progress: 39.9% ... Training loss: 0.288 ... Validation loss: 0.461\r",
      "Progress: 39.9% ... Training loss: 0.283 ... Validation loss: 0.453\r",
      "Progress: 39.9% ... Training loss: 0.282 ... Validation loss: 0.454\r",
      "Progress: 39.9% ... Training loss: 0.294 ... Validation loss: 0.463\r",
      "Progress: 40.0% ... Training loss: 0.294 ... Validation loss: 0.468\r",
      "Progress: 40.0% ... Training loss: 0.310 ... Validation loss: 0.478\r",
      "Progress: 40.0% ... Training loss: 0.329 ... Validation loss: 0.508\r",
      "Progress: 40.0% ... Training loss: 0.355 ... Validation loss: 0.522\r",
      "Progress: 40.0% ... Training loss: 0.323 ... Validation loss: 0.502\r",
      "Progress: 40.1% ... Training loss: 0.363 ... Validation loss: 0.531\r",
      "Progress: 40.1% ... Training loss: 0.309 ... Validation loss: 0.487\r",
      "Progress: 40.1% ... Training loss: 0.350 ... Validation loss: 0.520\r",
      "Progress: 40.1% ... Training loss: 0.304 ... Validation loss: 0.474\r",
      "Progress: 40.1% ... Training loss: 0.281 ... Validation loss: 0.452\r",
      "Progress: 40.1% ... Training loss: 0.291 ... Validation loss: 0.458\r",
      "Progress: 40.2% ... Training loss: 0.284 ... Validation loss: 0.453\r",
      "Progress: 40.2% ... Training loss: 0.282 ... Validation loss: 0.454\r",
      "Progress: 40.2% ... Training loss: 0.289 ... Validation loss: 0.461\r",
      "Progress: 40.2% ... Training loss: 0.282 ... Validation loss: 0.457\r",
      "Progress: 40.2% ... Training loss: 0.280 ... Validation loss: 0.457\r",
      "Progress: 40.3% ... Training loss: 0.282 ... Validation loss: 0.458\r",
      "Progress: 40.3% ... Training loss: 0.280 ... Validation loss: 0.454\r",
      "Progress: 40.3% ... Training loss: 0.280 ... Validation loss: 0.455\r",
      "Progress: 40.3% ... Training loss: 0.282 ... Validation loss: 0.462\r",
      "Progress: 40.3% ... Training loss: 0.279 ... Validation loss: 0.458\r",
      "Progress: 40.3% ... Training loss: 0.294 ... Validation loss: 0.468\r",
      "Progress: 40.4% ... Training loss: 0.300 ... Validation loss: 0.483\r",
      "Progress: 40.4% ... Training loss: 0.289 ... Validation loss: 0.461\r",
      "Progress: 40.4% ... Training loss: 0.290 ... Validation loss: 0.469\r",
      "Progress: 40.4% ... Training loss: 0.316 ... Validation loss: 0.484\r",
      "Progress: 40.4% ... Training loss: 0.353 ... Validation loss: 0.536\r",
      "Progress: 40.5% ... Training loss: 0.330 ... Validation loss: 0.498\r",
      "Progress: 40.5% ... Training loss: 0.366 ... Validation loss: 0.536\r",
      "Progress: 40.5% ... Training loss: 0.310 ... Validation loss: 0.482\r",
      "Progress: 40.5% ... Training loss: 0.322 ... Validation loss: 0.489\r",
      "Progress: 40.5% ... Training loss: 0.311 ... Validation loss: 0.482\r",
      "Progress: 40.5% ... Training loss: 0.290 ... Validation loss: 0.464\r",
      "Progress: 40.6% ... Training loss: 0.293 ... Validation loss: 0.465\r",
      "Progress: 40.6% ... Training loss: 0.284 ... Validation loss: 0.463\r",
      "Progress: 40.6% ... Training loss: 0.280 ... Validation loss: 0.461\r",
      "Progress: 40.6% ... Training loss: 0.281 ... Validation loss: 0.458\r",
      "Progress: 40.6% ... Training loss: 0.282 ... Validation loss: 0.460\r",
      "Progress: 40.7% ... Training loss: 0.309 ... Validation loss: 0.481\r",
      "Progress: 40.7% ... Training loss: 0.299 ... Validation loss: 0.486\r",
      "Progress: 40.7% ... Training loss: 0.281 ... Validation loss: 0.461\r",
      "Progress: 40.7% ... Training loss: 0.284 ... Validation loss: 0.462\r",
      "Progress: 40.7% ... Training loss: 0.284 ... Validation loss: 0.472\r",
      "Progress: 40.7% ... Training loss: 0.287 ... Validation loss: 0.467\r",
      "Progress: 40.8% ... Training loss: 0.325 ... Validation loss: 0.513\r",
      "Progress: 40.8% ... Training loss: 0.323 ... Validation loss: 0.492\r",
      "Progress: 40.8% ... Training loss: 0.300 ... Validation loss: 0.487\r",
      "Progress: 40.8% ... Training loss: 0.285 ... Validation loss: 0.463\r",
      "Progress: 40.8% ... Training loss: 0.284 ... Validation loss: 0.471\r",
      "Progress: 40.9% ... Training loss: 0.288 ... Validation loss: 0.465\r",
      "Progress: 40.9% ... Training loss: 0.290 ... Validation loss: 0.464\r",
      "Progress: 40.9% ... Training loss: 0.363 ... Validation loss: 0.531\r",
      "Progress: 40.9% ... Training loss: 0.382 ... Validation loss: 0.563\r",
      "Progress: 40.9% ... Training loss: 0.319 ... Validation loss: 0.492\r",
      "Progress: 40.9% ... Training loss: 0.286 ... Validation loss: 0.461\r",
      "Progress: 41.0% ... Training loss: 0.279 ... Validation loss: 0.455\r",
      "Progress: 41.0% ... Training loss: 0.279 ... Validation loss: 0.455\r",
      "Progress: 41.0% ... Training loss: 0.308 ... Validation loss: 0.483\r",
      "Progress: 41.0% ... Training loss: 0.292 ... Validation loss: 0.470\r",
      "Progress: 41.0% ... Training loss: 0.281 ... Validation loss: 0.458\r",
      "Progress: 41.1% ... Training loss: 0.283 ... Validation loss: 0.456\r",
      "Progress: 41.1% ... Training loss: 0.289 ... Validation loss: 0.465\r",
      "Progress: 41.1% ... Training loss: 0.296 ... Validation loss: 0.476\r",
      "Progress: 41.1% ... Training loss: 0.282 ... Validation loss: 0.459\r",
      "Progress: 41.1% ... Training loss: 0.279 ... Validation loss: 0.455\r",
      "Progress: 41.1% ... Training loss: 0.309 ... Validation loss: 0.478\r",
      "Progress: 41.2% ... Training loss: 0.321 ... Validation loss: 0.498\r",
      "Progress: 41.2% ... Training loss: 0.305 ... Validation loss: 0.482\r",
      "Progress: 41.2% ... Training loss: 0.306 ... Validation loss: 0.484\r",
      "Progress: 41.2% ... Training loss: 0.290 ... Validation loss: 0.472\r",
      "Progress: 41.2% ... Training loss: 0.326 ... Validation loss: 0.502\r",
      "Progress: 41.3% ... Training loss: 0.316 ... Validation loss: 0.500\r",
      "Progress: 41.3% ... Training loss: 0.327 ... Validation loss: 0.504\r",
      "Progress: 41.3% ... Training loss: 0.281 ... Validation loss: 0.466\r",
      "Progress: 41.3% ... Training loss: 0.309 ... Validation loss: 0.490\r",
      "Progress: 41.3% ... Training loss: 0.280 ... Validation loss: 0.463\r",
      "Progress: 41.3% ... Training loss: 0.279 ... Validation loss: 0.458\r",
      "Progress: 41.4% ... Training loss: 0.280 ... Validation loss: 0.461\r",
      "Progress: 41.4% ... Training loss: 0.287 ... Validation loss: 0.468\r",
      "Progress: 41.4% ... Training loss: 0.314 ... Validation loss: 0.491\r",
      "Progress: 41.4% ... Training loss: 0.364 ... Validation loss: 0.550\r",
      "Progress: 41.4% ... Training loss: 0.326 ... Validation loss: 0.498\r",
      "Progress: 41.5% ... Training loss: 0.279 ... Validation loss: 0.459\r",
      "Progress: 41.5% ... Training loss: 0.280 ... Validation loss: 0.460\r",
      "Progress: 41.5% ... Training loss: 0.284 ... Validation loss: 0.462\r",
      "Progress: 41.5% ... Training loss: 0.343 ... Validation loss: 0.528\r",
      "Progress: 41.5% ... Training loss: 0.351 ... Validation loss: 0.523\r",
      "Progress: 41.5% ... Training loss: 0.322 ... Validation loss: 0.513\r",
      "Progress: 41.6% ... Training loss: 0.289 ... Validation loss: 0.468\r",
      "Progress: 41.6% ... Training loss: 0.346 ... Validation loss: 0.538\r",
      "Progress: 41.6% ... Training loss: 0.319 ... Validation loss: 0.491\r",
      "Progress: 41.6% ... Training loss: 0.279 ... Validation loss: 0.459\r",
      "Progress: 41.6% ... Training loss: 0.289 ... Validation loss: 0.466\r",
      "Progress: 41.7% ... Training loss: 0.310 ... Validation loss: 0.490\r",
      "Progress: 41.7% ... Training loss: 0.344 ... Validation loss: 0.516\r",
      "Progress: 41.7% ... Training loss: 0.334 ... Validation loss: 0.515\r",
      "Progress: 41.7% ... Training loss: 0.300 ... Validation loss: 0.478\r",
      "Progress: 41.7% ... Training loss: 0.297 ... Validation loss: 0.470\r",
      "Progress: 41.7% ... Training loss: 0.293 ... Validation loss: 0.469\r",
      "Progress: 41.8% ... Training loss: 0.281 ... Validation loss: 0.453\r",
      "Progress: 41.8% ... Training loss: 0.278 ... Validation loss: 0.453\r",
      "Progress: 41.8% ... Training loss: 0.279 ... Validation loss: 0.456\r",
      "Progress: 41.8% ... Training loss: 0.281 ... Validation loss: 0.456\r",
      "Progress: 41.8% ... Training loss: 0.291 ... Validation loss: 0.468\r",
      "Progress: 41.9% ... Training loss: 0.282 ... Validation loss: 0.457\r",
      "Progress: 41.9% ... Training loss: 0.282 ... Validation loss: 0.458\r",
      "Progress: 41.9% ... Training loss: 0.282 ... Validation loss: 0.459\r",
      "Progress: 41.9% ... Training loss: 0.281 ... Validation loss: 0.457\r",
      "Progress: 41.9% ... Training loss: 0.284 ... Validation loss: 0.461\r",
      "Progress: 41.9% ... Training loss: 0.278 ... Validation loss: 0.456\r",
      "Progress: 42.0% ... Training loss: 0.309 ... Validation loss: 0.473\r",
      "Progress: 42.0% ... Training loss: 0.283 ... Validation loss: 0.457\r",
      "Progress: 42.0% ... Training loss: 0.279 ... Validation loss: 0.452\r",
      "Progress: 42.0% ... Training loss: 0.292 ... Validation loss: 0.467\r",
      "Progress: 42.0% ... Training loss: 0.313 ... Validation loss: 0.483\r",
      "Progress: 42.1% ... Training loss: 0.279 ... Validation loss: 0.449\r",
      "Progress: 42.1% ... Training loss: 0.286 ... Validation loss: 0.459\r",
      "Progress: 42.1% ... Training loss: 0.287 ... Validation loss: 0.461\r",
      "Progress: 42.1% ... Training loss: 0.281 ... Validation loss: 0.454\r",
      "Progress: 42.1% ... Training loss: 0.286 ... Validation loss: 0.459\r",
      "Progress: 42.1% ... Training loss: 0.279 ... Validation loss: 0.456\r",
      "Progress: 42.2% ... Training loss: 0.282 ... Validation loss: 0.461\r",
      "Progress: 42.2% ... Training loss: 0.279 ... Validation loss: 0.457\r",
      "Progress: 42.2% ... Training loss: 0.293 ... Validation loss: 0.475\r",
      "Progress: 42.2% ... Training loss: 0.351 ... Validation loss: 0.521\r",
      "Progress: 42.2% ... Training loss: 0.335 ... Validation loss: 0.518\r",
      "Progress: 42.3% ... Training loss: 0.308 ... Validation loss: 0.481\r",
      "Progress: 42.3% ... Training loss: 0.313 ... Validation loss: 0.493\r",
      "Progress: 42.3% ... Training loss: 0.285 ... Validation loss: 0.462\r",
      "Progress: 42.3% ... Training loss: 0.279 ... Validation loss: 0.459\r",
      "Progress: 42.3% ... Training loss: 0.309 ... Validation loss: 0.489\r",
      "Progress: 42.3% ... Training loss: 0.315 ... Validation loss: 0.493\r",
      "Progress: 42.4% ... Training loss: 0.295 ... Validation loss: 0.476\r",
      "Progress: 42.4% ... Training loss: 0.289 ... Validation loss: 0.468\r",
      "Progress: 42.4% ... Training loss: 0.326 ... Validation loss: 0.507\r",
      "Progress: 42.4% ... Training loss: 0.296 ... Validation loss: 0.472\r",
      "Progress: 42.4% ... Training loss: 0.284 ... Validation loss: 0.457\r",
      "Progress: 42.5% ... Training loss: 0.278 ... Validation loss: 0.453\r",
      "Progress: 42.5% ... Training loss: 0.277 ... Validation loss: 0.452\r",
      "Progress: 42.5% ... Training loss: 0.281 ... Validation loss: 0.458\r",
      "Progress: 42.5% ... Training loss: 0.297 ... Validation loss: 0.469\r",
      "Progress: 42.5% ... Training loss: 0.320 ... Validation loss: 0.498\r",
      "Progress: 42.5% ... Training loss: 0.328 ... Validation loss: 0.497\r",
      "Progress: 42.6% ... Training loss: 0.323 ... Validation loss: 0.504\r",
      "Progress: 42.6% ... Training loss: 0.298 ... Validation loss: 0.470\r",
      "Progress: 42.6% ... Training loss: 0.309 ... Validation loss: 0.477\r",
      "Progress: 42.6% ... Training loss: 0.279 ... Validation loss: 0.451\r",
      "Progress: 42.6% ... Training loss: 0.279 ... Validation loss: 0.449\r",
      "Progress: 42.7% ... Training loss: 0.283 ... Validation loss: 0.453\r",
      "Progress: 42.7% ... Training loss: 0.293 ... Validation loss: 0.462\r",
      "Progress: 42.7% ... Training loss: 0.318 ... Validation loss: 0.488\r",
      "Progress: 42.7% ... Training loss: 0.312 ... Validation loss: 0.485\r",
      "Progress: 42.7% ... Training loss: 0.294 ... Validation loss: 0.468\r",
      "Progress: 42.7% ... Training loss: 0.301 ... Validation loss: 0.477\r",
      "Progress: 42.8% ... Training loss: 0.288 ... Validation loss: 0.461\r",
      "Progress: 42.8% ... Training loss: 0.288 ... Validation loss: 0.464\r",
      "Progress: 42.8% ... Training loss: 0.278 ... Validation loss: 0.451\r",
      "Progress: 42.8% ... Training loss: 0.287 ... Validation loss: 0.459\r",
      "Progress: 42.8% ... Training loss: 0.287 ... Validation loss: 0.455\r",
      "Progress: 42.9% ... Training loss: 0.285 ... Validation loss: 0.455\r",
      "Progress: 42.9% ... Training loss: 0.277 ... Validation loss: 0.449\r",
      "Progress: 42.9% ... Training loss: 0.290 ... Validation loss: 0.465\r",
      "Progress: 42.9% ... Training loss: 0.282 ... Validation loss: 0.452\r",
      "Progress: 42.9% ... Training loss: 0.292 ... Validation loss: 0.462\r",
      "Progress: 42.9% ... Training loss: 0.333 ... Validation loss: 0.501\r",
      "Progress: 43.0% ... Training loss: 0.356 ... Validation loss: 0.520\r",
      "Progress: 43.0% ... Training loss: 0.327 ... Validation loss: 0.497\r",
      "Progress: 43.0% ... Training loss: 0.353 ... Validation loss: 0.512\r",
      "Progress: 43.0% ... Training loss: 0.360 ... Validation loss: 0.530\r",
      "Progress: 43.0% ... Training loss: 0.418 ... Validation loss: 0.573\r",
      "Progress: 43.1% ... Training loss: 0.317 ... Validation loss: 0.487\r",
      "Progress: 43.1% ... Training loss: 0.301 ... Validation loss: 0.468\r",
      "Progress: 43.1% ... Training loss: 0.289 ... Validation loss: 0.461\r",
      "Progress: 43.1% ... Training loss: 0.281 ... Validation loss: 0.453\r",
      "Progress: 43.1% ... Training loss: 0.285 ... Validation loss: 0.455\r",
      "Progress: 43.1% ... Training loss: 0.278 ... Validation loss: 0.451\r",
      "Progress: 43.2% ... Training loss: 0.293 ... Validation loss: 0.464\r",
      "Progress: 43.2% ... Training loss: 0.279 ... Validation loss: 0.452\r",
      "Progress: 43.2% ... Training loss: 0.281 ... Validation loss: 0.453\r",
      "Progress: 43.2% ... Training loss: 0.290 ... Validation loss: 0.462\r",
      "Progress: 43.2% ... Training loss: 0.294 ... Validation loss: 0.470\r",
      "Progress: 43.3% ... Training loss: 0.283 ... Validation loss: 0.455\r",
      "Progress: 43.3% ... Training loss: 0.280 ... Validation loss: 0.451\r",
      "Progress: 43.3% ... Training loss: 0.277 ... Validation loss: 0.448\r",
      "Progress: 43.3% ... Training loss: 0.279 ... Validation loss: 0.454\r",
      "Progress: 43.3% ... Training loss: 0.280 ... Validation loss: 0.456\r",
      "Progress: 43.3% ... Training loss: 0.276 ... Validation loss: 0.453\r",
      "Progress: 43.4% ... Training loss: 0.292 ... Validation loss: 0.467\r",
      "Progress: 43.4% ... Training loss: 0.294 ... Validation loss: 0.469\r",
      "Progress: 43.4% ... Training loss: 0.281 ... Validation loss: 0.460\r",
      "Progress: 43.4% ... Training loss: 0.287 ... Validation loss: 0.464\r",
      "Progress: 43.4% ... Training loss: 0.286 ... Validation loss: 0.461\r",
      "Progress: 43.5% ... Training loss: 0.284 ... Validation loss: 0.462\r",
      "Progress: 43.5% ... Training loss: 0.279 ... Validation loss: 0.452\r",
      "Progress: 43.5% ... Training loss: 0.280 ... Validation loss: 0.456\r",
      "Progress: 43.5% ... Training loss: 0.301 ... Validation loss: 0.476\r",
      "Progress: 43.5% ... Training loss: 0.286 ... Validation loss: 0.462\r",
      "Progress: 43.5% ... Training loss: 0.278 ... Validation loss: 0.456\r",
      "Progress: 43.6% ... Training loss: 0.285 ... Validation loss: 0.461\r",
      "Progress: 43.6% ... Training loss: 0.321 ... Validation loss: 0.500\r",
      "Progress: 43.6% ... Training loss: 0.279 ... Validation loss: 0.455\r",
      "Progress: 43.6% ... Training loss: 0.318 ... Validation loss: 0.502\r",
      "Progress: 43.6% ... Training loss: 0.296 ... Validation loss: 0.468\r",
      "Progress: 43.7% ... Training loss: 0.312 ... Validation loss: 0.486\r",
      "Progress: 43.7% ... Training loss: 0.295 ... Validation loss: 0.466\r",
      "Progress: 43.7% ... Training loss: 0.307 ... Validation loss: 0.480\r",
      "Progress: 43.7% ... Training loss: 0.298 ... Validation loss: 0.465\r",
      "Progress: 43.7% ... Training loss: 0.276 ... Validation loss: 0.448\r",
      "Progress: 43.7% ... Training loss: 0.276 ... Validation loss: 0.451\r",
      "Progress: 43.8% ... Training loss: 0.298 ... Validation loss: 0.464\r",
      "Progress: 43.8% ... Training loss: 0.309 ... Validation loss: 0.489\r",
      "Progress: 43.8% ... Training loss: 0.326 ... Validation loss: 0.493\r",
      "Progress: 43.8% ... Training loss: 0.301 ... Validation loss: 0.481\r",
      "Progress: 43.8% ... Training loss: 0.339 ... Validation loss: 0.501\r",
      "Progress: 43.9% ... Training loss: 0.323 ... Validation loss: 0.505\r",
      "Progress: 43.9% ... Training loss: 0.362 ... Validation loss: 0.521\r",
      "Progress: 43.9% ... Training loss: 0.317 ... Validation loss: 0.508\r",
      "Progress: 43.9% ... Training loss: 0.275 ... Validation loss: 0.452\r",
      "Progress: 43.9% ... Training loss: 0.278 ... Validation loss: 0.454\r",
      "Progress: 43.9% ... Training loss: 0.288 ... Validation loss: 0.470\r",
      "Progress: 44.0% ... Training loss: 0.277 ... Validation loss: 0.454\r",
      "Progress: 44.0% ... Training loss: 0.281 ... Validation loss: 0.466\r",
      "Progress: 44.0% ... Training loss: 0.285 ... Validation loss: 0.466\r",
      "Progress: 44.0% ... Training loss: 0.277 ... Validation loss: 0.454\r",
      "Progress: 44.0% ... Training loss: 0.288 ... Validation loss: 0.457\r",
      "Progress: 44.1% ... Training loss: 0.296 ... Validation loss: 0.474\r",
      "Progress: 44.1% ... Training loss: 0.306 ... Validation loss: 0.472\r",
      "Progress: 44.1% ... Training loss: 0.295 ... Validation loss: 0.477\r",
      "Progress: 44.1% ... Training loss: 0.356 ... Validation loss: 0.511\r",
      "Progress: 44.1% ... Training loss: 0.297 ... Validation loss: 0.488\r",
      "Progress: 44.1% ... Training loss: 0.305 ... Validation loss: 0.473\r",
      "Progress: 44.2% ... Training loss: 0.283 ... Validation loss: 0.464\r",
      "Progress: 44.2% ... Training loss: 0.275 ... Validation loss: 0.451\r",
      "Progress: 44.2% ... Training loss: 0.276 ... Validation loss: 0.453\r",
      "Progress: 44.2% ... Training loss: 0.277 ... Validation loss: 0.452\r",
      "Progress: 44.2% ... Training loss: 0.291 ... Validation loss: 0.477\r",
      "Progress: 44.3% ... Training loss: 0.295 ... Validation loss: 0.467\r",
      "Progress: 44.3% ... Training loss: 0.293 ... Validation loss: 0.473\r",
      "Progress: 44.3% ... Training loss: 0.289 ... Validation loss: 0.463\r",
      "Progress: 44.3% ... Training loss: 0.287 ... Validation loss: 0.471\r",
      "Progress: 44.3% ... Training loss: 0.278 ... Validation loss: 0.456\r",
      "Progress: 44.3% ... Training loss: 0.288 ... Validation loss: 0.460\r",
      "Progress: 44.4% ... Training loss: 0.294 ... Validation loss: 0.477\r",
      "Progress: 44.4% ... Training loss: 0.308 ... Validation loss: 0.476\r",
      "Progress: 44.4% ... Training loss: 0.276 ... Validation loss: 0.455\r",
      "Progress: 44.4% ... Training loss: 0.282 ... Validation loss: 0.461\r",
      "Progress: 44.4% ... Training loss: 0.275 ... Validation loss: 0.449\r",
      "Progress: 44.5% ... Training loss: 0.275 ... Validation loss: 0.449\r",
      "Progress: 44.5% ... Training loss: 0.277 ... Validation loss: 0.453\r",
      "Progress: 44.5% ... Training loss: 0.285 ... Validation loss: 0.458\r",
      "Progress: 44.5% ... Training loss: 0.278 ... Validation loss: 0.456\r",
      "Progress: 44.5% ... Training loss: 0.275 ... Validation loss: 0.450\r",
      "Progress: 44.5% ... Training loss: 0.278 ... Validation loss: 0.451\r",
      "Progress: 44.6% ... Training loss: 0.281 ... Validation loss: 0.458\r",
      "Progress: 44.6% ... Training loss: 0.280 ... Validation loss: 0.455\r",
      "Progress: 44.6% ... Training loss: 0.280 ... Validation loss: 0.456\r",
      "Progress: 44.6% ... Training loss: 0.276 ... Validation loss: 0.455\r",
      "Progress: 44.6% ... Training loss: 0.277 ... Validation loss: 0.453\r",
      "Progress: 44.7% ... Training loss: 0.277 ... Validation loss: 0.456\r",
      "Progress: 44.7% ... Training loss: 0.275 ... Validation loss: 0.452\r",
      "Progress: 44.7% ... Training loss: 0.277 ... Validation loss: 0.453\r",
      "Progress: 44.7% ... Training loss: 0.280 ... Validation loss: 0.458\r",
      "Progress: 44.7% ... Training loss: 0.282 ... Validation loss: 0.457\r",
      "Progress: 44.7% ... Training loss: 0.276 ... Validation loss: 0.451\r",
      "Progress: 44.8% ... Training loss: 0.277 ... Validation loss: 0.454\r",
      "Progress: 44.8% ... Training loss: 0.300 ... Validation loss: 0.471\r",
      "Progress: 44.8% ... Training loss: 0.288 ... Validation loss: 0.466\r",
      "Progress: 44.8% ... Training loss: 0.277 ... Validation loss: 0.456\r",
      "Progress: 44.8% ... Training loss: 0.304 ... Validation loss: 0.483\r",
      "Progress: 44.9% ... Training loss: 0.274 ... Validation loss: 0.452\r",
      "Progress: 44.9% ... Training loss: 0.277 ... Validation loss: 0.457\r",
      "Progress: 44.9% ... Training loss: 0.284 ... Validation loss: 0.461\r",
      "Progress: 44.9% ... Training loss: 0.288 ... Validation loss: 0.467\r",
      "Progress: 44.9% ... Training loss: 0.275 ... Validation loss: 0.452\r",
      "Progress: 44.9% ... Training loss: 0.276 ... Validation loss: 0.455\r",
      "Progress: 45.0% ... Training loss: 0.276 ... Validation loss: 0.454\r",
      "Progress: 45.0% ... Training loss: 0.278 ... Validation loss: 0.459\r",
      "Progress: 45.0% ... Training loss: 0.294 ... Validation loss: 0.473\r",
      "Progress: 45.0% ... Training loss: 0.285 ... Validation loss: 0.462\r",
      "Progress: 45.0% ... Training loss: 0.277 ... Validation loss: 0.456\r",
      "Progress: 45.1% ... Training loss: 0.286 ... Validation loss: 0.465\r",
      "Progress: 45.1% ... Training loss: 0.279 ... Validation loss: 0.461\r",
      "Progress: 45.1% ... Training loss: 0.277 ... Validation loss: 0.460\r",
      "Progress: 45.1% ... Training loss: 0.282 ... Validation loss: 0.464\r",
      "Progress: 45.1% ... Training loss: 0.312 ... Validation loss: 0.490\r",
      "Progress: 45.1% ... Training loss: 0.274 ... Validation loss: 0.457\r",
      "Progress: 45.2% ... Training loss: 0.276 ... Validation loss: 0.458\r",
      "Progress: 45.2% ... Training loss: 0.281 ... Validation loss: 0.461\r",
      "Progress: 45.2% ... Training loss: 0.277 ... Validation loss: 0.462\r",
      "Progress: 45.2% ... Training loss: 0.283 ... Validation loss: 0.463\r",
      "Progress: 45.2% ... Training loss: 0.361 ... Validation loss: 0.550\r",
      "Progress: 45.3% ... Training loss: 0.343 ... Validation loss: 0.511\r",
      "Progress: 45.3% ... Training loss: 0.379 ... Validation loss: 0.569\r",
      "Progress: 45.3% ... Training loss: 0.391 ... Validation loss: 0.554\r",
      "Progress: 45.3% ... Training loss: 0.376 ... Validation loss: 0.568\r",
      "Progress: 45.3% ... Training loss: 0.496 ... Validation loss: 0.647\r",
      "Progress: 45.3% ... Training loss: 0.345 ... Validation loss: 0.529\r",
      "Progress: 45.4% ... Training loss: 0.350 ... Validation loss: 0.520\r",
      "Progress: 45.4% ... Training loss: 0.297 ... Validation loss: 0.478\r",
      "Progress: 45.4% ... Training loss: 0.277 ... Validation loss: 0.456\r",
      "Progress: 45.4% ... Training loss: 0.275 ... Validation loss: 0.456\r",
      "Progress: 45.4% ... Training loss: 0.292 ... Validation loss: 0.470\r",
      "Progress: 45.5% ... Training loss: 0.289 ... Validation loss: 0.463\r",
      "Progress: 45.5% ... Training loss: 0.288 ... Validation loss: 0.469\r",
      "Progress: 45.5% ... Training loss: 0.275 ... Validation loss: 0.454\r",
      "Progress: 45.5% ... Training loss: 0.275 ... Validation loss: 0.454\r",
      "Progress: 45.5% ... Training loss: 0.274 ... Validation loss: 0.454\r",
      "Progress: 45.5% ... Training loss: 0.274 ... Validation loss: 0.456\r",
      "Progress: 45.6% ... Training loss: 0.276 ... Validation loss: 0.461\r",
      "Progress: 45.6% ... Training loss: 0.285 ... Validation loss: 0.469\r",
      "Progress: 45.6% ... Training loss: 0.280 ... Validation loss: 0.461\r",
      "Progress: 45.6% ... Training loss: 0.275 ... Validation loss: 0.456\r",
      "Progress: 45.6% ... Training loss: 0.275 ... Validation loss: 0.454\r",
      "Progress: 45.7% ... Training loss: 0.280 ... Validation loss: 0.463\r",
      "Progress: 45.7% ... Training loss: 0.283 ... Validation loss: 0.465\r",
      "Progress: 45.7% ... Training loss: 0.279 ... Validation loss: 0.459\r",
      "Progress: 45.7% ... Training loss: 0.277 ... Validation loss: 0.457\r",
      "Progress: 45.7% ... Training loss: 0.282 ... Validation loss: 0.460\r",
      "Progress: 45.7% ... Training loss: 0.275 ... Validation loss: 0.454\r",
      "Progress: 45.8% ... Training loss: 0.274 ... Validation loss: 0.455\r",
      "Progress: 45.8% ... Training loss: 0.281 ... Validation loss: 0.462\r",
      "Progress: 45.8% ... Training loss: 0.277 ... Validation loss: 0.455\r",
      "Progress: 45.8% ... Training loss: 0.274 ... Validation loss: 0.454\r",
      "Progress: 45.8% ... Training loss: 0.287 ... Validation loss: 0.472\r",
      "Progress: 45.9% ... Training loss: 0.336 ... Validation loss: 0.510\r",
      "Progress: 45.9% ... Training loss: 0.338 ... Validation loss: 0.521\r",
      "Progress: 45.9% ... Training loss: 0.326 ... Validation loss: 0.501\r",
      "Progress: 45.9% ... Training loss: 0.353 ... Validation loss: 0.534\r",
      "Progress: 45.9% ... Training loss: 0.317 ... Validation loss: 0.491\r",
      "Progress: 45.9% ... Training loss: 0.299 ... Validation loss: 0.487\r",
      "Progress: 46.0% ... Training loss: 0.284 ... Validation loss: 0.462\r",
      "Progress: 46.0% ... Training loss: 0.276 ... Validation loss: 0.459\r",
      "Progress: 46.0% ... Training loss: 0.275 ... Validation loss: 0.460\r",
      "Progress: 46.0% ... Training loss: 0.273 ... Validation loss: 0.454\r",
      "Progress: 46.0% ... Training loss: 0.273 ... Validation loss: 0.454\r",
      "Progress: 46.1% ... Training loss: 0.273 ... Validation loss: 0.454\r",
      "Progress: 46.1% ... Training loss: 0.274 ... Validation loss: 0.453\r",
      "Progress: 46.1% ... Training loss: 0.283 ... Validation loss: 0.466\r",
      "Progress: 46.1% ... Training loss: 0.328 ... Validation loss: 0.503\r",
      "Progress: 46.1% ... Training loss: 0.281 ... Validation loss: 0.469\r",
      "Progress: 46.1% ... Training loss: 0.311 ... Validation loss: 0.484\r",
      "Progress: 46.2% ... Training loss: 0.287 ... Validation loss: 0.476\r",
      "Progress: 46.2% ... Training loss: 0.290 ... Validation loss: 0.467\r",
      "Progress: 46.2% ... Training loss: 0.291 ... Validation loss: 0.482\r",
      "Progress: 46.2% ... Training loss: 0.275 ... Validation loss: 0.464\r",
      "Progress: 46.2% ... Training loss: 0.287 ... Validation loss: 0.466\r",
      "Progress: 46.3% ... Training loss: 0.275 ... Validation loss: 0.463\r",
      "Progress: 46.3% ... Training loss: 0.276 ... Validation loss: 0.464\r",
      "Progress: 46.3% ... Training loss: 0.330 ... Validation loss: 0.500\r",
      "Progress: 46.3% ... Training loss: 0.277 ... Validation loss: 0.466\r",
      "Progress: 46.3% ... Training loss: 0.279 ... Validation loss: 0.462\r",
      "Progress: 46.3% ... Training loss: 0.275 ... Validation loss: 0.455\r",
      "Progress: 46.4% ... Training loss: 0.273 ... Validation loss: 0.453\r",
      "Progress: 46.4% ... Training loss: 0.278 ... Validation loss: 0.465\r",
      "Progress: 46.4% ... Training loss: 0.287 ... Validation loss: 0.463\r",
      "Progress: 46.4% ... Training loss: 0.273 ... Validation loss: 0.455\r",
      "Progress: 46.4% ... Training loss: 0.273 ... Validation loss: 0.454\r",
      "Progress: 46.5% ... Training loss: 0.278 ... Validation loss: 0.460\r",
      "Progress: 46.5% ... Training loss: 0.275 ... Validation loss: 0.454\r",
      "Progress: 46.5% ... Training loss: 0.273 ... Validation loss: 0.454\r",
      "Progress: 46.5% ... Training loss: 0.279 ... Validation loss: 0.462\r",
      "Progress: 46.5% ... Training loss: 0.277 ... Validation loss: 0.457\r",
      "Progress: 46.5% ... Training loss: 0.281 ... Validation loss: 0.465\r",
      "Progress: 46.6% ... Training loss: 0.282 ... Validation loss: 0.460\r",
      "Progress: 46.6% ... Training loss: 0.278 ... Validation loss: 0.457\r",
      "Progress: 46.6% ... Training loss: 0.273 ... Validation loss: 0.454\r",
      "Progress: 46.6% ... Training loss: 0.275 ... Validation loss: 0.453\r",
      "Progress: 46.6% ... Training loss: 0.273 ... Validation loss: 0.461\r",
      "Progress: 46.7% ... Training loss: 0.280 ... Validation loss: 0.462\r",
      "Progress: 46.7% ... Training loss: 0.282 ... Validation loss: 0.463\r",
      "Progress: 46.7% ... Training loss: 0.305 ... Validation loss: 0.489\r",
      "Progress: 46.7% ... Training loss: 0.287 ... Validation loss: 0.467\r",
      "Progress: 46.7% ... Training loss: 0.273 ... Validation loss: 0.455\r",
      "Progress: 46.7% ... Training loss: 0.273 ... Validation loss: 0.457\r",
      "Progress: 46.8% ... Training loss: 0.275 ... Validation loss: 0.460\r",
      "Progress: 46.8% ... Training loss: 0.275 ... Validation loss: 0.457\r",
      "Progress: 46.8% ... Training loss: 0.273 ... Validation loss: 0.455\r",
      "Progress: 46.8% ... Training loss: 0.286 ... Validation loss: 0.468\r",
      "Progress: 46.8% ... Training loss: 0.275 ... Validation loss: 0.456\r",
      "Progress: 46.9% ... Training loss: 0.277 ... Validation loss: 0.456\r",
      "Progress: 46.9% ... Training loss: 0.277 ... Validation loss: 0.456\r",
      "Progress: 46.9% ... Training loss: 0.280 ... Validation loss: 0.461\r",
      "Progress: 46.9% ... Training loss: 0.295 ... Validation loss: 0.483\r",
      "Progress: 46.9% ... Training loss: 0.307 ... Validation loss: 0.485\r",
      "Progress: 46.9% ... Training loss: 0.342 ... Validation loss: 0.524\r",
      "Progress: 47.0% ... Training loss: 0.350 ... Validation loss: 0.523\r",
      "Progress: 47.0% ... Training loss: 0.278 ... Validation loss: 0.466\r",
      "Progress: 47.0% ... Training loss: 0.273 ... Validation loss: 0.459\r",
      "Progress: 47.0% ... Training loss: 0.273 ... Validation loss: 0.459\r",
      "Progress: 47.0% ... Training loss: 0.275 ... Validation loss: 0.464\r",
      "Progress: 47.1% ... Training loss: 0.281 ... Validation loss: 0.465\r",
      "Progress: 47.1% ... Training loss: 0.278 ... Validation loss: 0.467\r",
      "Progress: 47.1% ... Training loss: 0.286 ... Validation loss: 0.464\r",
      "Progress: 47.1% ... Training loss: 0.289 ... Validation loss: 0.482\r",
      "Progress: 47.1% ... Training loss: 0.326 ... Validation loss: 0.495\r",
      "Progress: 47.1% ... Training loss: 0.286 ... Validation loss: 0.480\r",
      "Progress: 47.2% ... Training loss: 0.278 ... Validation loss: 0.458\r",
      "Progress: 47.2% ... Training loss: 0.308 ... Validation loss: 0.499\r",
      "Progress: 47.2% ... Training loss: 0.293 ... Validation loss: 0.469\r",
      "Progress: 47.2% ... Training loss: 0.273 ... Validation loss: 0.460\r",
      "Progress: 47.2% ... Training loss: 0.277 ... Validation loss: 0.460\r",
      "Progress: 47.3% ... Training loss: 0.273 ... Validation loss: 0.461\r",
      "Progress: 47.3% ... Training loss: 0.296 ... Validation loss: 0.493\r",
      "Progress: 47.3% ... Training loss: 0.278 ... Validation loss: 0.462\r",
      "Progress: 47.3% ... Training loss: 0.320 ... Validation loss: 0.522\r",
      "Progress: 47.3% ... Training loss: 0.338 ... Validation loss: 0.508\r",
      "Progress: 47.3% ... Training loss: 0.367 ... Validation loss: 0.564\r",
      "Progress: 47.4% ... Training loss: 0.387 ... Validation loss: 0.553\r",
      "Progress: 47.4% ... Training loss: 0.345 ... Validation loss: 0.538\r",
      "Progress: 47.4% ... Training loss: 0.369 ... Validation loss: 0.533\r",
      "Progress: 47.4% ... Training loss: 0.302 ... Validation loss: 0.498\r",
      "Progress: 47.4% ... Training loss: 0.308 ... Validation loss: 0.482\r",
      "Progress: 47.5% ... Training loss: 0.291 ... Validation loss: 0.484\r",
      "Progress: 47.5% ... Training loss: 0.281 ... Validation loss: 0.470\r",
      "Progress: 47.5% ... Training loss: 0.281 ... Validation loss: 0.470\r",
      "Progress: 47.5% ... Training loss: 0.329 ... Validation loss: 0.498\r",
      "Progress: 47.5% ... Training loss: 0.309 ... Validation loss: 0.499\r",
      "Progress: 47.5% ... Training loss: 0.273 ... Validation loss: 0.456\r",
      "Progress: 47.6% ... Training loss: 0.272 ... Validation loss: 0.454\r",
      "Progress: 47.6% ... Training loss: 0.276 ... Validation loss: 0.457\r",
      "Progress: 47.6% ... Training loss: 0.274 ... Validation loss: 0.452\r",
      "Progress: 47.6% ... Training loss: 0.283 ... Validation loss: 0.460\r",
      "Progress: 47.6% ... Training loss: 0.272 ... Validation loss: 0.454\r",
      "Progress: 47.7% ... Training loss: 0.272 ... Validation loss: 0.455\r",
      "Progress: 47.7% ... Training loss: 0.272 ... Validation loss: 0.453\r",
      "Progress: 47.7% ... Training loss: 0.283 ... Validation loss: 0.464\r",
      "Progress: 47.7% ... Training loss: 0.281 ... Validation loss: 0.458\r",
      "Progress: 47.7% ... Training loss: 0.272 ... Validation loss: 0.454\r",
      "Progress: 47.7% ... Training loss: 0.272 ... Validation loss: 0.455\r",
      "Progress: 47.8% ... Training loss: 0.281 ... Validation loss: 0.463\r",
      "Progress: 47.8% ... Training loss: 0.275 ... Validation loss: 0.458\r",
      "Progress: 47.8% ... Training loss: 0.275 ... Validation loss: 0.463\r",
      "Progress: 47.8% ... Training loss: 0.307 ... Validation loss: 0.487\r",
      "Progress: 47.8% ... Training loss: 0.344 ... Validation loss: 0.538\r",
      "Progress: 47.9% ... Training loss: 0.350 ... Validation loss: 0.525\r",
      "Progress: 47.9% ... Training loss: 0.314 ... Validation loss: 0.508\r",
      "Progress: 47.9% ... Training loss: 0.312 ... Validation loss: 0.492\r",
      "Progress: 47.9% ... Training loss: 0.331 ... Validation loss: 0.525\r",
      "Progress: 47.9% ... Training loss: 0.329 ... Validation loss: 0.505\r",
      "Progress: 47.9% ... Training loss: 0.305 ... Validation loss: 0.496\r",
      "Progress: 48.0% ... Training loss: 0.356 ... Validation loss: 0.528\r",
      "Progress: 48.0% ... Training loss: 0.283 ... Validation loss: 0.479\r",
      "Progress: 48.0% ... Training loss: 0.279 ... Validation loss: 0.470\r",
      "Progress: 48.0% ... Training loss: 0.275 ... Validation loss: 0.459\r",
      "Progress: 48.0% ... Training loss: 0.274 ... Validation loss: 0.463\r",
      "Progress: 48.1% ... Training loss: 0.292 ... Validation loss: 0.476\r",
      "Progress: 48.1% ... Training loss: 0.272 ... Validation loss: 0.460\r",
      "Progress: 48.1% ... Training loss: 0.277 ... Validation loss: 0.464\r",
      "Progress: 48.1% ... Training loss: 0.276 ... Validation loss: 0.462\r",
      "Progress: 48.1% ... Training loss: 0.283 ... Validation loss: 0.470\r",
      "Progress: 48.1% ... Training loss: 0.276 ... Validation loss: 0.466\r",
      "Progress: 48.2% ... Training loss: 0.272 ... Validation loss: 0.461\r",
      "Progress: 48.2% ... Training loss: 0.274 ... Validation loss: 0.462\r",
      "Progress: 48.2% ... Training loss: 0.279 ... Validation loss: 0.468\r",
      "Progress: 48.2% ... Training loss: 0.274 ... Validation loss: 0.460\r",
      "Progress: 48.2% ... Training loss: 0.271 ... Validation loss: 0.457\r",
      "Progress: 48.3% ... Training loss: 0.291 ... Validation loss: 0.470\r",
      "Progress: 48.3% ... Training loss: 0.275 ... Validation loss: 0.459\r",
      "Progress: 48.3% ... Training loss: 0.272 ... Validation loss: 0.456\r",
      "Progress: 48.3% ... Training loss: 0.271 ... Validation loss: 0.456\r",
      "Progress: 48.3% ... Training loss: 0.277 ... Validation loss: 0.459\r",
      "Progress: 48.3% ... Training loss: 0.273 ... Validation loss: 0.457\r",
      "Progress: 48.4% ... Training loss: 0.279 ... Validation loss: 0.461\r",
      "Progress: 48.4% ... Training loss: 0.274 ... Validation loss: 0.457\r",
      "Progress: 48.4% ... Training loss: 0.275 ... Validation loss: 0.460\r",
      "Progress: 48.4% ... Training loss: 0.292 ... Validation loss: 0.474\r",
      "Progress: 48.4% ... Training loss: 0.287 ... Validation loss: 0.469\r",
      "Progress: 48.5% ... Training loss: 0.294 ... Validation loss: 0.473\r",
      "Progress: 48.5% ... Training loss: 0.279 ... Validation loss: 0.461\r",
      "Progress: 48.5% ... Training loss: 0.273 ... Validation loss: 0.460\r",
      "Progress: 48.5% ... Training loss: 0.296 ... Validation loss: 0.480\r",
      "Progress: 48.5% ... Training loss: 0.273 ... Validation loss: 0.458\r",
      "Progress: 48.5% ... Training loss: 0.272 ... Validation loss: 0.457\r",
      "Progress: 48.6% ... Training loss: 0.272 ... Validation loss: 0.458\r",
      "Progress: 48.6% ... Training loss: 0.273 ... Validation loss: 0.458\r",
      "Progress: 48.6% ... Training loss: 0.272 ... Validation loss: 0.456\r",
      "Progress: 48.6% ... Training loss: 0.272 ... Validation loss: 0.455\r",
      "Progress: 48.6% ... Training loss: 0.275 ... Validation loss: 0.458\r",
      "Progress: 48.7% ... Training loss: 0.283 ... Validation loss: 0.466\r",
      "Progress: 48.7% ... Training loss: 0.292 ... Validation loss: 0.468\r",
      "Progress: 48.7% ... Training loss: 0.272 ... Validation loss: 0.449\r",
      "Progress: 48.7% ... Training loss: 0.271 ... Validation loss: 0.448\r",
      "Progress: 48.7% ... Training loss: 0.272 ... Validation loss: 0.449\r",
      "Progress: 48.7% ... Training loss: 0.279 ... Validation loss: 0.458\r",
      "Progress: 48.8% ... Training loss: 0.273 ... Validation loss: 0.454\r",
      "Progress: 48.8% ... Training loss: 0.271 ... Validation loss: 0.453\r",
      "Progress: 48.8% ... Training loss: 0.271 ... Validation loss: 0.452\r",
      "Progress: 48.8% ... Training loss: 0.281 ... Validation loss: 0.455\r",
      "Progress: 48.8% ... Training loss: 0.273 ... Validation loss: 0.447\r",
      "Progress: 48.9% ... Training loss: 0.294 ... Validation loss: 0.463\r",
      "Progress: 48.9% ... Training loss: 0.273 ... Validation loss: 0.448\r",
      "Progress: 48.9% ... Training loss: 0.274 ... Validation loss: 0.450\r",
      "Progress: 48.9% ... Training loss: 0.272 ... Validation loss: 0.449\r",
      "Progress: 48.9% ... Training loss: 0.282 ... Validation loss: 0.463\r",
      "Progress: 48.9% ... Training loss: 0.271 ... Validation loss: 0.452\r",
      "Progress: 49.0% ... Training loss: 0.306 ... Validation loss: 0.488\r",
      "Progress: 49.0% ... Training loss: 0.325 ... Validation loss: 0.505\r",
      "Progress: 49.0% ... Training loss: 0.311 ... Validation loss: 0.490\r",
      "Progress: 49.0% ... Training loss: 0.315 ... Validation loss: 0.496\r",
      "Progress: 49.0% ... Training loss: 0.312 ... Validation loss: 0.491\r",
      "Progress: 49.1% ... Training loss: 0.316 ... Validation loss: 0.486\r",
      "Progress: 49.1% ... Training loss: 0.294 ... Validation loss: 0.474\r",
      "Progress: 49.1% ... Training loss: 0.272 ... Validation loss: 0.451\r",
      "Progress: 49.1% ... Training loss: 0.274 ... Validation loss: 0.455\r",
      "Progress: 49.1% ... Training loss: 0.275 ... Validation loss: 0.455\r",
      "Progress: 49.1% ... Training loss: 0.271 ... Validation loss: 0.451\r",
      "Progress: 49.2% ... Training loss: 0.271 ... Validation loss: 0.449\r",
      "Progress: 49.2% ... Training loss: 0.299 ... Validation loss: 0.480\r",
      "Progress: 49.2% ... Training loss: 0.306 ... Validation loss: 0.478\r",
      "Progress: 49.2% ... Training loss: 0.297 ... Validation loss: 0.474\r",
      "Progress: 49.2% ... Training loss: 0.333 ... Validation loss: 0.504\r",
      "Progress: 49.3% ... Training loss: 0.397 ... Validation loss: 0.568\r",
      "Progress: 49.3% ... Training loss: 0.446 ... Validation loss: 0.622\r",
      "Progress: 49.3% ... Training loss: 0.482 ... Validation loss: 0.633\r",
      "Progress: 49.3% ... Training loss: 0.320 ... Validation loss: 0.520\r",
      "Progress: 49.3% ... Training loss: 0.331 ... Validation loss: 0.499\r",
      "Progress: 49.3% ... Training loss: 0.366 ... Validation loss: 0.564\r",
      "Progress: 49.4% ... Training loss: 0.314 ... Validation loss: 0.483\r",
      "Progress: 49.4% ... Training loss: 0.301 ... Validation loss: 0.489\r",
      "Progress: 49.4% ... Training loss: 0.347 ... Validation loss: 0.510\r",
      "Progress: 49.4% ... Training loss: 0.300 ... Validation loss: 0.491\r",
      "Progress: 49.4% ... Training loss: 0.286 ... Validation loss: 0.462\r",
      "Progress: 49.5% ... Training loss: 0.277 ... Validation loss: 0.458\r",
      "Progress: 49.5% ... Training loss: 0.271 ... Validation loss: 0.454\r",
      "Progress: 49.5% ... Training loss: 0.282 ... Validation loss: 0.466\r",
      "Progress: 49.5% ... Training loss: 0.271 ... Validation loss: 0.453\r",
      "Progress: 49.5% ... Training loss: 0.271 ... Validation loss: 0.452\r",
      "Progress: 49.5% ... Training loss: 0.280 ... Validation loss: 0.466\r",
      "Progress: 49.6% ... Training loss: 0.293 ... Validation loss: 0.467\r",
      "Progress: 49.6% ... Training loss: 0.316 ... Validation loss: 0.512\r",
      "Progress: 49.6% ... Training loss: 0.294 ... Validation loss: 0.467\r",
      "Progress: 49.6% ... Training loss: 0.271 ... Validation loss: 0.455\r",
      "Progress: 49.6% ... Training loss: 0.271 ... Validation loss: 0.451\r",
      "Progress: 49.7% ... Training loss: 0.270 ... Validation loss: 0.451\r",
      "Progress: 49.7% ... Training loss: 0.273 ... Validation loss: 0.450\r",
      "Progress: 49.7% ... Training loss: 0.271 ... Validation loss: 0.451\r",
      "Progress: 49.7% ... Training loss: 0.276 ... Validation loss: 0.462\r",
      "Progress: 49.7% ... Training loss: 0.283 ... Validation loss: 0.456\r",
      "Progress: 49.7% ... Training loss: 0.282 ... Validation loss: 0.462\r",
      "Progress: 49.8% ... Training loss: 0.291 ... Validation loss: 0.462\r",
      "Progress: 49.8% ... Training loss: 0.274 ... Validation loss: 0.456\r",
      "Progress: 49.8% ... Training loss: 0.272 ... Validation loss: 0.450\r",
      "Progress: 49.8% ... Training loss: 0.303 ... Validation loss: 0.473\r",
      "Progress: 49.8% ... Training loss: 0.279 ... Validation loss: 0.463\r",
      "Progress: 49.9% ... Training loss: 0.272 ... Validation loss: 0.449\r",
      "Progress: 49.9% ... Training loss: 0.276 ... Validation loss: 0.461\r",
      "Progress: 49.9% ... Training loss: 0.330 ... Validation loss: 0.495\r",
      "Progress: 49.9% ... Training loss: 0.288 ... Validation loss: 0.481\r",
      "Progress: 49.9% ... Training loss: 0.300 ... Validation loss: 0.475\r",
      "Progress: 49.9% ... Training loss: 0.302 ... Validation loss: 0.494\r",
      "Progress: 50.0% ... Training loss: 0.329 ... Validation loss: 0.502\r",
      "Progress: 50.0% ... Training loss: 0.304 ... Validation loss: 0.502\r",
      "Progress: 50.0% ... Training loss: 0.286 ... Validation loss: 0.467\r",
      "Progress: 50.0% ... Training loss: 0.274 ... Validation loss: 0.466\r",
      "Progress: 50.0% ... Training loss: 0.271 ... Validation loss: 0.455\r",
      "Progress: 50.1% ... Training loss: 0.273 ... Validation loss: 0.461\r",
      "Progress: 50.1% ... Training loss: 0.271 ... Validation loss: 0.453\r",
      "Progress: 50.1% ... Training loss: 0.272 ... Validation loss: 0.455\r",
      "Progress: 50.1% ... Training loss: 0.290 ... Validation loss: 0.484\r",
      "Progress: 50.1% ... Training loss: 0.279 ... Validation loss: 0.458\r",
      "Progress: 50.1% ... Training loss: 0.271 ... Validation loss: 0.459\r",
      "Progress: 50.2% ... Training loss: 0.271 ... Validation loss: 0.458\r",
      "Progress: 50.2% ... Training loss: 0.276 ... Validation loss: 0.467\r",
      "Progress: 50.2% ... Training loss: 0.321 ... Validation loss: 0.489\r",
      "Progress: 50.2% ... Training loss: 0.315 ... Validation loss: 0.522\r",
      "Progress: 50.2% ... Training loss: 0.282 ... Validation loss: 0.461\r",
      "Progress: 50.3% ... Training loss: 0.276 ... Validation loss: 0.464\r",
      "Progress: 50.3% ... Training loss: 0.271 ... Validation loss: 0.451\r",
      "Progress: 50.3% ... Training loss: 0.270 ... Validation loss: 0.452\r",
      "Progress: 50.3% ... Training loss: 0.271 ... Validation loss: 0.461\r",
      "Progress: 50.3% ... Training loss: 0.271 ... Validation loss: 0.457\r",
      "Progress: 50.3% ... Training loss: 0.292 ... Validation loss: 0.465\r",
      "Progress: 50.4% ... Training loss: 0.310 ... Validation loss: 0.515\r",
      "Progress: 50.4% ... Training loss: 0.276 ... Validation loss: 0.458\r",
      "Progress: 50.4% ... Training loss: 0.270 ... Validation loss: 0.457\r",
      "Progress: 50.4% ... Training loss: 0.280 ... Validation loss: 0.473\r",
      "Progress: 50.4% ... Training loss: 0.286 ... Validation loss: 0.464\r",
      "Progress: 50.5% ... Training loss: 0.270 ... Validation loss: 0.458\r",
      "Progress: 50.5% ... Training loss: 0.280 ... Validation loss: 0.458\r",
      "Progress: 50.5% ... Training loss: 0.300 ... Validation loss: 0.487\r",
      "Progress: 50.5% ... Training loss: 0.281 ... Validation loss: 0.458\r",
      "Progress: 50.5% ... Training loss: 0.270 ... Validation loss: 0.453\r",
      "Progress: 50.5% ... Training loss: 0.270 ... Validation loss: 0.455\r",
      "Progress: 50.6% ... Training loss: 0.275 ... Validation loss: 0.459\r",
      "Progress: 50.6% ... Training loss: 0.289 ... Validation loss: 0.478\r",
      "Progress: 50.6% ... Training loss: 0.276 ... Validation loss: 0.457\r",
      "Progress: 50.6% ... Training loss: 0.270 ... Validation loss: 0.453\r",
      "Progress: 50.6% ... Training loss: 0.270 ... Validation loss: 0.453\r",
      "Progress: 50.7% ... Training loss: 0.295 ... Validation loss: 0.484\r",
      "Progress: 50.7% ... Training loss: 0.272 ... Validation loss: 0.454\r",
      "Progress: 50.7% ... Training loss: 0.276 ... Validation loss: 0.468\r",
      "Progress: 50.7% ... Training loss: 0.336 ... Validation loss: 0.503\r",
      "Progress: 50.7% ... Training loss: 0.346 ... Validation loss: 0.551\r",
      "Progress: 50.7% ... Training loss: 0.271 ... Validation loss: 0.449\r",
      "Progress: 50.8% ... Training loss: 0.271 ... Validation loss: 0.450\r",
      "Progress: 50.8% ... Training loss: 0.271 ... Validation loss: 0.453\r",
      "Progress: 50.8% ... Training loss: 0.269 ... Validation loss: 0.450\r",
      "Progress: 50.8% ... Training loss: 0.279 ... Validation loss: 0.456\r",
      "Progress: 50.8% ... Training loss: 0.272 ... Validation loss: 0.456\r",
      "Progress: 50.9% ... Training loss: 0.272 ... Validation loss: 0.458\r",
      "Progress: 50.9% ... Training loss: 0.316 ... Validation loss: 0.489\r",
      "Progress: 50.9% ... Training loss: 0.321 ... Validation loss: 0.509\r",
      "Progress: 50.9% ... Training loss: 0.353 ... Validation loss: 0.520\r",
      "Progress: 50.9% ... Training loss: 0.291 ... Validation loss: 0.478\r",
      "Progress: 50.9% ... Training loss: 0.277 ... Validation loss: 0.457\r",
      "Progress: 51.0% ... Training loss: 0.273 ... Validation loss: 0.459\r",
      "Progress: 51.0% ... Training loss: 0.269 ... Validation loss: 0.452\r",
      "Progress: 51.0% ... Training loss: 0.269 ... Validation loss: 0.450\r",
      "Progress: 51.0% ... Training loss: 0.283 ... Validation loss: 0.459\r",
      "Progress: 51.0% ... Training loss: 0.302 ... Validation loss: 0.494\r",
      "Progress: 51.1% ... Training loss: 0.269 ... Validation loss: 0.451\r",
      "Progress: 51.1% ... Training loss: 0.270 ... Validation loss: 0.449\r",
      "Progress: 51.1% ... Training loss: 0.271 ... Validation loss: 0.459\r",
      "Progress: 51.1% ... Training loss: 0.269 ... Validation loss: 0.454\r",
      "Progress: 51.1% ... Training loss: 0.274 ... Validation loss: 0.456\r",
      "Progress: 51.1% ... Training loss: 0.274 ... Validation loss: 0.461\r",
      "Progress: 51.2% ... Training loss: 0.280 ... Validation loss: 0.460\r",
      "Progress: 51.2% ... Training loss: 0.323 ... Validation loss: 0.509\r",
      "Progress: 51.2% ... Training loss: 0.362 ... Validation loss: 0.532\r",
      "Progress: 51.2% ... Training loss: 0.342 ... Validation loss: 0.531\r",
      "Progress: 51.2% ... Training loss: 0.350 ... Validation loss: 0.523\r",
      "Progress: 51.3% ... Training loss: 0.376 ... Validation loss: 0.565\r",
      "Progress: 51.3% ... Training loss: 0.356 ... Validation loss: 0.526\r",
      "Progress: 51.3% ... Training loss: 0.300 ... Validation loss: 0.495\r",
      "Progress: 51.3% ... Training loss: 0.308 ... Validation loss: 0.489\r",
      "Progress: 51.3% ... Training loss: 0.332 ... Validation loss: 0.525\r",
      "Progress: 51.3% ... Training loss: 0.394 ... Validation loss: 0.565\r",
      "Progress: 51.4% ... Training loss: 0.351 ... Validation loss: 0.544\r",
      "Progress: 51.4% ... Training loss: 0.338 ... Validation loss: 0.520\r",
      "Progress: 51.4% ... Training loss: 0.364 ... Validation loss: 0.550\r",
      "Progress: 51.4% ... Training loss: 0.313 ... Validation loss: 0.497\r",
      "Progress: 51.4% ... Training loss: 0.304 ... Validation loss: 0.488\r",
      "Progress: 51.5% ... Training loss: 0.295 ... Validation loss: 0.479\r",
      "Progress: 51.5% ... Training loss: 0.275 ... Validation loss: 0.461\r",
      "Progress: 51.5% ... Training loss: 0.271 ... Validation loss: 0.458\r",
      "Progress: 51.5% ... Training loss: 0.273 ... Validation loss: 0.459\r",
      "Progress: 51.5% ... Training loss: 0.273 ... Validation loss: 0.459\r",
      "Progress: 51.5% ... Training loss: 0.273 ... Validation loss: 0.456\r",
      "Progress: 51.6% ... Training loss: 0.344 ... Validation loss: 0.525\r",
      "Progress: 51.6% ... Training loss: 0.326 ... Validation loss: 0.507\r",
      "Progress: 51.6% ... Training loss: 0.290 ... Validation loss: 0.471\r",
      "Progress: 51.6% ... Training loss: 0.313 ... Validation loss: 0.495\r",
      "Progress: 51.6% ... Training loss: 0.269 ... Validation loss: 0.451\r",
      "Progress: 51.7% ... Training loss: 0.271 ... Validation loss: 0.454\r",
      "Progress: 51.7% ... Training loss: 0.268 ... Validation loss: 0.452\r",
      "Progress: 51.7% ... Training loss: 0.272 ... Validation loss: 0.455\r",
      "Progress: 51.7% ... Training loss: 0.279 ... Validation loss: 0.460\r",
      "Progress: 51.7% ... Training loss: 0.277 ... Validation loss: 0.458\r",
      "Progress: 51.7% ... Training loss: 0.286 ... Validation loss: 0.467\r",
      "Progress: 51.8% ... Training loss: 0.269 ... Validation loss: 0.455\r",
      "Progress: 51.8% ... Training loss: 0.282 ... Validation loss: 0.466\r",
      "Progress: 51.8% ... Training loss: 0.282 ... Validation loss: 0.473\r",
      "Progress: 51.8% ... Training loss: 0.270 ... Validation loss: 0.456\r",
      "Progress: 51.8% ... Training loss: 0.271 ... Validation loss: 0.459\r",
      "Progress: 51.9% ... Training loss: 0.272 ... Validation loss: 0.461\r",
      "Progress: 51.9% ... Training loss: 0.274 ... Validation loss: 0.467\r",
      "Progress: 51.9% ... Training loss: 0.299 ... Validation loss: 0.480\r",
      "Progress: 51.9% ... Training loss: 0.280 ... Validation loss: 0.474\r",
      "Progress: 51.9% ... Training loss: 0.293 ... Validation loss: 0.476\r",
      "Progress: 51.9% ... Training loss: 0.334 ... Validation loss: 0.527\r",
      "Progress: 52.0% ... Training loss: 0.278 ... Validation loss: 0.461\r",
      "Progress: 52.0% ... Training loss: 0.292 ... Validation loss: 0.472\r",
      "Progress: 52.0% ... Training loss: 0.269 ... Validation loss: 0.450\r",
      "Progress: 52.0% ... Training loss: 0.284 ... Validation loss: 0.464\r",
      "Progress: 52.0% ... Training loss: 0.281 ... Validation loss: 0.461\r",
      "Progress: 52.1% ... Training loss: 0.271 ... Validation loss: 0.452\r",
      "Progress: 52.1% ... Training loss: 0.268 ... Validation loss: 0.452\r",
      "Progress: 52.1% ... Training loss: 0.279 ... Validation loss: 0.461\r",
      "Progress: 52.1% ... Training loss: 0.281 ... Validation loss: 0.464\r",
      "Progress: 52.1% ... Training loss: 0.284 ... Validation loss: 0.465\r",
      "Progress: 52.1% ... Training loss: 0.288 ... Validation loss: 0.472\r",
      "Progress: 52.2% ... Training loss: 0.268 ... Validation loss: 0.453\r",
      "Progress: 52.2% ... Training loss: 0.268 ... Validation loss: 0.455\r",
      "Progress: 52.2% ... Training loss: 0.277 ... Validation loss: 0.462\r",
      "Progress: 52.2% ... Training loss: 0.281 ... Validation loss: 0.471\r",
      "Progress: 52.2% ... Training loss: 0.287 ... Validation loss: 0.470\r",
      "Progress: 52.3% ... Training loss: 0.297 ... Validation loss: 0.483\r",
      "Progress: 52.3% ... Training loss: 0.321 ... Validation loss: 0.501\r",
      "Progress: 52.3% ... Training loss: 0.322 ... Validation loss: 0.502\r",
      "Progress: 52.3% ... Training loss: 0.269 ... Validation loss: 0.451\r",
      "Progress: 52.3% ... Training loss: 0.287 ... Validation loss: 0.464\r",
      "Progress: 52.3% ... Training loss: 0.274 ... Validation loss: 0.455\r",
      "Progress: 52.4% ... Training loss: 0.273 ... Validation loss: 0.452\r",
      "Progress: 52.4% ... Training loss: 0.268 ... Validation loss: 0.449\r",
      "Progress: 52.4% ... Training loss: 0.270 ... Validation loss: 0.451\r",
      "Progress: 52.4% ... Training loss: 0.272 ... Validation loss: 0.455\r",
      "Progress: 52.4% ... Training loss: 0.271 ... Validation loss: 0.451\r",
      "Progress: 52.5% ... Training loss: 0.280 ... Validation loss: 0.464\r",
      "Progress: 52.5% ... Training loss: 0.272 ... Validation loss: 0.457\r",
      "Progress: 52.5% ... Training loss: 0.269 ... Validation loss: 0.454\r",
      "Progress: 52.5% ... Training loss: 0.269 ... Validation loss: 0.454\r",
      "Progress: 52.5% ... Training loss: 0.290 ... Validation loss: 0.468\r",
      "Progress: 52.5% ... Training loss: 0.268 ... Validation loss: 0.448\r",
      "Progress: 52.6% ... Training loss: 0.268 ... Validation loss: 0.448\r",
      "Progress: 52.6% ... Training loss: 0.297 ... Validation loss: 0.481\r",
      "Progress: 52.6% ... Training loss: 0.271 ... Validation loss: 0.451\r",
      "Progress: 52.6% ... Training loss: 0.268 ... Validation loss: 0.449\r",
      "Progress: 52.6% ... Training loss: 0.295 ... Validation loss: 0.478\r",
      "Progress: 52.7% ... Training loss: 0.277 ... Validation loss: 0.462\r",
      "Progress: 52.7% ... Training loss: 0.295 ... Validation loss: 0.481\r",
      "Progress: 52.7% ... Training loss: 0.333 ... Validation loss: 0.520\r",
      "Progress: 52.7% ... Training loss: 0.307 ... Validation loss: 0.493\r",
      "Progress: 52.7% ... Training loss: 0.271 ... Validation loss: 0.456\r",
      "Progress: 52.7% ... Training loss: 0.269 ... Validation loss: 0.452\r",
      "Progress: 52.8% ... Training loss: 0.268 ... Validation loss: 0.451\r",
      "Progress: 52.8% ... Training loss: 0.268 ... Validation loss: 0.450\r",
      "Progress: 52.8% ... Training loss: 0.268 ... Validation loss: 0.447\r",
      "Progress: 52.8% ... Training loss: 0.269 ... Validation loss: 0.449\r",
      "Progress: 52.8% ... Training loss: 0.280 ... Validation loss: 0.456\r",
      "Progress: 52.9% ... Training loss: 0.270 ... Validation loss: 0.451\r",
      "Progress: 52.9% ... Training loss: 0.274 ... Validation loss: 0.454\r",
      "Progress: 52.9% ... Training loss: 0.312 ... Validation loss: 0.494\r",
      "Progress: 52.9% ... Training loss: 0.317 ... Validation loss: 0.496\r",
      "Progress: 52.9% ... Training loss: 0.308 ... Validation loss: 0.490\r",
      "Progress: 52.9% ... Training loss: 0.269 ... Validation loss: 0.453\r",
      "Progress: 53.0% ... Training loss: 0.274 ... Validation loss: 0.457\r",
      "Progress: 53.0% ... Training loss: 0.283 ... Validation loss: 0.467\r",
      "Progress: 53.0% ... Training loss: 0.276 ... Validation loss: 0.459\r",
      "Progress: 53.0% ... Training loss: 0.277 ... Validation loss: 0.462\r",
      "Progress: 53.0% ... Training loss: 0.270 ... Validation loss: 0.456\r",
      "Progress: 53.1% ... Training loss: 0.283 ... Validation loss: 0.468\r",
      "Progress: 53.1% ... Training loss: 0.280 ... Validation loss: 0.471\r",
      "Progress: 53.1% ... Training loss: 0.294 ... Validation loss: 0.476\r",
      "Progress: 53.1% ... Training loss: 0.282 ... Validation loss: 0.474\r",
      "Progress: 53.1% ... Training loss: 0.268 ... Validation loss: 0.455\r",
      "Progress: 53.1% ... Training loss: 0.269 ... Validation loss: 0.455\r",
      "Progress: 53.2% ... Training loss: 0.269 ... Validation loss: 0.452\r",
      "Progress: 53.2% ... Training loss: 0.271 ... Validation loss: 0.454\r",
      "Progress: 53.2% ... Training loss: 0.268 ... Validation loss: 0.450\r",
      "Progress: 53.2% ... Training loss: 0.278 ... Validation loss: 0.462\r",
      "Progress: 53.2% ... Training loss: 0.276 ... Validation loss: 0.458\r",
      "Progress: 53.3% ... Training loss: 0.286 ... Validation loss: 0.464\r",
      "Progress: 53.3% ... Training loss: 0.287 ... Validation loss: 0.467\r",
      "Progress: 53.3% ... Training loss: 0.295 ... Validation loss: 0.474\r",
      "Progress: 53.3% ... Training loss: 0.268 ... Validation loss: 0.451\r",
      "Progress: 53.3% ... Training loss: 0.269 ... Validation loss: 0.453\r",
      "Progress: 53.3% ... Training loss: 0.290 ... Validation loss: 0.469\r",
      "Progress: 53.4% ... Training loss: 0.268 ... Validation loss: 0.457\r",
      "Progress: 53.4% ... Training loss: 0.269 ... Validation loss: 0.456\r",
      "Progress: 53.4% ... Training loss: 0.268 ... Validation loss: 0.458\r",
      "Progress: 53.4% ... Training loss: 0.276 ... Validation loss: 0.468\r",
      "Progress: 53.4% ... Training loss: 0.274 ... Validation loss: 0.453\r",
      "Progress: 53.5% ... Training loss: 0.268 ... Validation loss: 0.451\r",
      "Progress: 53.5% ... Training loss: 0.277 ... Validation loss: 0.468\r",
      "Progress: 53.5% ... Training loss: 0.305 ... Validation loss: 0.482\r",
      "Progress: 53.5% ... Training loss: 0.298 ... Validation loss: 0.491\r",
      "Progress: 53.5% ... Training loss: 0.276 ... Validation loss: 0.459\r",
      "Progress: 53.5% ... Training loss: 0.288 ... Validation loss: 0.471\r",
      "Progress: 53.6% ... Training loss: 0.270 ... Validation loss: 0.463\r",
      "Progress: 53.6% ... Training loss: 0.271 ... Validation loss: 0.458\r",
      "Progress: 53.6% ... Training loss: 0.286 ... Validation loss: 0.475\r",
      "Progress: 53.6% ... Training loss: 0.283 ... Validation loss: 0.466\r",
      "Progress: 53.6% ... Training loss: 0.303 ... Validation loss: 0.487\r",
      "Progress: 53.7% ... Training loss: 0.275 ... Validation loss: 0.455\r",
      "Progress: 53.7% ... Training loss: 0.269 ... Validation loss: 0.452\r",
      "Progress: 53.7% ... Training loss: 0.270 ... Validation loss: 0.452\r",
      "Progress: 53.7% ... Training loss: 0.268 ... Validation loss: 0.451\r",
      "Progress: 53.7% ... Training loss: 0.268 ... Validation loss: 0.449\r",
      "Progress: 53.7% ... Training loss: 0.274 ... Validation loss: 0.454\r",
      "Progress: 53.8% ... Training loss: 0.269 ... Validation loss: 0.449\r",
      "Progress: 53.8% ... Training loss: 0.269 ... Validation loss: 0.452\r",
      "Progress: 53.8% ... Training loss: 0.268 ... Validation loss: 0.451\r",
      "Progress: 53.8% ... Training loss: 0.267 ... Validation loss: 0.447\r",
      "Progress: 53.8% ... Training loss: 0.285 ... Validation loss: 0.468\r",
      "Progress: 53.9% ... Training loss: 0.329 ... Validation loss: 0.506\r",
      "Progress: 53.9% ... Training loss: 0.326 ... Validation loss: 0.505\r",
      "Progress: 53.9% ... Training loss: 0.351 ... Validation loss: 0.530\r",
      "Progress: 53.9% ... Training loss: 0.333 ... Validation loss: 0.518\r",
      "Progress: 53.9% ... Training loss: 0.343 ... Validation loss: 0.522\r",
      "Progress: 53.9% ... Training loss: 0.317 ... Validation loss: 0.500\r",
      "Progress: 54.0% ... Training loss: 0.268 ... Validation loss: 0.452\r",
      "Progress: 54.0% ... Training loss: 0.274 ... Validation loss: 0.450\r",
      "Progress: 54.0% ... Training loss: 0.280 ... Validation loss: 0.455\r",
      "Progress: 54.0% ... Training loss: 0.271 ... Validation loss: 0.451\r",
      "Progress: 54.0% ... Training loss: 0.268 ... Validation loss: 0.448\r",
      "Progress: 54.1% ... Training loss: 0.268 ... Validation loss: 0.449\r",
      "Progress: 54.1% ... Training loss: 0.277 ... Validation loss: 0.461\r",
      "Progress: 54.1% ... Training loss: 0.274 ... Validation loss: 0.460\r",
      "Progress: 54.1% ... Training loss: 0.299 ... Validation loss: 0.480\r",
      "Progress: 54.1% ... Training loss: 0.340 ... Validation loss: 0.523\r",
      "Progress: 54.1% ... Training loss: 0.305 ... Validation loss: 0.486\r",
      "Progress: 54.2% ... Training loss: 0.283 ... Validation loss: 0.470\r",
      "Progress: 54.2% ... Training loss: 0.268 ... Validation loss: 0.454\r",
      "Progress: 54.2% ... Training loss: 0.268 ... Validation loss: 0.454\r",
      "Progress: 54.2% ... Training loss: 0.282 ... Validation loss: 0.472\r",
      "Progress: 54.2% ... Training loss: 0.273 ... Validation loss: 0.459\r",
      "Progress: 54.3% ... Training loss: 0.270 ... Validation loss: 0.456\r",
      "Progress: 54.3% ... Training loss: 0.267 ... Validation loss: 0.453\r",
      "Progress: 54.3% ... Training loss: 0.290 ... Validation loss: 0.474\r",
      "Progress: 54.3% ... Training loss: 0.292 ... Validation loss: 0.474\r",
      "Progress: 54.3% ... Training loss: 0.273 ... Validation loss: 0.459\r",
      "Progress: 54.3% ... Training loss: 0.268 ... Validation loss: 0.451\r",
      "Progress: 54.4% ... Training loss: 0.275 ... Validation loss: 0.457\r",
      "Progress: 54.4% ... Training loss: 0.269 ... Validation loss: 0.454\r",
      "Progress: 54.4% ... Training loss: 0.267 ... Validation loss: 0.452\r",
      "Progress: 54.4% ... Training loss: 0.266 ... Validation loss: 0.453\r",
      "Progress: 54.4% ... Training loss: 0.270 ... Validation loss: 0.454\r",
      "Progress: 54.5% ... Training loss: 0.269 ... Validation loss: 0.458\r",
      "Progress: 54.5% ... Training loss: 0.268 ... Validation loss: 0.459\r",
      "Progress: 54.5% ... Training loss: 0.275 ... Validation loss: 0.462\r",
      "Progress: 54.5% ... Training loss: 0.267 ... Validation loss: 0.461\r",
      "Progress: 54.5% ... Training loss: 0.269 ... Validation loss: 0.456\r",
      "Progress: 54.5% ... Training loss: 0.267 ... Validation loss: 0.456\r",
      "Progress: 54.6% ... Training loss: 0.266 ... Validation loss: 0.455\r",
      "Progress: 54.6% ... Training loss: 0.288 ... Validation loss: 0.481\r",
      "Progress: 54.6% ... Training loss: 0.281 ... Validation loss: 0.464\r",
      "Progress: 54.6% ... Training loss: 0.266 ... Validation loss: 0.455\r",
      "Progress: 54.6% ... Training loss: 0.276 ... Validation loss: 0.460\r",
      "Progress: 54.7% ... Training loss: 0.268 ... Validation loss: 0.453\r",
      "Progress: 54.7% ... Training loss: 0.300 ... Validation loss: 0.490\r",
      "Progress: 54.7% ... Training loss: 0.312 ... Validation loss: 0.490\r",
      "Progress: 54.7% ... Training loss: 0.287 ... Validation loss: 0.477\r",
      "Progress: 54.7% ... Training loss: 0.271 ... Validation loss: 0.451\r",
      "Progress: 54.7% ... Training loss: 0.292 ... Validation loss: 0.482\r",
      "Progress: 54.8% ... Training loss: 0.293 ... Validation loss: 0.468\r",
      "Progress: 54.8% ... Training loss: 0.294 ... Validation loss: 0.484\r",
      "Progress: 54.8% ... Training loss: 0.289 ... Validation loss: 0.469\r",
      "Progress: 54.8% ... Training loss: 0.282 ... Validation loss: 0.471\r",
      "Progress: 54.8% ... Training loss: 0.318 ... Validation loss: 0.496\r",
      "Progress: 54.9% ... Training loss: 0.268 ... Validation loss: 0.461\r",
      "Progress: 54.9% ... Training loss: 0.269 ... Validation loss: 0.457\r",
      "Progress: 54.9% ... Training loss: 0.266 ... Validation loss: 0.459\r",
      "Progress: 54.9% ... Training loss: 0.274 ... Validation loss: 0.468\r",
      "Progress: 54.9% ... Training loss: 0.305 ... Validation loss: 0.484\r",
      "Progress: 54.9% ... Training loss: 0.306 ... Validation loss: 0.510\r",
      "Progress: 55.0% ... Training loss: 0.294 ... Validation loss: 0.474\r",
      "Progress: 55.0% ... Training loss: 0.274 ... Validation loss: 0.468\r",
      "Progress: 55.0% ... Training loss: 0.267 ... Validation loss: 0.455\r",
      "Progress: 55.0% ... Training loss: 0.268 ... Validation loss: 0.463\r",
      "Progress: 55.0% ... Training loss: 0.267 ... Validation loss: 0.453\r",
      "Progress: 55.1% ... Training loss: 0.266 ... Validation loss: 0.456\r",
      "Progress: 55.1% ... Training loss: 0.269 ... Validation loss: 0.453\r",
      "Progress: 55.1% ... Training loss: 0.271 ... Validation loss: 0.463\r",
      "Progress: 55.1% ... Training loss: 0.266 ... Validation loss: 0.455\r",
      "Progress: 55.1% ... Training loss: 0.279 ... Validation loss: 0.480\r",
      "Progress: 55.1% ... Training loss: 0.267 ... Validation loss: 0.457\r",
      "Progress: 55.2% ... Training loss: 0.266 ... Validation loss: 0.461\r",
      "Progress: 55.2% ... Training loss: 0.275 ... Validation loss: 0.460\r",
      "Progress: 55.2% ... Training loss: 0.268 ... Validation loss: 0.456\r",
      "Progress: 55.2% ... Training loss: 0.272 ... Validation loss: 0.470\r",
      "Progress: 55.2% ... Training loss: 0.280 ... Validation loss: 0.463\r",
      "Progress: 55.3% ... Training loss: 0.266 ... Validation loss: 0.459\r",
      "Progress: 55.3% ... Training loss: 0.268 ... Validation loss: 0.459\r",
      "Progress: 55.3% ... Training loss: 0.267 ... Validation loss: 0.463\r",
      "Progress: 55.3% ... Training loss: 0.270 ... Validation loss: 0.467\r",
      "Progress: 55.3% ... Training loss: 0.279 ... Validation loss: 0.463\r",
      "Progress: 55.3% ... Training loss: 0.275 ... Validation loss: 0.476\r",
      "Progress: 55.4% ... Training loss: 0.266 ... Validation loss: 0.459\r",
      "Progress: 55.4% ... Training loss: 0.270 ... Validation loss: 0.457\r",
      "Progress: 55.4% ... Training loss: 0.274 ... Validation loss: 0.469\r",
      "Progress: 55.4% ... Training loss: 0.290 ... Validation loss: 0.471\r",
      "Progress: 55.4% ... Training loss: 0.296 ... Validation loss: 0.496\r",
      "Progress: 55.5% ... Training loss: 0.297 ... Validation loss: 0.477\r",
      "Progress: 55.5% ... Training loss: 0.272 ... Validation loss: 0.465\r",
      "Progress: 55.5% ... Training loss: 0.266 ... Validation loss: 0.456\r",
      "Progress: 55.5% ... Training loss: 0.288 ... Validation loss: 0.471\r",
      "Progress: 55.5% ... Training loss: 0.302 ... Validation loss: 0.502\r",
      "Progress: 55.5% ... Training loss: 0.322 ... Validation loss: 0.496\r",
      "Progress: 55.6% ... Training loss: 0.340 ... Validation loss: 0.544\r",
      "Progress: 55.6% ... Training loss: 0.329 ... Validation loss: 0.498\r",
      "Progress: 55.6% ... Training loss: 0.309 ... Validation loss: 0.511\r",
      "Progress: 55.6% ... Training loss: 0.306 ... Validation loss: 0.481\r",
      "Progress: 55.6% ... Training loss: 0.298 ... Validation loss: 0.499\r",
      "Progress: 55.7% ... Training loss: 0.281 ... Validation loss: 0.463\r",
      "Progress: 55.7% ... Training loss: 0.274 ... Validation loss: 0.469\r",
      "Progress: 55.7% ... Training loss: 0.316 ... Validation loss: 0.490\r",
      "Progress: 55.7% ... Training loss: 0.289 ... Validation loss: 0.496\r",
      "Progress: 55.7% ... Training loss: 0.271 ... Validation loss: 0.459\r",
      "Progress: 55.7% ... Training loss: 0.278 ... Validation loss: 0.474\r",
      "Progress: 55.8% ... Training loss: 0.270 ... Validation loss: 0.459\r",
      "Progress: 55.8% ... Training loss: 0.266 ... Validation loss: 0.459\r",
      "Progress: 55.8% ... Training loss: 0.284 ... Validation loss: 0.468\r",
      "Progress: 55.8% ... Training loss: 0.266 ... Validation loss: 0.458\r",
      "Progress: 55.8% ... Training loss: 0.266 ... Validation loss: 0.457\r",
      "Progress: 55.9% ... Training loss: 0.266 ... Validation loss: 0.458\r",
      "Progress: 55.9% ... Training loss: 0.266 ... Validation loss: 0.458\r",
      "Progress: 55.9% ... Training loss: 0.269 ... Validation loss: 0.462\r",
      "Progress: 55.9% ... Training loss: 0.266 ... Validation loss: 0.454\r",
      "Progress: 55.9% ... Training loss: 0.266 ... Validation loss: 0.453\r",
      "Progress: 55.9% ... Training loss: 0.271 ... Validation loss: 0.459\r",
      "Progress: 56.0% ... Training loss: 0.276 ... Validation loss: 0.456\r",
      "Progress: 56.0% ... Training loss: 0.267 ... Validation loss: 0.452\r",
      "Progress: 56.0% ... Training loss: 0.271 ... Validation loss: 0.459\r",
      "Progress: 56.0% ... Training loss: 0.286 ... Validation loss: 0.465\r",
      "Progress: 56.0% ... Training loss: 0.307 ... Validation loss: 0.499\r",
      "Progress: 56.1% ... Training loss: 0.337 ... Validation loss: 0.506\r",
      "Progress: 56.1% ... Training loss: 0.344 ... Validation loss: 0.540\r",
      "Progress: 56.1% ... Training loss: 0.302 ... Validation loss: 0.475\r",
      "Progress: 56.1% ... Training loss: 0.341 ... Validation loss: 0.534\r",
      "Progress: 56.1% ... Training loss: 0.318 ... Validation loss: 0.488\r",
      "Progress: 56.1% ... Training loss: 0.290 ... Validation loss: 0.476\r",
      "Progress: 56.2% ... Training loss: 0.267 ... Validation loss: 0.446\r",
      "Progress: 56.2% ... Training loss: 0.277 ... Validation loss: 0.455\r",
      "Progress: 56.2% ... Training loss: 0.266 ... Validation loss: 0.448\r",
      "Progress: 56.2% ... Training loss: 0.267 ... Validation loss: 0.448\r",
      "Progress: 56.2% ... Training loss: 0.267 ... Validation loss: 0.450\r",
      "Progress: 56.3% ... Training loss: 0.283 ... Validation loss: 0.466\r",
      "Progress: 56.3% ... Training loss: 0.296 ... Validation loss: 0.473\r",
      "Progress: 56.3% ... Training loss: 0.280 ... Validation loss: 0.464\r",
      "Progress: 56.3% ... Training loss: 0.266 ... Validation loss: 0.447\r",
      "Progress: 56.3% ... Training loss: 0.268 ... Validation loss: 0.448\r",
      "Progress: 56.3% ... Training loss: 0.270 ... Validation loss: 0.456\r",
      "Progress: 56.4% ... Training loss: 0.269 ... Validation loss: 0.453\r",
      "Progress: 56.4% ... Training loss: 0.266 ... Validation loss: 0.449\r",
      "Progress: 56.4% ... Training loss: 0.269 ... Validation loss: 0.453\r",
      "Progress: 56.4% ... Training loss: 0.284 ... Validation loss: 0.463\r",
      "Progress: 56.4% ... Training loss: 0.265 ... Validation loss: 0.452\r",
      "Progress: 56.5% ... Training loss: 0.276 ... Validation loss: 0.464\r",
      "Progress: 56.5% ... Training loss: 0.270 ... Validation loss: 0.450\r",
      "Progress: 56.5% ... Training loss: 0.279 ... Validation loss: 0.460\r",
      "Progress: 56.5% ... Training loss: 0.269 ... Validation loss: 0.462\r",
      "Progress: 56.5% ... Training loss: 0.268 ... Validation loss: 0.457\r",
      "Progress: 56.5% ... Training loss: 0.267 ... Validation loss: 0.461\r",
      "Progress: 56.6% ... Training loss: 0.309 ... Validation loss: 0.483\r",
      "Progress: 56.6% ... Training loss: 0.285 ... Validation loss: 0.485\r",
      "Progress: 56.6% ... Training loss: 0.268 ... Validation loss: 0.451\r",
      "Progress: 56.6% ... Training loss: 0.265 ... Validation loss: 0.454\r",
      "Progress: 56.6% ... Training loss: 0.266 ... Validation loss: 0.454\r",
      "Progress: 56.7% ... Training loss: 0.268 ... Validation loss: 0.452\r",
      "Progress: 56.7% ... Training loss: 0.265 ... Validation loss: 0.454\r",
      "Progress: 56.7% ... Training loss: 0.271 ... Validation loss: 0.452\r",
      "Progress: 56.7% ... Training loss: 0.265 ... Validation loss: 0.452\r",
      "Progress: 56.7% ... Training loss: 0.278 ... Validation loss: 0.458\r",
      "Progress: 56.7% ... Training loss: 0.269 ... Validation loss: 0.455\r",
      "Progress: 56.8% ... Training loss: 0.275 ... Validation loss: 0.472\r",
      "Progress: 56.8% ... Training loss: 0.270 ... Validation loss: 0.454\r",
      "Progress: 56.8% ... Training loss: 0.277 ... Validation loss: 0.468\r",
      "Progress: 56.8% ... Training loss: 0.299 ... Validation loss: 0.470\r",
      "Progress: 56.8% ... Training loss: 0.303 ... Validation loss: 0.507\r",
      "Progress: 56.9% ... Training loss: 0.279 ... Validation loss: 0.457\r",
      "Progress: 56.9% ... Training loss: 0.277 ... Validation loss: 0.468\r",
      "Progress: 56.9% ... Training loss: 0.264 ... Validation loss: 0.447\r",
      "Progress: 56.9% ... Training loss: 0.271 ... Validation loss: 0.460\r",
      "Progress: 56.9% ... Training loss: 0.288 ... Validation loss: 0.483\r",
      "Progress: 56.9% ... Training loss: 0.319 ... Validation loss: 0.485\r",
      "Progress: 57.0% ... Training loss: 0.267 ... Validation loss: 0.459\r",
      "Progress: 57.0% ... Training loss: 0.268 ... Validation loss: 0.463\r",
      "Progress: 57.0% ... Training loss: 0.271 ... Validation loss: 0.451\r",
      "Progress: 57.0% ... Training loss: 0.265 ... Validation loss: 0.455\r",
      "Progress: 57.0% ... Training loss: 0.264 ... Validation loss: 0.451\r",
      "Progress: 57.1% ... Training loss: 0.272 ... Validation loss: 0.453\r",
      "Progress: 57.1% ... Training loss: 0.306 ... Validation loss: 0.502\r",
      "Progress: 57.1% ... Training loss: 0.297 ... Validation loss: 0.471\r",
      "Progress: 57.1% ... Training loss: 0.323 ... Validation loss: 0.515\r",
      "Progress: 57.1% ... Training loss: 0.353 ... Validation loss: 0.517\r",
      "Progress: 57.1% ... Training loss: 0.291 ... Validation loss: 0.484\r",
      "Progress: 57.2% ... Training loss: 0.265 ... Validation loss: 0.447\r",
      "Progress: 57.2% ... Training loss: 0.277 ... Validation loss: 0.456\r",
      "Progress: 57.2% ... Training loss: 0.280 ... Validation loss: 0.472\r",
      "Progress: 57.2% ... Training loss: 0.265 ... Validation loss: 0.447\r",
      "Progress: 57.2% ... Training loss: 0.265 ... Validation loss: 0.448\r",
      "Progress: 57.3% ... Training loss: 0.280 ... Validation loss: 0.457\r",
      "Progress: 57.3% ... Training loss: 0.268 ... Validation loss: 0.452\r",
      "Progress: 57.3% ... Training loss: 0.268 ... Validation loss: 0.448\r",
      "Progress: 57.3% ... Training loss: 0.265 ... Validation loss: 0.447\r",
      "Progress: 57.3% ... Training loss: 0.268 ... Validation loss: 0.450\r",
      "Progress: 57.3% ... Training loss: 0.266 ... Validation loss: 0.444\r",
      "Progress: 57.4% ... Training loss: 0.265 ... Validation loss: 0.444\r",
      "Progress: 57.4% ... Training loss: 0.269 ... Validation loss: 0.449\r",
      "Progress: 57.4% ... Training loss: 0.302 ... Validation loss: 0.490\r",
      "Progress: 57.4% ... Training loss: 0.298 ... Validation loss: 0.474\r",
      "Progress: 57.4% ... Training loss: 0.282 ... Validation loss: 0.475\r",
      "Progress: 57.5% ... Training loss: 0.281 ... Validation loss: 0.460\r",
      "Progress: 57.5% ... Training loss: 0.264 ... Validation loss: 0.450\r",
      "Progress: 57.5% ... Training loss: 0.265 ... Validation loss: 0.449\r",
      "Progress: 57.5% ... Training loss: 0.265 ... Validation loss: 0.448\r",
      "Progress: 57.5% ... Training loss: 0.266 ... Validation loss: 0.450\r",
      "Progress: 57.5% ... Training loss: 0.270 ... Validation loss: 0.460\r",
      "Progress: 57.6% ... Training loss: 0.271 ... Validation loss: 0.457\r",
      "Progress: 57.6% ... Training loss: 0.265 ... Validation loss: 0.455\r",
      "Progress: 57.6% ... Training loss: 0.282 ... Validation loss: 0.474\r",
      "Progress: 57.6% ... Training loss: 0.270 ... Validation loss: 0.455\r",
      "Progress: 57.6% ... Training loss: 0.274 ... Validation loss: 0.458\r",
      "Progress: 57.7% ... Training loss: 0.292 ... Validation loss: 0.474\r",
      "Progress: 57.7% ... Training loss: 0.299 ... Validation loss: 0.479\r",
      "Progress: 57.7% ... Training loss: 0.296 ... Validation loss: 0.481\r",
      "Progress: 57.7% ... Training loss: 0.392 ... Validation loss: 0.572\r",
      "Progress: 57.7% ... Training loss: 0.311 ... Validation loss: 0.492\r",
      "Progress: 57.7% ... Training loss: 0.276 ... Validation loss: 0.461\r",
      "Progress: 57.8% ... Training loss: 0.267 ... Validation loss: 0.451\r",
      "Progress: 57.8% ... Training loss: 0.265 ... Validation loss: 0.448\r",
      "Progress: 57.8% ... Training loss: 0.266 ... Validation loss: 0.447\r",
      "Progress: 57.8% ... Training loss: 0.294 ... Validation loss: 0.475\r",
      "Progress: 57.8% ... Training loss: 0.282 ... Validation loss: 0.463\r",
      "Progress: 57.9% ... Training loss: 0.276 ... Validation loss: 0.458\r",
      "Progress: 57.9% ... Training loss: 0.278 ... Validation loss: 0.466\r",
      "Progress: 57.9% ... Training loss: 0.264 ... Validation loss: 0.448\r",
      "Progress: 57.9% ... Training loss: 0.284 ... Validation loss: 0.464\r",
      "Progress: 57.9% ... Training loss: 0.295 ... Validation loss: 0.479\r",
      "Progress: 57.9% ... Training loss: 0.283 ... Validation loss: 0.462\r",
      "Progress: 58.0% ... Training loss: 0.309 ... Validation loss: 0.495\r",
      "Progress: 58.0% ... Training loss: 0.277 ... Validation loss: 0.454\r",
      "Progress: 58.0% ... Training loss: 0.333 ... Validation loss: 0.517\r",
      "Progress: 58.0% ... Training loss: 0.352 ... Validation loss: 0.519\r",
      "Progress: 58.0% ... Training loss: 0.388 ... Validation loss: 0.574\r",
      "Progress: 58.1% ... Training loss: 0.310 ... Validation loss: 0.481\r",
      "Progress: 58.1% ... Training loss: 0.323 ... Validation loss: 0.505\r",
      "Progress: 58.1% ... Training loss: 0.328 ... Validation loss: 0.499\r",
      "Progress: 58.1% ... Training loss: 0.315 ... Validation loss: 0.513\r",
      "Progress: 58.1% ... Training loss: 0.310 ... Validation loss: 0.485\r",
      "Progress: 58.1% ... Training loss: 0.335 ... Validation loss: 0.531\r",
      "Progress: 58.2% ... Training loss: 0.271 ... Validation loss: 0.453\r",
      "Progress: 58.2% ... Training loss: 0.267 ... Validation loss: 0.452\r",
      "Progress: 58.2% ... Training loss: 0.269 ... Validation loss: 0.459\r",
      "Progress: 58.2% ... Training loss: 0.276 ... Validation loss: 0.458\r",
      "Progress: 58.2% ... Training loss: 0.268 ... Validation loss: 0.461\r",
      "Progress: 58.3% ... Training loss: 0.266 ... Validation loss: 0.457\r",
      "Progress: 58.3% ... Training loss: 0.290 ... Validation loss: 0.465\r",
      "Progress: 58.3% ... Training loss: 0.309 ... Validation loss: 0.501\r",
      "Progress: 58.3% ... Training loss: 0.312 ... Validation loss: 0.484\r",
      "Progress: 58.3% ... Training loss: 0.281 ... Validation loss: 0.475\r",
      "Progress: 58.3% ... Training loss: 0.269 ... Validation loss: 0.452\r",
      "Progress: 58.4% ... Training loss: 0.268 ... Validation loss: 0.452\r",
      "Progress: 58.4% ... Training loss: 0.271 ... Validation loss: 0.462\r",
      "Progress: 58.4% ... Training loss: 0.264 ... Validation loss: 0.450\r",
      "Progress: 58.4% ... Training loss: 0.282 ... Validation loss: 0.465\r",
      "Progress: 58.4% ... Training loss: 0.283 ... Validation loss: 0.475\r",
      "Progress: 58.5% ... Training loss: 0.271 ... Validation loss: 0.455\r",
      "Progress: 58.5% ... Training loss: 0.273 ... Validation loss: 0.463\r",
      "Progress: 58.5% ... Training loss: 0.264 ... Validation loss: 0.450\r",
      "Progress: 58.5% ... Training loss: 0.267 ... Validation loss: 0.456\r",
      "Progress: 58.5% ... Training loss: 0.264 ... Validation loss: 0.450\r",
      "Progress: 58.5% ... Training loss: 0.264 ... Validation loss: 0.448\r",
      "Progress: 58.6% ... Training loss: 0.275 ... Validation loss: 0.464\r",
      "Progress: 58.6% ... Training loss: 0.269 ... Validation loss: 0.453\r",
      "Progress: 58.6% ... Training loss: 0.268 ... Validation loss: 0.456\r",
      "Progress: 58.6% ... Training loss: 0.280 ... Validation loss: 0.462\r",
      "Progress: 58.6% ... Training loss: 0.270 ... Validation loss: 0.461\r",
      "Progress: 58.7% ... Training loss: 0.290 ... Validation loss: 0.470\r",
      "Progress: 58.7% ... Training loss: 0.278 ... Validation loss: 0.467\r",
      "Progress: 58.7% ... Training loss: 0.270 ... Validation loss: 0.454\r",
      "Progress: 58.7% ... Training loss: 0.267 ... Validation loss: 0.456\r",
      "Progress: 58.7% ... Training loss: 0.275 ... Validation loss: 0.458\r",
      "Progress: 58.7% ... Training loss: 0.275 ... Validation loss: 0.467\r",
      "Progress: 58.8% ... Training loss: 0.272 ... Validation loss: 0.453\r",
      "Progress: 58.8% ... Training loss: 0.276 ... Validation loss: 0.464\r",
      "Progress: 58.8% ... Training loss: 0.293 ... Validation loss: 0.472\r",
      "Progress: 58.8% ... Training loss: 0.288 ... Validation loss: 0.476\r",
      "Progress: 58.8% ... Training loss: 0.264 ... Validation loss: 0.446\r",
      "Progress: 58.9% ... Training loss: 0.263 ... Validation loss: 0.447\r",
      "Progress: 58.9% ... Training loss: 0.269 ... Validation loss: 0.451\r",
      "Progress: 58.9% ... Training loss: 0.269 ... Validation loss: 0.454\r",
      "Progress: 58.9% ... Training loss: 0.263 ... Validation loss: 0.448\r",
      "Progress: 58.9% ... Training loss: 0.266 ... Validation loss: 0.449\r",
      "Progress: 58.9% ... Training loss: 0.274 ... Validation loss: 0.457\r",
      "Progress: 59.0% ... Training loss: 0.295 ... Validation loss: 0.482\r",
      "Progress: 59.0% ... Training loss: 0.309 ... Validation loss: 0.486\r",
      "Progress: 59.0% ... Training loss: 0.280 ... Validation loss: 0.468\r",
      "Progress: 59.0% ... Training loss: 0.316 ... Validation loss: 0.490\r",
      "Progress: 59.0% ... Training loss: 0.301 ... Validation loss: 0.491\r",
      "Progress: 59.1% ... Training loss: 0.329 ... Validation loss: 0.501\r",
      "Progress: 59.1% ... Training loss: 0.266 ... Validation loss: 0.458\r",
      "Progress: 59.1% ... Training loss: 0.267 ... Validation loss: 0.453\r",
      "Progress: 59.1% ... Training loss: 0.268 ... Validation loss: 0.463\r",
      "Progress: 59.1% ... Training loss: 0.277 ... Validation loss: 0.472\r",
      "Progress: 59.1% ... Training loss: 0.272 ... Validation loss: 0.454\r",
      "Progress: 59.2% ... Training loss: 0.263 ... Validation loss: 0.449\r",
      "Progress: 59.2% ... Training loss: 0.264 ... Validation loss: 0.449\r",
      "Progress: 59.2% ... Training loss: 0.265 ... Validation loss: 0.455\r",
      "Progress: 59.2% ... Training loss: 0.272 ... Validation loss: 0.453\r",
      "Progress: 59.2% ... Training loss: 0.265 ... Validation loss: 0.455\r",
      "Progress: 59.3% ... Training loss: 0.263 ... Validation loss: 0.447\r",
      "Progress: 59.3% ... Training loss: 0.266 ... Validation loss: 0.451\r",
      "Progress: 59.3% ... Training loss: 0.266 ... Validation loss: 0.453\r",
      "Progress: 59.3% ... Training loss: 0.266 ... Validation loss: 0.449\r",
      "Progress: 59.3% ... Training loss: 0.279 ... Validation loss: 0.471\r",
      "Progress: 59.3% ... Training loss: 0.268 ... Validation loss: 0.458\r",
      "Progress: 59.4% ... Training loss: 0.264 ... Validation loss: 0.452\r",
      "Progress: 59.4% ... Training loss: 0.263 ... Validation loss: 0.450\r",
      "Progress: 59.4% ... Training loss: 0.263 ... Validation loss: 0.448\r",
      "Progress: 59.4% ... Training loss: 0.263 ... Validation loss: 0.450\r",
      "Progress: 59.4% ... Training loss: 0.282 ... Validation loss: 0.477\r",
      "Progress: 59.5% ... Training loss: 0.264 ... Validation loss: 0.450\r",
      "Progress: 59.5% ... Training loss: 0.280 ... Validation loss: 0.478\r",
      "Progress: 59.5% ... Training loss: 0.283 ... Validation loss: 0.463\r",
      "Progress: 59.5% ... Training loss: 0.263 ... Validation loss: 0.450\r",
      "Progress: 59.5% ... Training loss: 0.284 ... Validation loss: 0.477\r",
      "Progress: 59.5% ... Training loss: 0.291 ... Validation loss: 0.469\r",
      "Progress: 59.6% ... Training loss: 0.297 ... Validation loss: 0.498\r",
      "Progress: 59.6% ... Training loss: 0.267 ... Validation loss: 0.452\r",
      "Progress: 59.6% ... Training loss: 0.265 ... Validation loss: 0.456\r",
      "Progress: 59.6% ... Training loss: 0.263 ... Validation loss: 0.451\r",
      "Progress: 59.6% ... Training loss: 0.271 ... Validation loss: 0.451\r",
      "Progress: 59.7% ... Training loss: 0.302 ... Validation loss: 0.502\r",
      "Progress: 59.7% ... Training loss: 0.292 ... Validation loss: 0.466\r",
      "Progress: 59.7% ... Training loss: 0.264 ... Validation loss: 0.448\r",
      "Progress: 59.7% ... Training loss: 0.265 ... Validation loss: 0.450\r",
      "Progress: 59.7% ... Training loss: 0.263 ... Validation loss: 0.444\r",
      "Progress: 59.7% ... Training loss: 0.287 ... Validation loss: 0.475\r",
      "Progress: 59.8% ... Training loss: 0.265 ... Validation loss: 0.445\r",
      "Progress: 59.8% ... Training loss: 0.262 ... Validation loss: 0.447\r",
      "Progress: 59.8% ... Training loss: 0.263 ... Validation loss: 0.443\r",
      "Progress: 59.8% ... Training loss: 0.262 ... Validation loss: 0.448\r",
      "Progress: 59.8% ... Training loss: 0.286 ... Validation loss: 0.460\r",
      "Progress: 59.9% ... Training loss: 0.291 ... Validation loss: 0.492\r",
      "Progress: 59.9% ... Training loss: 0.337 ... Validation loss: 0.500\r",
      "Progress: 59.9% ... Training loss: 0.273 ... Validation loss: 0.471\r",
      "Progress: 59.9% ... Training loss: 0.264 ... Validation loss: 0.455\r",
      "Progress: 59.9% ... Training loss: 0.279 ... Validation loss: 0.477\r",
      "Progress: 59.9% ... Training loss: 0.313 ... Validation loss: 0.479\r",
      "Progress: 60.0% ... Training loss: 0.275 ... Validation loss: 0.467\r",
      "Progress: 60.0% ... Training loss: 0.286 ... Validation loss: 0.462\r",
      "Progress: 60.0% ... Training loss: 0.264 ... Validation loss: 0.458\r",
      "Progress: 60.0% ... Training loss: 0.289 ... Validation loss: 0.467\r",
      "Progress: 60.0% ... Training loss: 0.274 ... Validation loss: 0.476\r",
      "Progress: 60.1% ... Training loss: 0.266 ... Validation loss: 0.455\r",
      "Progress: 60.1% ... Training loss: 0.264 ... Validation loss: 0.460\r",
      "Progress: 60.1% ... Training loss: 0.264 ... Validation loss: 0.462\r",
      "Progress: 60.1% ... Training loss: 0.265 ... Validation loss: 0.463\r",
      "Progress: 60.1% ... Training loss: 0.262 ... Validation loss: 0.453\r",
      "Progress: 60.1% ... Training loss: 0.269 ... Validation loss: 0.467\r",
      "Progress: 60.2% ... Training loss: 0.263 ... Validation loss: 0.453\r",
      "Progress: 60.2% ... Training loss: 0.268 ... Validation loss: 0.451\r",
      "Progress: 60.2% ... Training loss: 0.263 ... Validation loss: 0.457\r",
      "Progress: 60.2% ... Training loss: 0.299 ... Validation loss: 0.508\r",
      "Progress: 60.2% ... Training loss: 0.371 ... Validation loss: 0.523\r",
      "Progress: 60.3% ... Training loss: 0.341 ... Validation loss: 0.558\r",
      "Progress: 60.3% ... Training loss: 0.371 ... Validation loss: 0.520\r",
      "Progress: 60.3% ... Training loss: 0.287 ... Validation loss: 0.496\r",
      "Progress: 60.3% ... Training loss: 0.265 ... Validation loss: 0.449\r",
      "Progress: 60.3% ... Training loss: 0.280 ... Validation loss: 0.477\r",
      "Progress: 60.3% ... Training loss: 0.262 ... Validation loss: 0.450\r",
      "Progress: 60.4% ... Training loss: 0.268 ... Validation loss: 0.451\r",
      "Progress: 60.4% ... Training loss: 0.263 ... Validation loss: 0.453\r",
      "Progress: 60.4% ... Training loss: 0.270 ... Validation loss: 0.452\r",
      "Progress: 60.4% ... Training loss: 0.266 ... Validation loss: 0.453\r",
      "Progress: 60.4% ... Training loss: 0.267 ... Validation loss: 0.450\r",
      "Progress: 60.5% ... Training loss: 0.269 ... Validation loss: 0.449\r",
      "Progress: 60.5% ... Training loss: 0.268 ... Validation loss: 0.453\r",
      "Progress: 60.5% ... Training loss: 0.262 ... Validation loss: 0.443\r",
      "Progress: 60.5% ... Training loss: 0.262 ... Validation loss: 0.443\r",
      "Progress: 60.5% ... Training loss: 0.262 ... Validation loss: 0.445\r",
      "Progress: 60.5% ... Training loss: 0.263 ... Validation loss: 0.446\r",
      "Progress: 60.6% ... Training loss: 0.262 ... Validation loss: 0.448\r",
      "Progress: 60.6% ... Training loss: 0.264 ... Validation loss: 0.452\r",
      "Progress: 60.6% ... Training loss: 0.262 ... Validation loss: 0.448\r",
      "Progress: 60.6% ... Training loss: 0.263 ... Validation loss: 0.446\r",
      "Progress: 60.6% ... Training loss: 0.265 ... Validation loss: 0.453\r",
      "Progress: 60.7% ... Training loss: 0.263 ... Validation loss: 0.445\r",
      "Progress: 60.7% ... Training loss: 0.265 ... Validation loss: 0.452\r",
      "Progress: 60.7% ... Training loss: 0.262 ... Validation loss: 0.448\r",
      "Progress: 60.7% ... Training loss: 0.270 ... Validation loss: 0.458\r",
      "Progress: 60.7% ... Training loss: 0.274 ... Validation loss: 0.452\r",
      "Progress: 60.7% ... Training loss: 0.270 ... Validation loss: 0.451\r",
      "Progress: 60.8% ... Training loss: 0.267 ... Validation loss: 0.461\r",
      "Progress: 60.8% ... Training loss: 0.262 ... Validation loss: 0.451\r",
      "Progress: 60.8% ... Training loss: 0.266 ... Validation loss: 0.458\r",
      "Progress: 60.8% ... Training loss: 0.262 ... Validation loss: 0.447\r",
      "Progress: 60.8% ... Training loss: 0.278 ... Validation loss: 0.456\r",
      "Progress: 60.9% ... Training loss: 0.262 ... Validation loss: 0.450\r",
      "Progress: 60.9% ... Training loss: 0.263 ... Validation loss: 0.448\r",
      "Progress: 60.9% ... Training loss: 0.267 ... Validation loss: 0.451\r",
      "Progress: 60.9% ... Training loss: 0.262 ... Validation loss: 0.452\r",
      "Progress: 60.9% ... Training loss: 0.261 ... Validation loss: 0.447\r",
      "Progress: 60.9% ... Training loss: 0.262 ... Validation loss: 0.451\r",
      "Progress: 61.0% ... Training loss: 0.262 ... Validation loss: 0.454\r",
      "Progress: 61.0% ... Training loss: 0.262 ... Validation loss: 0.451\r",
      "Progress: 61.0% ... Training loss: 0.267 ... Validation loss: 0.454\r",
      "Progress: 61.0% ... Training loss: 0.262 ... Validation loss: 0.451\r",
      "Progress: 61.0% ... Training loss: 0.272 ... Validation loss: 0.463\r",
      "Progress: 61.1% ... Training loss: 0.288 ... Validation loss: 0.467\r",
      "Progress: 61.1% ... Training loss: 0.296 ... Validation loss: 0.481\r",
      "Progress: 61.1% ... Training loss: 0.273 ... Validation loss: 0.453\r",
      "Progress: 61.1% ... Training loss: 0.263 ... Validation loss: 0.444\r",
      "Progress: 61.1% ... Training loss: 0.265 ... Validation loss: 0.445\r",
      "Progress: 61.1% ... Training loss: 0.263 ... Validation loss: 0.445\r",
      "Progress: 61.2% ... Training loss: 0.325 ... Validation loss: 0.501\r",
      "Progress: 61.2% ... Training loss: 0.294 ... Validation loss: 0.477\r",
      "Progress: 61.2% ... Training loss: 0.269 ... Validation loss: 0.452\r",
      "Progress: 61.2% ... Training loss: 0.262 ... Validation loss: 0.446\r",
      "Progress: 61.2% ... Training loss: 0.261 ... Validation loss: 0.444\r",
      "Progress: 61.3% ... Training loss: 0.264 ... Validation loss: 0.446\r",
      "Progress: 61.3% ... Training loss: 0.272 ... Validation loss: 0.453\r",
      "Progress: 61.3% ... Training loss: 0.263 ... Validation loss: 0.450\r",
      "Progress: 61.3% ... Training loss: 0.268 ... Validation loss: 0.450\r",
      "Progress: 61.3% ... Training loss: 0.264 ... Validation loss: 0.449\r",
      "Progress: 61.3% ... Training loss: 0.262 ... Validation loss: 0.447\r",
      "Progress: 61.4% ... Training loss: 0.274 ... Validation loss: 0.458\r",
      "Progress: 61.4% ... Training loss: 0.274 ... Validation loss: 0.464\r",
      "Progress: 61.4% ... Training loss: 0.278 ... Validation loss: 0.463\r",
      "Progress: 61.4% ... Training loss: 0.266 ... Validation loss: 0.453\r",
      "Progress: 61.4% ... Training loss: 0.266 ... Validation loss: 0.452\r",
      "Progress: 61.5% ... Training loss: 0.262 ... Validation loss: 0.447\r",
      "Progress: 61.5% ... Training loss: 0.270 ... Validation loss: 0.456\r",
      "Progress: 61.5% ... Training loss: 0.280 ... Validation loss: 0.468\r",
      "Progress: 61.5% ... Training loss: 0.266 ... Validation loss: 0.452\r",
      "Progress: 61.5% ... Training loss: 0.265 ... Validation loss: 0.452\r",
      "Progress: 61.5% ... Training loss: 0.268 ... Validation loss: 0.457\r",
      "Progress: 61.6% ... Training loss: 0.262 ... Validation loss: 0.450\r",
      "Progress: 61.6% ... Training loss: 0.262 ... Validation loss: 0.449\r",
      "Progress: 61.6% ... Training loss: 0.262 ... Validation loss: 0.449\r",
      "Progress: 61.6% ... Training loss: 0.268 ... Validation loss: 0.457\r",
      "Progress: 61.6% ... Training loss: 0.262 ... Validation loss: 0.449\r",
      "Progress: 61.7% ... Training loss: 0.262 ... Validation loss: 0.449\r",
      "Progress: 61.7% ... Training loss: 0.267 ... Validation loss: 0.457\r",
      "Progress: 61.7% ... Training loss: 0.261 ... Validation loss: 0.448\r",
      "Progress: 61.7% ... Training loss: 0.263 ... Validation loss: 0.451\r",
      "Progress: 61.7% ... Training loss: 0.261 ... Validation loss: 0.446\r",
      "Progress: 61.7% ... Training loss: 0.269 ... Validation loss: 0.458\r",
      "Progress: 61.8% ... Training loss: 0.280 ... Validation loss: 0.462\r",
      "Progress: 61.8% ... Training loss: 0.302 ... Validation loss: 0.486\r",
      "Progress: 61.8% ... Training loss: 0.265 ... Validation loss: 0.448\r",
      "Progress: 61.8% ... Training loss: 0.282 ... Validation loss: 0.468\r",
      "Progress: 61.8% ... Training loss: 0.283 ... Validation loss: 0.466\r",
      "Progress: 61.9% ... Training loss: 0.262 ... Validation loss: 0.450\r",
      "Progress: 61.9% ... Training loss: 0.264 ... Validation loss: 0.456\r",
      "Progress: 61.9% ... Training loss: 0.270 ... Validation loss: 0.459\r",
      "Progress: 61.9% ... Training loss: 0.267 ... Validation loss: 0.450\r",
      "Progress: 61.9% ... Training loss: 0.272 ... Validation loss: 0.460\r",
      "Progress: 61.9% ... Training loss: 0.269 ... Validation loss: 0.449\r",
      "Progress: 62.0% ... Training loss: 0.263 ... Validation loss: 0.446\r",
      "Progress: 62.0% ... Training loss: 0.262 ... Validation loss: 0.451\r",
      "Progress: 62.0% ... Training loss: 0.262 ... Validation loss: 0.448\r",
      "Progress: 62.0% ... Training loss: 0.261 ... Validation loss: 0.445\r",
      "Progress: 62.0% ... Training loss: 0.269 ... Validation loss: 0.458\r",
      "Progress: 62.1% ... Training loss: 0.264 ... Validation loss: 0.445\r",
      "Progress: 62.1% ... Training loss: 0.295 ... Validation loss: 0.481\r",
      "Progress: 62.1% ... Training loss: 0.270 ... Validation loss: 0.451\r",
      "Progress: 62.1% ... Training loss: 0.274 ... Validation loss: 0.460\r",
      "Progress: 62.1% ... Training loss: 0.261 ... Validation loss: 0.444\r",
      "Progress: 62.1% ... Training loss: 0.266 ... Validation loss: 0.450\r",
      "Progress: 62.2% ... Training loss: 0.268 ... Validation loss: 0.448\r",
      "Progress: 62.2% ... Training loss: 0.284 ... Validation loss: 0.466\r",
      "Progress: 62.2% ... Training loss: 0.260 ... Validation loss: 0.443\r",
      "Progress: 62.2% ... Training loss: 0.265 ... Validation loss: 0.449\r",
      "Progress: 62.2% ... Training loss: 0.261 ... Validation loss: 0.443\r",
      "Progress: 62.3% ... Training loss: 0.284 ... Validation loss: 0.466\r",
      "Progress: 62.3% ... Training loss: 0.273 ... Validation loss: 0.456\r",
      "Progress: 62.3% ... Training loss: 0.286 ... Validation loss: 0.470\r",
      "Progress: 62.3% ... Training loss: 0.275 ... Validation loss: 0.455\r",
      "Progress: 62.3% ... Training loss: 0.263 ... Validation loss: 0.449\r",
      "Progress: 62.3% ... Training loss: 0.261 ... Validation loss: 0.447\r",
      "Progress: 62.4% ... Training loss: 0.269 ... Validation loss: 0.451\r",
      "Progress: 62.4% ... Training loss: 0.262 ... Validation loss: 0.455\r",
      "Progress: 62.4% ... Training loss: 0.263 ... Validation loss: 0.448\r",
      "Progress: 62.4% ... Training loss: 0.291 ... Validation loss: 0.486\r",
      "Progress: 62.4% ... Training loss: 0.282 ... Validation loss: 0.459\r",
      "Progress: 62.5% ... Training loss: 0.281 ... Validation loss: 0.475\r",
      "Progress: 62.5% ... Training loss: 0.286 ... Validation loss: 0.463\r",
      "Progress: 62.5% ... Training loss: 0.294 ... Validation loss: 0.496\r",
      "Progress: 62.5% ... Training loss: 0.288 ... Validation loss: 0.461\r",
      "Progress: 62.5% ... Training loss: 0.274 ... Validation loss: 0.467\r",
      "Progress: 62.5% ... Training loss: 0.264 ... Validation loss: 0.445\r",
      "Progress: 62.6% ... Training loss: 0.262 ... Validation loss: 0.444\r",
      "Progress: 62.6% ... Training loss: 0.262 ... Validation loss: 0.447\r",
      "Progress: 62.6% ... Training loss: 0.263 ... Validation loss: 0.457\r",
      "Progress: 62.6% ... Training loss: 0.292 ... Validation loss: 0.463\r",
      "Progress: 62.6% ... Training loss: 0.262 ... Validation loss: 0.456\r",
      "Progress: 62.7% ... Training loss: 0.260 ... Validation loss: 0.449\r",
      "Progress: 62.7% ... Training loss: 0.281 ... Validation loss: 0.481\r",
      "Progress: 62.7% ... Training loss: 0.267 ... Validation loss: 0.449\r",
      "Progress: 62.7% ... Training loss: 0.264 ... Validation loss: 0.455\r",
      "Progress: 62.7% ... Training loss: 0.261 ... Validation loss: 0.444\r",
      "Progress: 62.7% ... Training loss: 0.261 ... Validation loss: 0.443\r",
      "Progress: 62.8% ... Training loss: 0.272 ... Validation loss: 0.449\r",
      "Progress: 62.8% ... Training loss: 0.264 ... Validation loss: 0.444\r",
      "Progress: 62.8% ... Training loss: 0.264 ... Validation loss: 0.452\r",
      "Progress: 62.8% ... Training loss: 0.283 ... Validation loss: 0.459\r",
      "Progress: 62.8% ... Training loss: 0.273 ... Validation loss: 0.464\r",
      "Progress: 62.9% ... Training loss: 0.268 ... Validation loss: 0.450\r",
      "Progress: 62.9% ... Training loss: 0.267 ... Validation loss: 0.454\r",
      "Progress: 62.9% ... Training loss: 0.262 ... Validation loss: 0.450\r",
      "Progress: 62.9% ... Training loss: 0.261 ... Validation loss: 0.450\r",
      "Progress: 62.9% ... Training loss: 0.290 ... Validation loss: 0.473\r",
      "Progress: 62.9% ... Training loss: 0.318 ... Validation loss: 0.515\r",
      "Progress: 63.0% ... Training loss: 0.278 ... Validation loss: 0.462\r",
      "Progress: 63.0% ... Training loss: 0.261 ... Validation loss: 0.455\r",
      "Progress: 63.0% ... Training loss: 0.268 ... Validation loss: 0.459\r",
      "Progress: 63.0% ... Training loss: 0.261 ... Validation loss: 0.449\r",
      "Progress: 63.0% ... Training loss: 0.260 ... Validation loss: 0.447\r",
      "Progress: 63.1% ... Training loss: 0.260 ... Validation loss: 0.448\r",
      "Progress: 63.1% ... Training loss: 0.260 ... Validation loss: 0.448\r",
      "Progress: 63.1% ... Training loss: 0.272 ... Validation loss: 0.454\r",
      "Progress: 63.1% ... Training loss: 0.267 ... Validation loss: 0.454\r",
      "Progress: 63.1% ... Training loss: 0.260 ... Validation loss: 0.445\r",
      "Progress: 63.1% ... Training loss: 0.271 ... Validation loss: 0.456\r",
      "Progress: 63.2% ... Training loss: 0.278 ... Validation loss: 0.467\r",
      "Progress: 63.2% ... Training loss: 0.271 ... Validation loss: 0.455\r",
      "Progress: 63.2% ... Training loss: 0.261 ... Validation loss: 0.452\r",
      "Progress: 63.2% ... Training loss: 0.264 ... Validation loss: 0.451\r",
      "Progress: 63.2% ... Training loss: 0.260 ... Validation loss: 0.450\r",
      "Progress: 63.3% ... Training loss: 0.265 ... Validation loss: 0.456\r",
      "Progress: 63.3% ... Training loss: 0.266 ... Validation loss: 0.453\r",
      "Progress: 63.3% ... Training loss: 0.261 ... Validation loss: 0.450\r",
      "Progress: 63.3% ... Training loss: 0.261 ... Validation loss: 0.450\r",
      "Progress: 63.3% ... Training loss: 0.262 ... Validation loss: 0.452\r",
      "Progress: 63.3% ... Training loss: 0.263 ... Validation loss: 0.452\r",
      "Progress: 63.4% ... Training loss: 0.265 ... Validation loss: 0.455\r",
      "Progress: 63.4% ... Training loss: 0.262 ... Validation loss: 0.457\r",
      "Progress: 63.4% ... Training loss: 0.263 ... Validation loss: 0.452\r",
      "Progress: 63.4% ... Training loss: 0.262 ... Validation loss: 0.454\r",
      "Progress: 63.4% ... Training loss: 0.274 ... Validation loss: 0.466\r",
      "Progress: 63.5% ... Training loss: 0.272 ... Validation loss: 0.457\r",
      "Progress: 63.5% ... Training loss: 0.263 ... Validation loss: 0.454\r",
      "Progress: 63.5% ... Training loss: 0.260 ... Validation loss: 0.451\r",
      "Progress: 63.5% ... Training loss: 0.262 ... Validation loss: 0.452\r",
      "Progress: 63.5% ... Training loss: 0.260 ... Validation loss: 0.450\r",
      "Progress: 63.5% ... Training loss: 0.261 ... Validation loss: 0.450\r",
      "Progress: 63.6% ... Training loss: 0.263 ... Validation loss: 0.454\r",
      "Progress: 63.6% ... Training loss: 0.276 ... Validation loss: 0.461\r",
      "Progress: 63.6% ... Training loss: 0.273 ... Validation loss: 0.460\r",
      "Progress: 63.6% ... Training loss: 0.285 ... Validation loss: 0.478\r",
      "Progress: 63.6% ... Training loss: 0.260 ... Validation loss: 0.448\r",
      "Progress: 63.7% ... Training loss: 0.270 ... Validation loss: 0.457\r",
      "Progress: 63.7% ... Training loss: 0.277 ... Validation loss: 0.460\r",
      "Progress: 63.7% ... Training loss: 0.268 ... Validation loss: 0.454\r",
      "Progress: 63.7% ... Training loss: 0.261 ... Validation loss: 0.446\r",
      "Progress: 63.7% ... Training loss: 0.270 ... Validation loss: 0.454\r",
      "Progress: 63.7% ... Training loss: 0.303 ... Validation loss: 0.481\r",
      "Progress: 63.8% ... Training loss: 0.299 ... Validation loss: 0.484\r",
      "Progress: 63.8% ... Training loss: 0.317 ... Validation loss: 0.486\r",
      "Progress: 63.8% ... Training loss: 0.291 ... Validation loss: 0.477\r",
      "Progress: 63.8% ... Training loss: 0.289 ... Validation loss: 0.465\r",
      "Progress: 63.8% ... Training loss: 0.270 ... Validation loss: 0.453\r",
      "Progress: 63.9% ... Training loss: 0.264 ... Validation loss: 0.445\r",
      "Progress: 63.9% ... Training loss: 0.274 ... Validation loss: 0.458\r",
      "Progress: 63.9% ... Training loss: 0.260 ... Validation loss: 0.444\r",
      "Progress: 63.9% ... Training loss: 0.260 ... Validation loss: 0.444\r",
      "Progress: 63.9% ... Training loss: 0.264 ... Validation loss: 0.450\r",
      "Progress: 63.9% ... Training loss: 0.269 ... Validation loss: 0.452\r",
      "Progress: 64.0% ... Training loss: 0.276 ... Validation loss: 0.457\r",
      "Progress: 64.0% ... Training loss: 0.264 ... Validation loss: 0.447\r",
      "Progress: 64.0% ... Training loss: 0.270 ... Validation loss: 0.458\r",
      "Progress: 64.0% ... Training loss: 0.266 ... Validation loss: 0.449\r",
      "Progress: 64.0% ... Training loss: 0.260 ... Validation loss: 0.443\r",
      "Progress: 64.1% ... Training loss: 0.270 ... Validation loss: 0.451\r",
      "Progress: 64.1% ... Training loss: 0.277 ... Validation loss: 0.453\r",
      "Progress: 64.1% ... Training loss: 0.316 ... Validation loss: 0.494\r",
      "Progress: 64.1% ... Training loss: 0.264 ... Validation loss: 0.446\r",
      "Progress: 64.1% ... Training loss: 0.279 ... Validation loss: 0.458\r",
      "Progress: 64.1% ... Training loss: 0.260 ... Validation loss: 0.441\r",
      "Progress: 64.2% ... Training loss: 0.260 ... Validation loss: 0.443\r",
      "Progress: 64.2% ... Training loss: 0.261 ... Validation loss: 0.448\r",
      "Progress: 64.2% ... Training loss: 0.268 ... Validation loss: 0.451\r",
      "Progress: 64.2% ... Training loss: 0.274 ... Validation loss: 0.455\r",
      "Progress: 64.2% ... Training loss: 0.261 ... Validation loss: 0.444\r",
      "Progress: 64.3% ... Training loss: 0.264 ... Validation loss: 0.449\r",
      "Progress: 64.3% ... Training loss: 0.273 ... Validation loss: 0.454\r",
      "Progress: 64.3% ... Training loss: 0.261 ... Validation loss: 0.451\r",
      "Progress: 64.3% ... Training loss: 0.264 ... Validation loss: 0.449\r",
      "Progress: 64.3% ... Training loss: 0.263 ... Validation loss: 0.452\r",
      "Progress: 64.3% ... Training loss: 0.259 ... Validation loss: 0.448\r",
      "Progress: 64.4% ... Training loss: 0.265 ... Validation loss: 0.452\r",
      "Progress: 64.4% ... Training loss: 0.261 ... Validation loss: 0.451\r",
      "Progress: 64.4% ... Training loss: 0.271 ... Validation loss: 0.463\r",
      "Progress: 64.4% ... Training loss: 0.298 ... Validation loss: 0.481\r",
      "Progress: 64.4% ... Training loss: 0.263 ... Validation loss: 0.454\r",
      "Progress: 64.5% ... Training loss: 0.278 ... Validation loss: 0.465\r",
      "Progress: 64.5% ... Training loss: 0.260 ... Validation loss: 0.450\r",
      "Progress: 64.5% ... Training loss: 0.265 ... Validation loss: 0.455\r",
      "Progress: 64.5% ... Training loss: 0.260 ... Validation loss: 0.450\r",
      "Progress: 64.5% ... Training loss: 0.285 ... Validation loss: 0.472\r",
      "Progress: 64.5% ... Training loss: 0.273 ... Validation loss: 0.461\r",
      "Progress: 64.6% ... Training loss: 0.277 ... Validation loss: 0.463\r",
      "Progress: 64.6% ... Training loss: 0.304 ... Validation loss: 0.497\r",
      "Progress: 64.6% ... Training loss: 0.262 ... Validation loss: 0.451\r",
      "Progress: 64.6% ... Training loss: 0.261 ... Validation loss: 0.452\r",
      "Progress: 64.6% ... Training loss: 0.260 ... Validation loss: 0.450\r",
      "Progress: 64.7% ... Training loss: 0.259 ... Validation loss: 0.449\r",
      "Progress: 64.7% ... Training loss: 0.259 ... Validation loss: 0.449\r",
      "Progress: 64.7% ... Training loss: 0.276 ... Validation loss: 0.464\r",
      "Progress: 64.7% ... Training loss: 0.259 ... Validation loss: 0.451\r",
      "Progress: 64.7% ... Training loss: 0.260 ... Validation loss: 0.451\r",
      "Progress: 64.7% ... Training loss: 0.267 ... Validation loss: 0.457\r",
      "Progress: 64.8% ... Training loss: 0.263 ... Validation loss: 0.454\r",
      "Progress: 64.8% ... Training loss: 0.260 ... Validation loss: 0.453\r",
      "Progress: 64.8% ... Training loss: 0.260 ... Validation loss: 0.454\r",
      "Progress: 64.8% ... Training loss: 0.291 ... Validation loss: 0.488\r",
      "Progress: 64.8% ... Training loss: 0.268 ... Validation loss: 0.461\r",
      "Progress: 64.9% ... Training loss: 0.259 ... Validation loss: 0.452\r",
      "Progress: 64.9% ... Training loss: 0.264 ... Validation loss: 0.456\r",
      "Progress: 64.9% ... Training loss: 0.275 ... Validation loss: 0.465\r",
      "Progress: 64.9% ... Training loss: 0.268 ... Validation loss: 0.459\r",
      "Progress: 64.9% ... Training loss: 0.265 ... Validation loss: 0.458\r",
      "Progress: 64.9% ... Training loss: 0.269 ... Validation loss: 0.458\r",
      "Progress: 65.0% ... Training loss: 0.259 ... Validation loss: 0.448\r",
      "Progress: 65.0% ... Training loss: 0.260 ... Validation loss: 0.450\r",
      "Progress: 65.0% ... Training loss: 0.266 ... Validation loss: 0.457\r",
      "Progress: 65.0% ... Training loss: 0.259 ... Validation loss: 0.452\r",
      "Progress: 65.0% ... Training loss: 0.261 ... Validation loss: 0.452\r",
      "Progress: 65.1% ... Training loss: 0.267 ... Validation loss: 0.459\r",
      "Progress: 65.1% ... Training loss: 0.259 ... Validation loss: 0.451\r",
      "Progress: 65.1% ... Training loss: 0.260 ... Validation loss: 0.452\r",
      "Progress: 65.1% ... Training loss: 0.259 ... Validation loss: 0.450\r",
      "Progress: 65.1% ... Training loss: 0.263 ... Validation loss: 0.454\r",
      "Progress: 65.1% ... Training loss: 0.259 ... Validation loss: 0.452\r",
      "Progress: 65.2% ... Training loss: 0.259 ... Validation loss: 0.451\r",
      "Progress: 65.2% ... Training loss: 0.268 ... Validation loss: 0.460\r",
      "Progress: 65.2% ... Training loss: 0.273 ... Validation loss: 0.463\r",
      "Progress: 65.2% ... Training loss: 0.279 ... Validation loss: 0.465\r",
      "Progress: 65.2% ... Training loss: 0.284 ... Validation loss: 0.479\r",
      "Progress: 65.3% ... Training loss: 0.289 ... Validation loss: 0.475\r",
      "Progress: 65.3% ... Training loss: 0.280 ... Validation loss: 0.470\r",
      "Progress: 65.3% ... Training loss: 0.260 ... Validation loss: 0.447\r",
      "Progress: 65.3% ... Training loss: 0.259 ... Validation loss: 0.447\r",
      "Progress: 65.3% ... Training loss: 0.274 ... Validation loss: 0.461\r",
      "Progress: 65.3% ... Training loss: 0.291 ... Validation loss: 0.474\r",
      "Progress: 65.4% ... Training loss: 0.299 ... Validation loss: 0.486\r",
      "Progress: 65.4% ... Training loss: 0.314 ... Validation loss: 0.496\r",
      "Progress: 65.4% ... Training loss: 0.294 ... Validation loss: 0.480\r",
      "Progress: 65.4% ... Training loss: 0.265 ... Validation loss: 0.447\r",
      "Progress: 65.4% ... Training loss: 0.263 ... Validation loss: 0.446\r",
      "Progress: 65.5% ... Training loss: 0.259 ... Validation loss: 0.440\r",
      "Progress: 65.5% ... Training loss: 0.261 ... Validation loss: 0.444\r",
      "Progress: 65.5% ... Training loss: 0.258 ... Validation loss: 0.444\r",
      "Progress: 65.5% ... Training loss: 0.259 ... Validation loss: 0.446\r",
      "Progress: 65.5% ... Training loss: 0.259 ... Validation loss: 0.445\r",
      "Progress: 65.5% ... Training loss: 0.264 ... Validation loss: 0.451\r",
      "Progress: 65.6% ... Training loss: 0.259 ... Validation loss: 0.446\r",
      "Progress: 65.6% ... Training loss: 0.275 ... Validation loss: 0.462\r",
      "Progress: 65.6% ... Training loss: 0.309 ... Validation loss: 0.501\r",
      "Progress: 65.6% ... Training loss: 0.273 ... Validation loss: 0.460\r",
      "Progress: 65.6% ... Training loss: 0.281 ... Validation loss: 0.466\r",
      "Progress: 65.7% ... Training loss: 0.262 ... Validation loss: 0.444\r",
      "Progress: 65.7% ... Training loss: 0.259 ... Validation loss: 0.441\r",
      "Progress: 65.7% ... Training loss: 0.279 ... Validation loss: 0.461\r",
      "Progress: 65.7% ... Training loss: 0.261 ... Validation loss: 0.444\r",
      "Progress: 65.7% ... Training loss: 0.266 ... Validation loss: 0.447\r",
      "Progress: 65.7% ... Training loss: 0.261 ... Validation loss: 0.442\r",
      "Progress: 65.8% ... Training loss: 0.259 ... Validation loss: 0.442\r",
      "Progress: 65.8% ... Training loss: 0.284 ... Validation loss: 0.467\r",
      "Progress: 65.8% ... Training loss: 0.304 ... Validation loss: 0.480\r",
      "Progress: 65.8% ... Training loss: 0.295 ... Validation loss: 0.472\r",
      "Progress: 65.8% ... Training loss: 0.262 ... Validation loss: 0.437\r",
      "Progress: 65.9% ... Training loss: 0.259 ... Validation loss: 0.437\r",
      "Progress: 65.9% ... Training loss: 0.270 ... Validation loss: 0.446\r",
      "Progress: 65.9% ... Training loss: 0.272 ... Validation loss: 0.456\r",
      "Progress: 65.9% ... Training loss: 0.269 ... Validation loss: 0.449\r",
      "Progress: 65.9% ... Training loss: 0.259 ... Validation loss: 0.444\r",
      "Progress: 65.9% ... Training loss: 0.259 ... Validation loss: 0.444\r",
      "Progress: 66.0% ... Training loss: 0.259 ... Validation loss: 0.447\r",
      "Progress: 66.0% ... Training loss: 0.259 ... Validation loss: 0.444\r",
      "Progress: 66.0% ... Training loss: 0.268 ... Validation loss: 0.464\r",
      "Progress: 66.0% ... Training loss: 0.259 ... Validation loss: 0.445\r",
      "Progress: 66.0% ... Training loss: 0.268 ... Validation loss: 0.447\r",
      "Progress: 66.1% ... Training loss: 0.261 ... Validation loss: 0.452\r",
      "Progress: 66.1% ... Training loss: 0.271 ... Validation loss: 0.449\r",
      "Progress: 66.1% ... Training loss: 0.258 ... Validation loss: 0.446\r",
      "Progress: 66.1% ... Training loss: 0.270 ... Validation loss: 0.450\r",
      "Progress: 66.1% ... Training loss: 0.272 ... Validation loss: 0.467\r",
      "Progress: 66.1% ... Training loss: 0.260 ... Validation loss: 0.443\r",
      "Progress: 66.2% ... Training loss: 0.272 ... Validation loss: 0.464\r",
      "Progress: 66.2% ... Training loss: 0.258 ... Validation loss: 0.442\r",
      "Progress: 66.2% ... Training loss: 0.258 ... Validation loss: 0.444\r",
      "Progress: 66.2% ... Training loss: 0.264 ... Validation loss: 0.445\r",
      "Progress: 66.2% ... Training loss: 0.290 ... Validation loss: 0.488\r",
      "Progress: 66.3% ... Training loss: 0.273 ... Validation loss: 0.452\r",
      "Progress: 66.3% ... Training loss: 0.274 ... Validation loss: 0.472\r",
      "Progress: 66.3% ... Training loss: 0.260 ... Validation loss: 0.443\r",
      "Progress: 66.3% ... Training loss: 0.263 ... Validation loss: 0.454\r",
      "Progress: 66.3% ... Training loss: 0.260 ... Validation loss: 0.449\r",
      "Progress: 66.3% ... Training loss: 0.264 ... Validation loss: 0.456\r",
      "Progress: 66.4% ... Training loss: 0.262 ... Validation loss: 0.445\r",
      "Progress: 66.4% ... Training loss: 0.295 ... Validation loss: 0.501\r",
      "Progress: 66.4% ... Training loss: 0.260 ... Validation loss: 0.442\r",
      "Progress: 66.4% ... Training loss: 0.266 ... Validation loss: 0.461\r",
      "Progress: 66.4% ... Training loss: 0.277 ... Validation loss: 0.451\r",
      "Progress: 66.5% ... Training loss: 0.266 ... Validation loss: 0.461\r",
      "Progress: 66.5% ... Training loss: 0.261 ... Validation loss: 0.441\r",
      "Progress: 66.5% ... Training loss: 0.267 ... Validation loss: 0.456\r",
      "Progress: 66.5% ... Training loss: 0.259 ... Validation loss: 0.442\r",
      "Progress: 66.5% ... Training loss: 0.259 ... Validation loss: 0.445\r",
      "Progress: 66.5% ... Training loss: 0.259 ... Validation loss: 0.444\r",
      "Progress: 66.6% ... Training loss: 0.260 ... Validation loss: 0.440\r",
      "Progress: 66.6% ... Training loss: 0.259 ... Validation loss: 0.438\r",
      "Progress: 66.6% ... Training loss: 0.259 ... Validation loss: 0.440\r",
      "Progress: 66.6% ... Training loss: 0.262 ... Validation loss: 0.444\r",
      "Progress: 66.6% ... Training loss: 0.259 ... Validation loss: 0.438\r",
      "Progress: 66.7% ... Training loss: 0.272 ... Validation loss: 0.448\r",
      "Progress: 66.7% ... Training loss: 0.310 ... Validation loss: 0.493\r",
      "Progress: 66.7% ... Training loss: 0.261 ... Validation loss: 0.436\r",
      "Progress: 66.7% ... Training loss: 0.261 ... Validation loss: 0.440\r",
      "Progress: 66.7% ... Training loss: 0.258 ... Validation loss: 0.441\r",
      "Progress: 66.7% ... Training loss: 0.258 ... Validation loss: 0.440\r",
      "Progress: 66.8% ... Training loss: 0.261 ... Validation loss: 0.442\r",
      "Progress: 66.8% ... Training loss: 0.270 ... Validation loss: 0.454\r",
      "Progress: 66.8% ... Training loss: 0.269 ... Validation loss: 0.450\r",
      "Progress: 66.8% ... Training loss: 0.266 ... Validation loss: 0.455\r",
      "Progress: 66.8% ... Training loss: 0.258 ... Validation loss: 0.444\r",
      "Progress: 66.9% ... Training loss: 0.259 ... Validation loss: 0.447\r",
      "Progress: 66.9% ... Training loss: 0.258 ... Validation loss: 0.445\r",
      "Progress: 66.9% ... Training loss: 0.269 ... Validation loss: 0.452\r",
      "Progress: 66.9% ... Training loss: 0.295 ... Validation loss: 0.500\r",
      "Progress: 66.9% ... Training loss: 0.267 ... Validation loss: 0.450\r",
      "Progress: 66.9% ... Training loss: 0.277 ... Validation loss: 0.483\r",
      "Progress: 67.0% ... Training loss: 0.261 ... Validation loss: 0.458\r",
      "Progress: 67.0% ... Training loss: 0.282 ... Validation loss: 0.460\r",
      "Progress: 67.0% ... Training loss: 0.258 ... Validation loss: 0.448\r",
      "Progress: 67.0% ... Training loss: 0.259 ... Validation loss: 0.451\r",
      "Progress: 67.0% ... Training loss: 0.268 ... Validation loss: 0.450\r",
      "Progress: 67.1% ... Training loss: 0.297 ... Validation loss: 0.488\r",
      "Progress: 67.1% ... Training loss: 0.264 ... Validation loss: 0.444\r",
      "Progress: 67.1% ... Training loss: 0.267 ... Validation loss: 0.459\r",
      "Progress: 67.1% ... Training loss: 0.283 ... Validation loss: 0.461\r",
      "Progress: 67.1% ... Training loss: 0.288 ... Validation loss: 0.489\r",
      "Progress: 67.1% ... Training loss: 0.259 ... Validation loss: 0.444\r",
      "Progress: 67.2% ... Training loss: 0.257 ... Validation loss: 0.444\r",
      "Progress: 67.2% ... Training loss: 0.334 ... Validation loss: 0.535\r",
      "Progress: 67.2% ... Training loss: 0.323 ... Validation loss: 0.490\r",
      "Progress: 67.2% ... Training loss: 0.296 ... Validation loss: 0.492\r",
      "Progress: 67.2% ... Training loss: 0.283 ... Validation loss: 0.455\r",
      "Progress: 67.3% ... Training loss: 0.266 ... Validation loss: 0.451\r",
      "Progress: 67.3% ... Training loss: 0.300 ... Validation loss: 0.467\r",
      "Progress: 67.3% ... Training loss: 0.307 ... Validation loss: 0.509\r",
      "Progress: 67.3% ... Training loss: 0.263 ... Validation loss: 0.442\r",
      "Progress: 67.3% ... Training loss: 0.261 ... Validation loss: 0.454\r",
      "Progress: 67.3% ... Training loss: 0.261 ... Validation loss: 0.443\r",
      "Progress: 67.4% ... Training loss: 0.258 ... Validation loss: 0.441\r",
      "Progress: 67.4% ... Training loss: 0.260 ... Validation loss: 0.442\r",
      "Progress: 67.4% ... Training loss: 0.262 ... Validation loss: 0.455\r",
      "Progress: 67.4% ... Training loss: 0.257 ... Validation loss: 0.446\r",
      "Progress: 67.4% ... Training loss: 0.257 ... Validation loss: 0.445\r",
      "Progress: 67.5% ... Training loss: 0.263 ... Validation loss: 0.446\r",
      "Progress: 67.5% ... Training loss: 0.260 ... Validation loss: 0.453\r",
      "Progress: 67.5% ... Training loss: 0.257 ... Validation loss: 0.443\r",
      "Progress: 67.5% ... Training loss: 0.256 ... Validation loss: 0.442\r",
      "Progress: 67.5% ... Training loss: 0.260 ... Validation loss: 0.446\r",
      "Progress: 67.5% ... Training loss: 0.274 ... Validation loss: 0.463\r",
      "Progress: 67.6% ... Training loss: 0.262 ... Validation loss: 0.442\r",
      "Progress: 67.6% ... Training loss: 0.286 ... Validation loss: 0.476\r",
      "Progress: 67.6% ... Training loss: 0.307 ... Validation loss: 0.478\r",
      "Progress: 67.6% ... Training loss: 0.270 ... Validation loss: 0.463\r",
      "Progress: 67.6% ... Training loss: 0.260 ... Validation loss: 0.441\r",
      "Progress: 67.7% ... Training loss: 0.257 ... Validation loss: 0.443\r",
      "Progress: 67.7% ... Training loss: 0.257 ... Validation loss: 0.445\r",
      "Progress: 67.7% ... Training loss: 0.262 ... Validation loss: 0.452\r",
      "Progress: 67.7% ... Training loss: 0.257 ... Validation loss: 0.438\r",
      "Progress: 67.7% ... Training loss: 0.256 ... Validation loss: 0.439\r",
      "Progress: 67.7% ... Training loss: 0.268 ... Validation loss: 0.452\r",
      "Progress: 67.8% ... Training loss: 0.331 ... Validation loss: 0.494\r",
      "Progress: 67.8% ... Training loss: 0.276 ... Validation loss: 0.472\r",
      "Progress: 67.8% ... Training loss: 0.276 ... Validation loss: 0.451\r",
      "Progress: 67.8% ... Training loss: 0.271 ... Validation loss: 0.449\r",
      "Progress: 67.8% ... Training loss: 0.291 ... Validation loss: 0.484\r",
      "Progress: 67.9% ... Training loss: 0.269 ... Validation loss: 0.447\r",
      "Progress: 67.9% ... Training loss: 0.267 ... Validation loss: 0.455\r",
      "Progress: 67.9% ... Training loss: 0.277 ... Validation loss: 0.454\r",
      "Progress: 67.9% ... Training loss: 0.273 ... Validation loss: 0.452\r",
      "Progress: 67.9% ... Training loss: 0.280 ... Validation loss: 0.469\r",
      "Progress: 67.9% ... Training loss: 0.269 ... Validation loss: 0.447\r",
      "Progress: 68.0% ... Training loss: 0.265 ... Validation loss: 0.452\r",
      "Progress: 68.0% ... Training loss: 0.257 ... Validation loss: 0.438\r",
      "Progress: 68.0% ... Training loss: 0.266 ... Validation loss: 0.450\r",
      "Progress: 68.0% ... Training loss: 0.263 ... Validation loss: 0.441\r",
      "Progress: 68.0% ... Training loss: 0.268 ... Validation loss: 0.455\r",
      "Progress: 68.1% ... Training loss: 0.276 ... Validation loss: 0.451\r",
      "Progress: 68.1% ... Training loss: 0.277 ... Validation loss: 0.462\r",
      "Progress: 68.1% ... Training loss: 0.260 ... Validation loss: 0.440\r",
      "Progress: 68.1% ... Training loss: 0.258 ... Validation loss: 0.439\r",
      "Progress: 68.1% ... Training loss: 0.277 ... Validation loss: 0.463\r",
      "Progress: 68.1% ... Training loss: 0.327 ... Validation loss: 0.495\r",
      "Progress: 68.2% ... Training loss: 0.263 ... Validation loss: 0.454\r",
      "Progress: 68.2% ... Training loss: 0.257 ... Validation loss: 0.446\r",
      "Progress: 68.2% ... Training loss: 0.259 ... Validation loss: 0.447\r",
      "Progress: 68.2% ... Training loss: 0.261 ... Validation loss: 0.449\r",
      "Progress: 68.2% ... Training loss: 0.258 ... Validation loss: 0.450\r",
      "Progress: 68.3% ... Training loss: 0.290 ... Validation loss: 0.490\r",
      "Progress: 68.3% ... Training loss: 0.273 ... Validation loss: 0.454\r",
      "Progress: 68.3% ... Training loss: 0.265 ... Validation loss: 0.449\r",
      "Progress: 68.3% ... Training loss: 0.258 ... Validation loss: 0.446\r",
      "Progress: 68.3% ... Training loss: 0.256 ... Validation loss: 0.446\r",
      "Progress: 68.3% ... Training loss: 0.265 ... Validation loss: 0.456\r",
      "Progress: 68.4% ... Training loss: 0.256 ... Validation loss: 0.440\r",
      "Progress: 68.4% ... Training loss: 0.280 ... Validation loss: 0.463\r",
      "Progress: 68.4% ... Training loss: 0.284 ... Validation loss: 0.467\r",
      "Progress: 68.4% ... Training loss: 0.354 ... Validation loss: 0.531\r",
      "Progress: 68.4% ... Training loss: 0.311 ... Validation loss: 0.501\r",
      "Progress: 68.5% ... Training loss: 0.294 ... Validation loss: 0.477\r",
      "Progress: 68.5% ... Training loss: 0.262 ... Validation loss: 0.454\r",
      "Progress: 68.5% ... Training loss: 0.261 ... Validation loss: 0.448\r",
      "Progress: 68.5% ... Training loss: 0.259 ... Validation loss: 0.444\r",
      "Progress: 68.5% ... Training loss: 0.284 ... Validation loss: 0.465\r",
      "Progress: 68.5% ... Training loss: 0.267 ... Validation loss: 0.453\r",
      "Progress: 68.6% ... Training loss: 0.261 ... Validation loss: 0.444\r",
      "Progress: 68.6% ... Training loss: 0.257 ... Validation loss: 0.443\r",
      "Progress: 68.6% ... Training loss: 0.256 ... Validation loss: 0.443\r",
      "Progress: 68.6% ... Training loss: 0.256 ... Validation loss: 0.442\r",
      "Progress: 68.6% ... Training loss: 0.260 ... Validation loss: 0.447\r",
      "Progress: 68.7% ... Training loss: 0.256 ... Validation loss: 0.445\r",
      "Progress: 68.7% ... Training loss: 0.258 ... Validation loss: 0.447\r",
      "Progress: 68.7% ... Training loss: 0.269 ... Validation loss: 0.458\r",
      "Progress: 68.7% ... Training loss: 0.256 ... Validation loss: 0.447\r",
      "Progress: 68.7% ... Training loss: 0.256 ... Validation loss: 0.446\r",
      "Progress: 68.7% ... Training loss: 0.256 ... Validation loss: 0.447\r",
      "Progress: 68.8% ... Training loss: 0.256 ... Validation loss: 0.444\r",
      "Progress: 68.8% ... Training loss: 0.265 ... Validation loss: 0.448\r",
      "Progress: 68.8% ... Training loss: 0.256 ... Validation loss: 0.443\r",
      "Progress: 68.8% ... Training loss: 0.257 ... Validation loss: 0.443\r",
      "Progress: 68.8% ... Training loss: 0.263 ... Validation loss: 0.454\r",
      "Progress: 68.9% ... Training loss: 0.275 ... Validation loss: 0.463\r",
      "Progress: 68.9% ... Training loss: 0.281 ... Validation loss: 0.468\r",
      "Progress: 68.9% ... Training loss: 0.276 ... Validation loss: 0.466\r",
      "Progress: 68.9% ... Training loss: 0.269 ... Validation loss: 0.457\r",
      "Progress: 68.9% ... Training loss: 0.258 ... Validation loss: 0.449\r",
      "Progress: 68.9% ... Training loss: 0.258 ... Validation loss: 0.450\r",
      "Progress: 69.0% ... Training loss: 0.269 ... Validation loss: 0.458\r",
      "Progress: 69.0% ... Training loss: 0.256 ... Validation loss: 0.445\r",
      "Progress: 69.0% ... Training loss: 0.264 ... Validation loss: 0.453\r",
      "Progress: 69.0% ... Training loss: 0.299 ... Validation loss: 0.485\r",
      "Progress: 69.0% ... Training loss: 0.264 ... Validation loss: 0.450\r",
      "Progress: 69.1% ... Training loss: 0.266 ... Validation loss: 0.456\r",
      "Progress: 69.1% ... Training loss: 0.292 ... Validation loss: 0.477\r",
      "Progress: 69.1% ... Training loss: 0.263 ... Validation loss: 0.455\r",
      "Progress: 69.1% ... Training loss: 0.267 ... Validation loss: 0.455\r",
      "Progress: 69.1% ... Training loss: 0.300 ... Validation loss: 0.488\r",
      "Progress: 69.1% ... Training loss: 0.268 ... Validation loss: 0.464\r",
      "Progress: 69.2% ... Training loss: 0.260 ... Validation loss: 0.452\r",
      "Progress: 69.2% ... Training loss: 0.256 ... Validation loss: 0.451\r",
      "Progress: 69.2% ... Training loss: 0.259 ... Validation loss: 0.452\r",
      "Progress: 69.2% ... Training loss: 0.257 ... Validation loss: 0.448\r",
      "Progress: 69.2% ... Training loss: 0.256 ... Validation loss: 0.448\r",
      "Progress: 69.3% ... Training loss: 0.255 ... Validation loss: 0.449\r",
      "Progress: 69.3% ... Training loss: 0.256 ... Validation loss: 0.448\r",
      "Progress: 69.3% ... Training loss: 0.256 ... Validation loss: 0.448\r",
      "Progress: 69.3% ... Training loss: 0.257 ... Validation loss: 0.451\r",
      "Progress: 69.3% ... Training loss: 0.267 ... Validation loss: 0.462\r",
      "Progress: 69.3% ... Training loss: 0.261 ... Validation loss: 0.451\r",
      "Progress: 69.4% ... Training loss: 0.257 ... Validation loss: 0.449\r",
      "Progress: 69.4% ... Training loss: 0.256 ... Validation loss: 0.447\r",
      "Progress: 69.4% ... Training loss: 0.258 ... Validation loss: 0.447\r",
      "Progress: 69.4% ... Training loss: 0.259 ... Validation loss: 0.447\r",
      "Progress: 69.4% ... Training loss: 0.274 ... Validation loss: 0.461\r",
      "Progress: 69.5% ... Training loss: 0.267 ... Validation loss: 0.458\r",
      "Progress: 69.5% ... Training loss: 0.258 ... Validation loss: 0.449\r",
      "Progress: 69.5% ... Training loss: 0.258 ... Validation loss: 0.447\r",
      "Progress: 69.5% ... Training loss: 0.260 ... Validation loss: 0.448\r",
      "Progress: 69.5% ... Training loss: 0.278 ... Validation loss: 0.469\r",
      "Progress: 69.5% ... Training loss: 0.323 ... Validation loss: 0.503\r",
      "Progress: 69.6% ... Training loss: 0.273 ... Validation loss: 0.463\r",
      "Progress: 69.6% ... Training loss: 0.257 ... Validation loss: 0.444\r",
      "Progress: 69.6% ... Training loss: 0.257 ... Validation loss: 0.444\r",
      "Progress: 69.6% ... Training loss: 0.274 ... Validation loss: 0.457\r",
      "Progress: 69.6% ... Training loss: 0.273 ... Validation loss: 0.456\r",
      "Progress: 69.7% ... Training loss: 0.255 ... Validation loss: 0.445\r",
      "Progress: 69.7% ... Training loss: 0.257 ... Validation loss: 0.443\r",
      "Progress: 69.7% ... Training loss: 0.260 ... Validation loss: 0.445\r",
      "Progress: 69.7% ... Training loss: 0.267 ... Validation loss: 0.450\r",
      "Progress: 69.7% ... Training loss: 0.270 ... Validation loss: 0.454\r",
      "Progress: 69.7% ... Training loss: 0.262 ... Validation loss: 0.444\r",
      "Progress: 69.8% ... Training loss: 0.258 ... Validation loss: 0.440\r",
      "Progress: 69.8% ... Training loss: 0.255 ... Validation loss: 0.441\r",
      "Progress: 69.8% ... Training loss: 0.275 ... Validation loss: 0.457\r",
      "Progress: 69.8% ... Training loss: 0.271 ... Validation loss: 0.462\r",
      "Progress: 69.8% ... Training loss: 0.260 ... Validation loss: 0.449\r",
      "Progress: 69.9% ... Training loss: 0.256 ... Validation loss: 0.445\r",
      "Progress: 69.9% ... Training loss: 0.282 ... Validation loss: 0.465\r",
      "Progress: 69.9% ... Training loss: 0.318 ... Validation loss: 0.504\r",
      "Progress: 69.9% ... Training loss: 0.292 ... Validation loss: 0.478\r",
      "Progress: 69.9% ... Training loss: 0.352 ... Validation loss: 0.529\r",
      "Progress: 69.9% ... Training loss: 0.316 ... Validation loss: 0.502\r",
      "Progress: 70.0% ... Training loss: 0.333 ... Validation loss: 0.522\r",
      "Progress: 70.0% ... Training loss: 0.258 ... Validation loss: 0.447\r",
      "Progress: 70.0% ... Training loss: 0.256 ... Validation loss: 0.441\r",
      "Progress: 70.0% ... Training loss: 0.267 ... Validation loss: 0.449\r",
      "Progress: 70.0% ... Training loss: 0.255 ... Validation loss: 0.440\r",
      "Progress: 70.1% ... Training loss: 0.260 ... Validation loss: 0.444\r",
      "Progress: 70.1% ... Training loss: 0.258 ... Validation loss: 0.443\r",
      "Progress: 70.1% ... Training loss: 0.261 ... Validation loss: 0.447\r",
      "Progress: 70.1% ... Training loss: 0.256 ... Validation loss: 0.443\r",
      "Progress: 70.1% ... Training loss: 0.262 ... Validation loss: 0.452\r",
      "Progress: 70.1% ... Training loss: 0.255 ... Validation loss: 0.441\r",
      "Progress: 70.2% ... Training loss: 0.266 ... Validation loss: 0.449\r",
      "Progress: 70.2% ... Training loss: 0.294 ... Validation loss: 0.488\r",
      "Progress: 70.2% ... Training loss: 0.265 ... Validation loss: 0.444\r",
      "Progress: 70.2% ... Training loss: 0.256 ... Validation loss: 0.439\r",
      "Progress: 70.2% ... Training loss: 0.263 ... Validation loss: 0.449\r",
      "Progress: 70.3% ... Training loss: 0.256 ... Validation loss: 0.439\r",
      "Progress: 70.3% ... Training loss: 0.257 ... Validation loss: 0.436\r",
      "Progress: 70.3% ... Training loss: 0.277 ... Validation loss: 0.464\r",
      "Progress: 70.3% ... Training loss: 0.278 ... Validation loss: 0.453\r",
      "Progress: 70.3% ... Training loss: 0.258 ... Validation loss: 0.444\r",
      "Progress: 70.3% ... Training loss: 0.254 ... Validation loss: 0.439\r",
      "Progress: 70.4% ... Training loss: 0.256 ... Validation loss: 0.438\r",
      "Progress: 70.4% ... Training loss: 0.254 ... Validation loss: 0.438\r",
      "Progress: 70.4% ... Training loss: 0.263 ... Validation loss: 0.451\r",
      "Progress: 70.4% ... Training loss: 0.261 ... Validation loss: 0.442\r",
      "Progress: 70.4% ... Training loss: 0.276 ... Validation loss: 0.461\r",
      "Progress: 70.5% ... Training loss: 0.259 ... Validation loss: 0.438\r",
      "Progress: 70.5% ... Training loss: 0.264 ... Validation loss: 0.452\r",
      "Progress: 70.5% ... Training loss: 0.259 ... Validation loss: 0.441\r",
      "Progress: 70.5% ... Training loss: 0.258 ... Validation loss: 0.440\r",
      "Progress: 70.5% ... Training loss: 0.260 ... Validation loss: 0.442\r",
      "Progress: 70.5% ... Training loss: 0.264 ... Validation loss: 0.446\r",
      "Progress: 70.6% ... Training loss: 0.260 ... Validation loss: 0.442\r",
      "Progress: 70.6% ... Training loss: 0.284 ... Validation loss: 0.464\r",
      "Progress: 70.6% ... Training loss: 0.280 ... Validation loss: 0.464\r",
      "Progress: 70.6% ... Training loss: 0.254 ... Validation loss: 0.436\r",
      "Progress: 70.6% ... Training loss: 0.256 ... Validation loss: 0.436\r",
      "Progress: 70.7% ... Training loss: 0.263 ... Validation loss: 0.444\r",
      "Progress: 70.7% ... Training loss: 0.259 ... Validation loss: 0.445\r",
      "Progress: 70.7% ... Training loss: 0.255 ... Validation loss: 0.439\r",
      "Progress: 70.7% ... Training loss: 0.255 ... Validation loss: 0.438\r",
      "Progress: 70.7% ... Training loss: 0.255 ... Validation loss: 0.439\r",
      "Progress: 70.7% ... Training loss: 0.260 ... Validation loss: 0.442\r",
      "Progress: 70.8% ... Training loss: 0.329 ... Validation loss: 0.507\r",
      "Progress: 70.8% ... Training loss: 0.284 ... Validation loss: 0.460\r",
      "Progress: 70.8% ... Training loss: 0.284 ... Validation loss: 0.471\r",
      "Progress: 70.8% ... Training loss: 0.258 ... Validation loss: 0.438\r",
      "Progress: 70.8% ... Training loss: 0.258 ... Validation loss: 0.441\r",
      "Progress: 70.9% ... Training loss: 0.259 ... Validation loss: 0.438\r",
      "Progress: 70.9% ... Training loss: 0.269 ... Validation loss: 0.444\r",
      "Progress: 70.9% ... Training loss: 0.283 ... Validation loss: 0.460\r",
      "Progress: 70.9% ... Training loss: 0.279 ... Validation loss: 0.454\r",
      "Progress: 70.9% ... Training loss: 0.296 ... Validation loss: 0.474\r",
      "Progress: 70.9% ... Training loss: 0.262 ... Validation loss: 0.438\r",
      "Progress: 71.0% ... Training loss: 0.256 ... Validation loss: 0.436\r",
      "Progress: 71.0% ... Training loss: 0.257 ... Validation loss: 0.437\r",
      "Progress: 71.0% ... Training loss: 0.255 ... Validation loss: 0.436\r",
      "Progress: 71.0% ... Training loss: 0.268 ... Validation loss: 0.447\r",
      "Progress: 71.0% ... Training loss: 0.255 ... Validation loss: 0.441\r",
      "Progress: 71.1% ... Training loss: 0.254 ... Validation loss: 0.442\r",
      "Progress: 71.1% ... Training loss: 0.267 ... Validation loss: 0.455\r",
      "Progress: 71.1% ... Training loss: 0.274 ... Validation loss: 0.454\r",
      "Progress: 71.1% ... Training loss: 0.259 ... Validation loss: 0.452\r",
      "Progress: 71.1% ... Training loss: 0.271 ... Validation loss: 0.464\r",
      "Progress: 71.1% ... Training loss: 0.257 ... Validation loss: 0.441\r",
      "Progress: 71.2% ... Training loss: 0.267 ... Validation loss: 0.457\r",
      "Progress: 71.2% ... Training loss: 0.285 ... Validation loss: 0.470\r",
      "Progress: 71.2% ... Training loss: 0.260 ... Validation loss: 0.438\r",
      "Progress: 71.2% ... Training loss: 0.267 ... Validation loss: 0.444\r",
      "Progress: 71.2% ... Training loss: 0.257 ... Validation loss: 0.441\r",
      "Progress: 71.3% ... Training loss: 0.254 ... Validation loss: 0.437\r",
      "Progress: 71.3% ... Training loss: 0.255 ... Validation loss: 0.438\r",
      "Progress: 71.3% ... Training loss: 0.255 ... Validation loss: 0.437\r",
      "Progress: 71.3% ... Training loss: 0.268 ... Validation loss: 0.447\r",
      "Progress: 71.3% ... Training loss: 0.264 ... Validation loss: 0.454\r",
      "Progress: 71.3% ... Training loss: 0.266 ... Validation loss: 0.445\r",
      "Progress: 71.4% ... Training loss: 0.262 ... Validation loss: 0.453\r",
      "Progress: 71.4% ... Training loss: 0.254 ... Validation loss: 0.444\r",
      "Progress: 71.4% ... Training loss: 0.269 ... Validation loss: 0.448\r",
      "Progress: 71.4% ... Training loss: 0.254 ... Validation loss: 0.446\r",
      "Progress: 71.4% ... Training loss: 0.265 ... Validation loss: 0.448\r",
      "Progress: 71.5% ... Training loss: 0.273 ... Validation loss: 0.465\r",
      "Progress: 71.5% ... Training loss: 0.312 ... Validation loss: 0.486\r",
      "Progress: 71.5% ... Training loss: 0.264 ... Validation loss: 0.453\r",
      "Progress: 71.5% ... Training loss: 0.262 ... Validation loss: 0.445\r",
      "Progress: 71.5% ... Training loss: 0.255 ... Validation loss: 0.441\r",
      "Progress: 71.5% ... Training loss: 0.268 ... Validation loss: 0.451\r",
      "Progress: 71.6% ... Training loss: 0.261 ... Validation loss: 0.446\r",
      "Progress: 71.6% ... Training loss: 0.255 ... Validation loss: 0.438\r",
      "Progress: 71.6% ... Training loss: 0.256 ... Validation loss: 0.440\r",
      "Progress: 71.6% ... Training loss: 0.257 ... Validation loss: 0.441\r",
      "Progress: 71.6% ... Training loss: 0.254 ... Validation loss: 0.438\r",
      "Progress: 71.7% ... Training loss: 0.283 ... Validation loss: 0.468\r",
      "Progress: 71.7% ... Training loss: 0.269 ... Validation loss: 0.456\r",
      "Progress: 71.7% ... Training loss: 0.260 ... Validation loss: 0.442\r",
      "Progress: 71.7% ... Training loss: 0.267 ... Validation loss: 0.454\r",
      "Progress: 71.7% ... Training loss: 0.256 ... Validation loss: 0.440\r",
      "Progress: 71.7% ... Training loss: 0.258 ... Validation loss: 0.443\r",
      "Progress: 71.8% ... Training loss: 0.253 ... Validation loss: 0.442\r",
      "Progress: 71.8% ... Training loss: 0.254 ... Validation loss: 0.445\r",
      "Progress: 71.8% ... Training loss: 0.253 ... Validation loss: 0.443\r",
      "Progress: 71.8% ... Training loss: 0.264 ... Validation loss: 0.446\r",
      "Progress: 71.8% ... Training loss: 0.269 ... Validation loss: 0.467\r",
      "Progress: 71.9% ... Training loss: 0.300 ... Validation loss: 0.474\r",
      "Progress: 71.9% ... Training loss: 0.328 ... Validation loss: 0.534\r",
      "Progress: 71.9% ... Training loss: 0.338 ... Validation loss: 0.507\r",
      "Progress: 71.9% ... Training loss: 0.323 ... Validation loss: 0.533\r",
      "Progress: 71.9% ... Training loss: 0.277 ... Validation loss: 0.459\r",
      "Progress: 71.9% ... Training loss: 0.271 ... Validation loss: 0.475\r",
      "Progress: 72.0% ... Training loss: 0.253 ... Validation loss: 0.446\r",
      "Progress: 72.0% ... Training loss: 0.258 ... Validation loss: 0.453\r",
      "Progress: 72.0% ... Training loss: 0.254 ... Validation loss: 0.446\r",
      "Progress: 72.0% ... Training loss: 0.257 ... Validation loss: 0.450\r",
      "Progress: 72.0% ... Training loss: 0.257 ... Validation loss: 0.441\r",
      "Progress: 72.1% ... Training loss: 0.268 ... Validation loss: 0.459\r",
      "Progress: 72.1% ... Training loss: 0.266 ... Validation loss: 0.447\r",
      "Progress: 72.1% ... Training loss: 0.253 ... Validation loss: 0.440\r",
      "Progress: 72.1% ... Training loss: 0.255 ... Validation loss: 0.440\r",
      "Progress: 72.1% ... Training loss: 0.254 ... Validation loss: 0.438\r",
      "Progress: 72.1% ... Training loss: 0.260 ... Validation loss: 0.441\r",
      "Progress: 72.2% ... Training loss: 0.257 ... Validation loss: 0.439\r",
      "Progress: 72.2% ... Training loss: 0.265 ... Validation loss: 0.448\r",
      "Progress: 72.2% ... Training loss: 0.288 ... Validation loss: 0.478\r",
      "Progress: 72.2% ... Training loss: 0.277 ... Validation loss: 0.457\r",
      "Progress: 72.2% ... Training loss: 0.257 ... Validation loss: 0.449\r",
      "Progress: 72.3% ... Training loss: 0.256 ... Validation loss: 0.447\r",
      "Progress: 72.3% ... Training loss: 0.258 ... Validation loss: 0.440\r",
      "Progress: 72.3% ... Training loss: 0.259 ... Validation loss: 0.445\r",
      "Progress: 72.3% ... Training loss: 0.258 ... Validation loss: 0.440\r",
      "Progress: 72.3% ... Training loss: 0.254 ... Validation loss: 0.437\r",
      "Progress: 72.3% ... Training loss: 0.262 ... Validation loss: 0.444\r",
      "Progress: 72.4% ... Training loss: 0.259 ... Validation loss: 0.446\r",
      "Progress: 72.4% ... Training loss: 0.265 ... Validation loss: 0.452\r",
      "Progress: 72.4% ... Training loss: 0.287 ... Validation loss: 0.468\r",
      "Progress: 72.4% ... Training loss: 0.280 ... Validation loss: 0.471\r",
      "Progress: 72.4% ... Training loss: 0.328 ... Validation loss: 0.505\r",
      "Progress: 72.5% ... Training loss: 0.262 ... Validation loss: 0.458\r",
      "Progress: 72.5% ... Training loss: 0.260 ... Validation loss: 0.447\r",
      "Progress: 72.5% ... Training loss: 0.258 ... Validation loss: 0.450\r",
      "Progress: 72.5% ... Training loss: 0.257 ... Validation loss: 0.445\r",
      "Progress: 72.5% ... Training loss: 0.265 ... Validation loss: 0.449\r",
      "Progress: 72.5% ... Training loss: 0.282 ... Validation loss: 0.467\r",
      "Progress: 72.6% ... Training loss: 0.295 ... Validation loss: 0.483\r",
      "Progress: 72.6% ... Training loss: 0.258 ... Validation loss: 0.445\r",
      "Progress: 72.6% ... Training loss: 0.253 ... Validation loss: 0.442\r",
      "Progress: 72.6% ... Training loss: 0.254 ... Validation loss: 0.444\r",
      "Progress: 72.6% ... Training loss: 0.254 ... Validation loss: 0.441\r",
      "Progress: 72.7% ... Training loss: 0.263 ... Validation loss: 0.450\r",
      "Progress: 72.7% ... Training loss: 0.252 ... Validation loss: 0.436\r",
      "Progress: 72.7% ... Training loss: 0.253 ... Validation loss: 0.438\r",
      "Progress: 72.7% ... Training loss: 0.252 ... Validation loss: 0.436\r",
      "Progress: 72.7% ... Training loss: 0.276 ... Validation loss: 0.460\r",
      "Progress: 72.7% ... Training loss: 0.258 ... Validation loss: 0.441\r",
      "Progress: 72.8% ... Training loss: 0.262 ... Validation loss: 0.446\r",
      "Progress: 72.8% ... Training loss: 0.256 ... Validation loss: 0.441\r",
      "Progress: 72.8% ... Training loss: 0.253 ... Validation loss: 0.434\r",
      "Progress: 72.8% ... Training loss: 0.259 ... Validation loss: 0.437\r",
      "Progress: 72.8% ... Training loss: 0.259 ... Validation loss: 0.440\r",
      "Progress: 72.9% ... Training loss: 0.268 ... Validation loss: 0.440\r",
      "Progress: 72.9% ... Training loss: 0.267 ... Validation loss: 0.448\r",
      "Progress: 72.9% ... Training loss: 0.276 ... Validation loss: 0.454\r",
      "Progress: 72.9% ... Training loss: 0.284 ... Validation loss: 0.465\r",
      "Progress: 72.9% ... Training loss: 0.301 ... Validation loss: 0.484\r",
      "Progress: 72.9% ... Training loss: 0.267 ... Validation loss: 0.449\r",
      "Progress: 73.0% ... Training loss: 0.256 ... Validation loss: 0.436\r",
      "Progress: 73.0% ... Training loss: 0.255 ... Validation loss: 0.436\r",
      "Progress: 73.0% ... Training loss: 0.257 ... Validation loss: 0.440\r",
      "Progress: 73.0% ... Training loss: 0.259 ... Validation loss: 0.437\r",
      "Progress: 73.0% ... Training loss: 0.266 ... Validation loss: 0.444\r",
      "Progress: 73.1% ... Training loss: 0.283 ... Validation loss: 0.465\r",
      "Progress: 73.1% ... Training loss: 0.268 ... Validation loss: 0.443\r",
      "Progress: 73.1% ... Training loss: 0.256 ... Validation loss: 0.437\r",
      "Progress: 73.1% ... Training loss: 0.254 ... Validation loss: 0.433\r",
      "Progress: 73.1% ... Training loss: 0.271 ... Validation loss: 0.447\r",
      "Progress: 73.1% ... Training loss: 0.252 ... Validation loss: 0.435\r",
      "Progress: 73.2% ... Training loss: 0.278 ... Validation loss: 0.457\r",
      "Progress: 73.2% ... Training loss: 0.283 ... Validation loss: 0.469\r",
      "Progress: 73.2% ... Training loss: 0.254 ... Validation loss: 0.437\r",
      "Progress: 73.2% ... Training loss: 0.253 ... Validation loss: 0.436\r",
      "Progress: 73.2% ... Training loss: 0.275 ... Validation loss: 0.455\r",
      "Progress: 73.3% ... Training loss: 0.253 ... Validation loss: 0.437\r",
      "Progress: 73.3% ... Training loss: 0.255 ... Validation loss: 0.438\r",
      "Progress: 73.3% ... Training loss: 0.252 ... Validation loss: 0.435\r",
      "Progress: 73.3% ... Training loss: 0.252 ... Validation loss: 0.434\r",
      "Progress: 73.3% ... Training loss: 0.252 ... Validation loss: 0.435\r",
      "Progress: 73.3% ... Training loss: 0.252 ... Validation loss: 0.436\r",
      "Progress: 73.4% ... Training loss: 0.255 ... Validation loss: 0.439\r",
      "Progress: 73.4% ... Training loss: 0.265 ... Validation loss: 0.452\r",
      "Progress: 73.4% ... Training loss: 0.252 ... Validation loss: 0.437\r",
      "Progress: 73.4% ... Training loss: 0.259 ... Validation loss: 0.447\r",
      "Progress: 73.4% ... Training loss: 0.253 ... Validation loss: 0.435\r",
      "Progress: 73.5% ... Training loss: 0.257 ... Validation loss: 0.437\r",
      "Progress: 73.5% ... Training loss: 0.253 ... Validation loss: 0.442\r",
      "Progress: 73.5% ... Training loss: 0.269 ... Validation loss: 0.449\r",
      "Progress: 73.5% ... Training loss: 0.257 ... Validation loss: 0.444\r",
      "Progress: 73.5% ... Training loss: 0.282 ... Validation loss: 0.461\r",
      "Progress: 73.5% ... Training loss: 0.252 ... Validation loss: 0.439\r",
      "Progress: 73.6% ... Training loss: 0.254 ... Validation loss: 0.441\r",
      "Progress: 73.6% ... Training loss: 0.255 ... Validation loss: 0.438\r",
      "Progress: 73.6% ... Training loss: 0.253 ... Validation loss: 0.437\r",
      "Progress: 73.6% ... Training loss: 0.263 ... Validation loss: 0.443\r",
      "Progress: 73.6% ... Training loss: 0.255 ... Validation loss: 0.440\r",
      "Progress: 73.7% ... Training loss: 0.266 ... Validation loss: 0.449\r",
      "Progress: 73.7% ... Training loss: 0.262 ... Validation loss: 0.442\r",
      "Progress: 73.7% ... Training loss: 0.287 ... Validation loss: 0.467\r",
      "Progress: 73.7% ... Training loss: 0.258 ... Validation loss: 0.441\r",
      "Progress: 73.7% ... Training loss: 0.261 ... Validation loss: 0.444\r",
      "Progress: 73.7% ... Training loss: 0.255 ... Validation loss: 0.439\r",
      "Progress: 73.8% ... Training loss: 0.269 ... Validation loss: 0.455\r",
      "Progress: 73.8% ... Training loss: 0.253 ... Validation loss: 0.437\r",
      "Progress: 73.8% ... Training loss: 0.266 ... Validation loss: 0.452\r",
      "Progress: 73.8% ... Training loss: 0.253 ... Validation loss: 0.436\r",
      "Progress: 73.8% ... Training loss: 0.252 ... Validation loss: 0.435\r",
      "Progress: 73.9% ... Training loss: 0.251 ... Validation loss: 0.434\r",
      "Progress: 73.9% ... Training loss: 0.256 ... Validation loss: 0.439\r",
      "Progress: 73.9% ... Training loss: 0.258 ... Validation loss: 0.446\r",
      "Progress: 73.9% ... Training loss: 0.261 ... Validation loss: 0.444\r",
      "Progress: 73.9% ... Training loss: 0.252 ... Validation loss: 0.438\r",
      "Progress: 73.9% ... Training loss: 0.255 ... Validation loss: 0.440\r",
      "Progress: 74.0% ... Training loss: 0.252 ... Validation loss: 0.440\r",
      "Progress: 74.0% ... Training loss: 0.264 ... Validation loss: 0.456\r",
      "Progress: 74.0% ... Training loss: 0.252 ... Validation loss: 0.440\r",
      "Progress: 74.0% ... Training loss: 0.283 ... Validation loss: 0.472\r",
      "Progress: 74.0% ... Training loss: 0.262 ... Validation loss: 0.447\r",
      "Progress: 74.1% ... Training loss: 0.280 ... Validation loss: 0.469\r",
      "Progress: 74.1% ... Training loss: 0.275 ... Validation loss: 0.451\r",
      "Progress: 74.1% ... Training loss: 0.296 ... Validation loss: 0.487\r",
      "Progress: 74.1% ... Training loss: 0.323 ... Validation loss: 0.503\r",
      "Progress: 74.1% ... Training loss: 0.338 ... Validation loss: 0.533\r",
      "Progress: 74.1% ... Training loss: 0.286 ... Validation loss: 0.461\r",
      "Progress: 74.2% ... Training loss: 0.268 ... Validation loss: 0.459\r",
      "Progress: 74.2% ... Training loss: 0.254 ... Validation loss: 0.439\r",
      "Progress: 74.2% ... Training loss: 0.252 ... Validation loss: 0.435\r",
      "Progress: 74.2% ... Training loss: 0.253 ... Validation loss: 0.435\r",
      "Progress: 74.2% ... Training loss: 0.257 ... Validation loss: 0.446\r",
      "Progress: 74.3% ... Training loss: 0.252 ... Validation loss: 0.436\r",
      "Progress: 74.3% ... Training loss: 0.253 ... Validation loss: 0.436\r",
      "Progress: 74.3% ... Training loss: 0.253 ... Validation loss: 0.440\r",
      "Progress: 74.3% ... Training loss: 0.252 ... Validation loss: 0.440\r",
      "Progress: 74.3% ... Training loss: 0.260 ... Validation loss: 0.451\r",
      "Progress: 74.3% ... Training loss: 0.253 ... Validation loss: 0.442\r",
      "Progress: 74.4% ... Training loss: 0.254 ... Validation loss: 0.446\r",
      "Progress: 74.4% ... Training loss: 0.255 ... Validation loss: 0.442\r",
      "Progress: 74.4% ... Training loss: 0.252 ... Validation loss: 0.443\r",
      "Progress: 74.4% ... Training loss: 0.252 ... Validation loss: 0.440\r",
      "Progress: 74.4% ... Training loss: 0.276 ... Validation loss: 0.466\r",
      "Progress: 74.5% ... Training loss: 0.253 ... Validation loss: 0.443\r",
      "Progress: 74.5% ... Training loss: 0.263 ... Validation loss: 0.453\r",
      "Progress: 74.5% ... Training loss: 0.265 ... Validation loss: 0.455\r",
      "Progress: 74.5% ... Training loss: 0.282 ... Validation loss: 0.471\r",
      "Progress: 74.5% ... Training loss: 0.311 ... Validation loss: 0.495\r",
      "Progress: 74.5% ... Training loss: 0.277 ... Validation loss: 0.467\r",
      "Progress: 74.6% ... Training loss: 0.283 ... Validation loss: 0.463\r",
      "Progress: 74.6% ... Training loss: 0.326 ... Validation loss: 0.518\r",
      "Progress: 74.6% ... Training loss: 0.273 ... Validation loss: 0.458\r",
      "Progress: 74.6% ... Training loss: 0.252 ... Validation loss: 0.438\r",
      "Progress: 74.6% ... Training loss: 0.253 ... Validation loss: 0.437\r",
      "Progress: 74.7% ... Training loss: 0.252 ... Validation loss: 0.437\r",
      "Progress: 74.7% ... Training loss: 0.270 ... Validation loss: 0.458\r",
      "Progress: 74.7% ... Training loss: 0.282 ... Validation loss: 0.470\r",
      "Progress: 74.7% ... Training loss: 0.252 ... Validation loss: 0.442\r",
      "Progress: 74.7% ... Training loss: 0.252 ... Validation loss: 0.444\r",
      "Progress: 74.7% ... Training loss: 0.251 ... Validation loss: 0.440\r",
      "Progress: 74.8% ... Training loss: 0.269 ... Validation loss: 0.453\r",
      "Progress: 74.8% ... Training loss: 0.253 ... Validation loss: 0.440\r",
      "Progress: 74.8% ... Training loss: 0.252 ... Validation loss: 0.438\r",
      "Progress: 74.8% ... Training loss: 0.251 ... Validation loss: 0.437\r",
      "Progress: 74.8% ... Training loss: 0.251 ... Validation loss: 0.435\r",
      "Progress: 74.9% ... Training loss: 0.265 ... Validation loss: 0.449\r",
      "Progress: 74.9% ... Training loss: 0.257 ... Validation loss: 0.447\r",
      "Progress: 74.9% ... Training loss: 0.274 ... Validation loss: 0.455\r",
      "Progress: 74.9% ... Training loss: 0.251 ... Validation loss: 0.439\r",
      "Progress: 74.9% ... Training loss: 0.258 ... Validation loss: 0.446\r",
      "Progress: 74.9% ... Training loss: 0.274 ... Validation loss: 0.455\r",
      "Progress: 75.0% ... Training loss: 0.256 ... Validation loss: 0.444\r",
      "Progress: 75.0% ... Training loss: 0.254 ... Validation loss: 0.440\r",
      "Progress: 75.0% ... Training loss: 0.255 ... Validation loss: 0.444\r",
      "Progress: 75.0% ... Training loss: 0.254 ... Validation loss: 0.440\r",
      "Progress: 75.0% ... Training loss: 0.252 ... Validation loss: 0.441\r",
      "Progress: 75.1% ... Training loss: 0.251 ... Validation loss: 0.437\r",
      "Progress: 75.1% ... Training loss: 0.256 ... Validation loss: 0.442\r",
      "Progress: 75.1% ... Training loss: 0.277 ... Validation loss: 0.462\r",
      "Progress: 75.1% ... Training loss: 0.250 ... Validation loss: 0.439\r",
      "Progress: 75.1% ... Training loss: 0.253 ... Validation loss: 0.440\r",
      "Progress: 75.1% ... Training loss: 0.277 ... Validation loss: 0.464\r",
      "Progress: 75.2% ... Training loss: 0.260 ... Validation loss: 0.450\r",
      "Progress: 75.2% ... Training loss: 0.258 ... Validation loss: 0.447\r",
      "Progress: 75.2% ... Training loss: 0.251 ... Validation loss: 0.442\r",
      "Progress: 75.2% ... Training loss: 0.251 ... Validation loss: 0.440\r",
      "Progress: 75.2% ... Training loss: 0.251 ... Validation loss: 0.440\r",
      "Progress: 75.3% ... Training loss: 0.251 ... Validation loss: 0.440\r",
      "Progress: 75.3% ... Training loss: 0.252 ... Validation loss: 0.443\r",
      "Progress: 75.3% ... Training loss: 0.307 ... Validation loss: 0.493\r",
      "Progress: 75.3% ... Training loss: 0.273 ... Validation loss: 0.462\r",
      "Progress: 75.3% ... Training loss: 0.252 ... Validation loss: 0.440\r",
      "Progress: 75.3% ... Training loss: 0.250 ... Validation loss: 0.439\r",
      "Progress: 75.4% ... Training loss: 0.251 ... Validation loss: 0.440\r",
      "Progress: 75.4% ... Training loss: 0.253 ... Validation loss: 0.444\r",
      "Progress: 75.4% ... Training loss: 0.271 ... Validation loss: 0.456\r",
      "Progress: 75.4% ... Training loss: 0.266 ... Validation loss: 0.455\r",
      "Progress: 75.4% ... Training loss: 0.254 ... Validation loss: 0.440\r",
      "Progress: 75.5% ... Training loss: 0.250 ... Validation loss: 0.437\r",
      "Progress: 75.5% ... Training loss: 0.252 ... Validation loss: 0.442\r",
      "Progress: 75.5% ... Training loss: 0.250 ... Validation loss: 0.438\r",
      "Progress: 75.5% ... Training loss: 0.250 ... Validation loss: 0.437\r",
      "Progress: 75.5% ... Training loss: 0.289 ... Validation loss: 0.464\r",
      "Progress: 75.5% ... Training loss: 0.250 ... Validation loss: 0.432\r",
      "Progress: 75.6% ... Training loss: 0.251 ... Validation loss: 0.433\r",
      "Progress: 75.6% ... Training loss: 0.253 ... Validation loss: 0.431\r",
      "Progress: 75.6% ... Training loss: 0.255 ... Validation loss: 0.431\r",
      "Progress: 75.6% ... Training loss: 0.276 ... Validation loss: 0.466\r",
      "Progress: 75.6% ... Training loss: 0.265 ... Validation loss: 0.444\r",
      "Progress: 75.7% ... Training loss: 0.283 ... Validation loss: 0.474\r",
      "Progress: 75.7% ... Training loss: 0.253 ... Validation loss: 0.436\r",
      "Progress: 75.7% ... Training loss: 0.251 ... Validation loss: 0.434\r",
      "Progress: 75.7% ... Training loss: 0.252 ... Validation loss: 0.438\r",
      "Progress: 75.7% ... Training loss: 0.249 ... Validation loss: 0.436\r",
      "Progress: 75.7% ... Training loss: 0.256 ... Validation loss: 0.440\r",
      "Progress: 75.8% ... Training loss: 0.251 ... Validation loss: 0.437\r",
      "Progress: 75.8% ... Training loss: 0.263 ... Validation loss: 0.450\r",
      "Progress: 75.8% ... Training loss: 0.257 ... Validation loss: 0.445\r",
      "Progress: 75.8% ... Training loss: 0.255 ... Validation loss: 0.441\r",
      "Progress: 75.8% ... Training loss: 0.258 ... Validation loss: 0.446\r",
      "Progress: 75.9% ... Training loss: 0.262 ... Validation loss: 0.450\r",
      "Progress: 75.9% ... Training loss: 0.272 ... Validation loss: 0.458\r",
      "Progress: 75.9% ... Training loss: 0.254 ... Validation loss: 0.442\r",
      "Progress: 75.9% ... Training loss: 0.250 ... Validation loss: 0.438\r",
      "Progress: 75.9% ... Training loss: 0.260 ... Validation loss: 0.445\r",
      "Progress: 75.9% ... Training loss: 0.250 ... Validation loss: 0.437\r",
      "Progress: 76.0% ... Training loss: 0.253 ... Validation loss: 0.436\r",
      "Progress: 76.0% ... Training loss: 0.256 ... Validation loss: 0.441\r",
      "Progress: 76.0% ... Training loss: 0.254 ... Validation loss: 0.441\r",
      "Progress: 76.0% ... Training loss: 0.253 ... Validation loss: 0.441\r",
      "Progress: 76.0% ... Training loss: 0.261 ... Validation loss: 0.448\r",
      "Progress: 76.1% ... Training loss: 0.258 ... Validation loss: 0.447\r",
      "Progress: 76.1% ... Training loss: 0.250 ... Validation loss: 0.440\r",
      "Progress: 76.1% ... Training loss: 0.250 ... Validation loss: 0.439\r",
      "Progress: 76.1% ... Training loss: 0.275 ... Validation loss: 0.467\r",
      "Progress: 76.1% ... Training loss: 0.253 ... Validation loss: 0.441\r",
      "Progress: 76.1% ... Training loss: 0.249 ... Validation loss: 0.438\r",
      "Progress: 76.2% ... Training loss: 0.250 ... Validation loss: 0.442\r",
      "Progress: 76.2% ... Training loss: 0.251 ... Validation loss: 0.441\r",
      "Progress: 76.2% ... Training loss: 0.250 ... Validation loss: 0.440\r",
      "Progress: 76.2% ... Training loss: 0.254 ... Validation loss: 0.445\r",
      "Progress: 76.2% ... Training loss: 0.262 ... Validation loss: 0.452\r",
      "Progress: 76.3% ... Training loss: 0.252 ... Validation loss: 0.440\r",
      "Progress: 76.3% ... Training loss: 0.257 ... Validation loss: 0.445\r",
      "Progress: 76.3% ... Training loss: 0.259 ... Validation loss: 0.446\r",
      "Progress: 76.3% ... Training loss: 0.252 ... Validation loss: 0.438\r",
      "Progress: 76.3% ... Training loss: 0.251 ... Validation loss: 0.437\r",
      "Progress: 76.3% ... Training loss: 0.259 ... Validation loss: 0.443\r",
      "Progress: 76.4% ... Training loss: 0.253 ... Validation loss: 0.441\r",
      "Progress: 76.4% ... Training loss: 0.249 ... Validation loss: 0.437\r",
      "Progress: 76.4% ... Training loss: 0.254 ... Validation loss: 0.445\r",
      "Progress: 76.4% ... Training loss: 0.253 ... Validation loss: 0.445\r",
      "Progress: 76.4% ... Training loss: 0.250 ... Validation loss: 0.438\r",
      "Progress: 76.5% ... Training loss: 0.249 ... Validation loss: 0.437\r",
      "Progress: 76.5% ... Training loss: 0.258 ... Validation loss: 0.448\r",
      "Progress: 76.5% ... Training loss: 0.269 ... Validation loss: 0.452\r",
      "Progress: 76.5% ... Training loss: 0.262 ... Validation loss: 0.451\r",
      "Progress: 76.5% ... Training loss: 0.253 ... Validation loss: 0.439\r",
      "Progress: 76.5% ... Training loss: 0.259 ... Validation loss: 0.451\r",
      "Progress: 76.6% ... Training loss: 0.249 ... Validation loss: 0.437\r",
      "Progress: 76.6% ... Training loss: 0.259 ... Validation loss: 0.443\r",
      "Progress: 76.6% ... Training loss: 0.253 ... Validation loss: 0.442\r",
      "Progress: 76.6% ... Training loss: 0.254 ... Validation loss: 0.438\r",
      "Progress: 76.6% ... Training loss: 0.252 ... Validation loss: 0.442\r",
      "Progress: 76.7% ... Training loss: 0.262 ... Validation loss: 0.445\r",
      "Progress: 76.7% ... Training loss: 0.262 ... Validation loss: 0.455\r",
      "Progress: 76.7% ... Training loss: 0.281 ... Validation loss: 0.461\r",
      "Progress: 76.7% ... Training loss: 0.273 ... Validation loss: 0.466\r",
      "Progress: 76.7% ... Training loss: 0.251 ... Validation loss: 0.443\r",
      "Progress: 76.7% ... Training loss: 0.250 ... Validation loss: 0.443\r",
      "Progress: 76.8% ... Training loss: 0.254 ... Validation loss: 0.443\r",
      "Progress: 76.8% ... Training loss: 0.252 ... Validation loss: 0.446\r",
      "Progress: 76.8% ... Training loss: 0.249 ... Validation loss: 0.441\r",
      "Progress: 76.8% ... Training loss: 0.254 ... Validation loss: 0.447\r",
      "Progress: 76.8% ... Training loss: 0.249 ... Validation loss: 0.442\r",
      "Progress: 76.9% ... Training loss: 0.258 ... Validation loss: 0.446\r",
      "Progress: 76.9% ... Training loss: 0.250 ... Validation loss: 0.438\r",
      "Progress: 76.9% ... Training loss: 0.267 ... Validation loss: 0.449\r",
      "Progress: 76.9% ... Training loss: 0.266 ... Validation loss: 0.460\r",
      "Progress: 76.9% ... Training loss: 0.277 ... Validation loss: 0.459\r",
      "Progress: 76.9% ... Training loss: 0.259 ... Validation loss: 0.451\r",
      "Progress: 77.0% ... Training loss: 0.255 ... Validation loss: 0.443\r",
      "Progress: 77.0% ... Training loss: 0.252 ... Validation loss: 0.444\r",
      "Progress: 77.0% ... Training loss: 0.268 ... Validation loss: 0.452\r",
      "Progress: 77.0% ... Training loss: 0.269 ... Validation loss: 0.459\r",
      "Progress: 77.0% ... Training loss: 0.252 ... Validation loss: 0.440\r",
      "Progress: 77.1% ... Training loss: 0.250 ... Validation loss: 0.439\r",
      "Progress: 77.1% ... Training loss: 0.267 ... Validation loss: 0.454\r",
      "Progress: 77.1% ... Training loss: 0.259 ... Validation loss: 0.446\r",
      "Progress: 77.1% ... Training loss: 0.249 ... Validation loss: 0.438\r",
      "Progress: 77.1% ... Training loss: 0.248 ... Validation loss: 0.436\r",
      "Progress: 77.1% ... Training loss: 0.248 ... Validation loss: 0.433\r",
      "Progress: 77.2% ... Training loss: 0.252 ... Validation loss: 0.435\r",
      "Progress: 77.2% ... Training loss: 0.248 ... Validation loss: 0.432\r",
      "Progress: 77.2% ... Training loss: 0.260 ... Validation loss: 0.443\r",
      "Progress: 77.2% ... Training loss: 0.300 ... Validation loss: 0.482\r",
      "Progress: 77.2% ... Training loss: 0.250 ... Validation loss: 0.437\r",
      "Progress: 77.3% ... Training loss: 0.266 ... Validation loss: 0.449\r",
      "Progress: 77.3% ... Training loss: 0.256 ... Validation loss: 0.444\r",
      "Progress: 77.3% ... Training loss: 0.249 ... Validation loss: 0.437\r",
      "Progress: 77.3% ... Training loss: 0.248 ... Validation loss: 0.438\r",
      "Progress: 77.3% ... Training loss: 0.255 ... Validation loss: 0.442\r",
      "Progress: 77.3% ... Training loss: 0.256 ... Validation loss: 0.446\r",
      "Progress: 77.4% ... Training loss: 0.251 ... Validation loss: 0.438\r",
      "Progress: 77.4% ... Training loss: 0.248 ... Validation loss: 0.439\r",
      "Progress: 77.4% ... Training loss: 0.251 ... Validation loss: 0.445\r",
      "Progress: 77.4% ... Training loss: 0.250 ... Validation loss: 0.439\r",
      "Progress: 77.4% ... Training loss: 0.263 ... Validation loss: 0.449\r",
      "Progress: 77.5% ... Training loss: 0.262 ... Validation loss: 0.460\r",
      "Progress: 77.5% ... Training loss: 0.259 ... Validation loss: 0.448\r",
      "Progress: 77.5% ... Training loss: 0.253 ... Validation loss: 0.439\r",
      "Progress: 77.5% ... Training loss: 0.256 ... Validation loss: 0.451\r",
      "Progress: 77.5% ... Training loss: 0.287 ... Validation loss: 0.466\r",
      "Progress: 77.5% ... Training loss: 0.313 ... Validation loss: 0.517\r",
      "Progress: 77.6% ... Training loss: 0.305 ... Validation loss: 0.481\r",
      "Progress: 77.6% ... Training loss: 0.278 ... Validation loss: 0.476\r",
      "Progress: 77.6% ... Training loss: 0.269 ... Validation loss: 0.453\r",
      "Progress: 77.6% ... Training loss: 0.268 ... Validation loss: 0.461\r",
      "Progress: 77.6% ... Training loss: 0.268 ... Validation loss: 0.453\r",
      "Progress: 77.7% ... Training loss: 0.253 ... Validation loss: 0.448\r",
      "Progress: 77.7% ... Training loss: 0.248 ... Validation loss: 0.437\r",
      "Progress: 77.7% ... Training loss: 0.251 ... Validation loss: 0.442\r",
      "Progress: 77.7% ... Training loss: 0.248 ... Validation loss: 0.438\r",
      "Progress: 77.7% ... Training loss: 0.248 ... Validation loss: 0.436\r",
      "Progress: 77.7% ... Training loss: 0.255 ... Validation loss: 0.445\r",
      "Progress: 77.8% ... Training loss: 0.259 ... Validation loss: 0.443\r",
      "Progress: 77.8% ... Training loss: 0.260 ... Validation loss: 0.448\r",
      "Progress: 77.8% ... Training loss: 0.264 ... Validation loss: 0.446\r",
      "Progress: 77.8% ... Training loss: 0.251 ... Validation loss: 0.442\r",
      "Progress: 77.8% ... Training loss: 0.252 ... Validation loss: 0.444\r",
      "Progress: 77.9% ... Training loss: 0.251 ... Validation loss: 0.437\r",
      "Progress: 77.9% ... Training loss: 0.257 ... Validation loss: 0.442\r",
      "Progress: 77.9% ... Training loss: 0.249 ... Validation loss: 0.440\r",
      "Progress: 77.9% ... Training loss: 0.263 ... Validation loss: 0.445\r",
      "Progress: 77.9% ... Training loss: 0.280 ... Validation loss: 0.480\r",
      "Progress: 77.9% ... Training loss: 0.248 ... Validation loss: 0.436\r",
      "Progress: 78.0% ... Training loss: 0.251 ... Validation loss: 0.436\r",
      "Progress: 78.0% ... Training loss: 0.247 ... Validation loss: 0.433\r",
      "Progress: 78.0% ... Training loss: 0.248 ... Validation loss: 0.433\r",
      "Progress: 78.0% ... Training loss: 0.271 ... Validation loss: 0.455\r",
      "Progress: 78.0% ... Training loss: 0.267 ... Validation loss: 0.452\r",
      "Progress: 78.1% ... Training loss: 0.248 ... Validation loss: 0.432\r",
      "Progress: 78.1% ... Training loss: 0.250 ... Validation loss: 0.433\r",
      "Progress: 78.1% ... Training loss: 0.248 ... Validation loss: 0.431\r",
      "Progress: 78.1% ... Training loss: 0.247 ... Validation loss: 0.432\r",
      "Progress: 78.1% ... Training loss: 0.247 ... Validation loss: 0.434\r",
      "Progress: 78.1% ... Training loss: 0.248 ... Validation loss: 0.436\r",
      "Progress: 78.2% ... Training loss: 0.248 ... Validation loss: 0.436\r",
      "Progress: 78.2% ... Training loss: 0.254 ... Validation loss: 0.440\r",
      "Progress: 78.2% ... Training loss: 0.259 ... Validation loss: 0.450\r",
      "Progress: 78.2% ... Training loss: 0.265 ... Validation loss: 0.451\r",
      "Progress: 78.2% ... Training loss: 0.256 ... Validation loss: 0.445\r",
      "Progress: 78.3% ... Training loss: 0.275 ... Validation loss: 0.460\r",
      "Progress: 78.3% ... Training loss: 0.275 ... Validation loss: 0.466\r",
      "Progress: 78.3% ... Training loss: 0.278 ... Validation loss: 0.463\r",
      "Progress: 78.3% ... Training loss: 0.261 ... Validation loss: 0.455\r",
      "Progress: 78.3% ... Training loss: 0.249 ... Validation loss: 0.440\r",
      "Progress: 78.3% ... Training loss: 0.254 ... Validation loss: 0.443\r",
      "Progress: 78.4% ... Training loss: 0.290 ... Validation loss: 0.479\r",
      "Progress: 78.4% ... Training loss: 0.247 ... Validation loss: 0.434\r",
      "Progress: 78.4% ... Training loss: 0.255 ... Validation loss: 0.442\r",
      "Progress: 78.4% ... Training loss: 0.247 ... Validation loss: 0.432\r",
      "Progress: 78.4% ... Training loss: 0.258 ... Validation loss: 0.440\r",
      "Progress: 78.5% ... Training loss: 0.273 ... Validation loss: 0.458\r",
      "Progress: 78.5% ... Training loss: 0.301 ... Validation loss: 0.477\r",
      "Progress: 78.5% ... Training loss: 0.304 ... Validation loss: 0.489\r",
      "Progress: 78.5% ... Training loss: 0.286 ... Validation loss: 0.466\r",
      "Progress: 78.5% ... Training loss: 0.276 ... Validation loss: 0.460\r",
      "Progress: 78.5% ... Training loss: 0.275 ... Validation loss: 0.455\r",
      "Progress: 78.6% ... Training loss: 0.262 ... Validation loss: 0.445\r",
      "Progress: 78.6% ... Training loss: 0.258 ... Validation loss: 0.440\r",
      "Progress: 78.6% ... Training loss: 0.282 ... Validation loss: 0.464\r",
      "Progress: 78.6% ... Training loss: 0.271 ... Validation loss: 0.453\r",
      "Progress: 78.6% ... Training loss: 0.260 ... Validation loss: 0.447\r",
      "Progress: 78.7% ... Training loss: 0.252 ... Validation loss: 0.436\r",
      "Progress: 78.7% ... Training loss: 0.247 ... Validation loss: 0.433\r",
      "Progress: 78.7% ... Training loss: 0.253 ... Validation loss: 0.440\r",
      "Progress: 78.7% ... Training loss: 0.248 ... Validation loss: 0.439\r",
      "Progress: 78.7% ... Training loss: 0.247 ... Validation loss: 0.437\r",
      "Progress: 78.7% ... Training loss: 0.247 ... Validation loss: 0.438\r",
      "Progress: 78.8% ... Training loss: 0.250 ... Validation loss: 0.440\r",
      "Progress: 78.8% ... Training loss: 0.254 ... Validation loss: 0.445\r",
      "Progress: 78.8% ... Training loss: 0.257 ... Validation loss: 0.446\r",
      "Progress: 78.8% ... Training loss: 0.249 ... Validation loss: 0.439\r",
      "Progress: 78.8% ... Training loss: 0.254 ... Validation loss: 0.447\r",
      "Progress: 78.9% ... Training loss: 0.256 ... Validation loss: 0.447\r",
      "Progress: 78.9% ... Training loss: 0.253 ... Validation loss: 0.447\r",
      "Progress: 78.9% ... Training loss: 0.247 ... Validation loss: 0.439\r",
      "Progress: 78.9% ... Training loss: 0.250 ... Validation loss: 0.443\r",
      "Progress: 78.9% ... Training loss: 0.247 ... Validation loss: 0.440\r",
      "Progress: 78.9% ... Training loss: 0.249 ... Validation loss: 0.441\r",
      "Progress: 79.0% ... Training loss: 0.247 ... Validation loss: 0.441\r",
      "Progress: 79.0% ... Training loss: 0.265 ... Validation loss: 0.458\r",
      "Progress: 79.0% ... Training loss: 0.250 ... Validation loss: 0.449\r",
      "Progress: 79.0% ... Training loss: 0.248 ... Validation loss: 0.443\r",
      "Progress: 79.0% ... Training loss: 0.247 ... Validation loss: 0.441\r",
      "Progress: 79.1% ... Training loss: 0.248 ... Validation loss: 0.442\r",
      "Progress: 79.1% ... Training loss: 0.249 ... Validation loss: 0.441\r",
      "Progress: 79.1% ... Training loss: 0.248 ... Validation loss: 0.439\r",
      "Progress: 79.1% ... Training loss: 0.249 ... Validation loss: 0.442\r",
      "Progress: 79.1% ... Training loss: 0.247 ... Validation loss: 0.441\r",
      "Progress: 79.1% ... Training loss: 0.253 ... Validation loss: 0.445\r",
      "Progress: 79.2% ... Training loss: 0.254 ... Validation loss: 0.446\r",
      "Progress: 79.2% ... Training loss: 0.291 ... Validation loss: 0.488\r",
      "Progress: 79.2% ... Training loss: 0.250 ... Validation loss: 0.439\r",
      "Progress: 79.2% ... Training loss: 0.247 ... Validation loss: 0.439\r",
      "Progress: 79.2% ... Training loss: 0.248 ... Validation loss: 0.437\r",
      "Progress: 79.3% ... Training loss: 0.256 ... Validation loss: 0.443\r",
      "Progress: 79.3% ... Training loss: 0.253 ... Validation loss: 0.442\r",
      "Progress: 79.3% ... Training loss: 0.311 ... Validation loss: 0.502\r",
      "Progress: 79.3% ... Training loss: 0.292 ... Validation loss: 0.475\r",
      "Progress: 79.3% ... Training loss: 0.259 ... Validation loss: 0.447\r",
      "Progress: 79.3% ... Training loss: 0.257 ... Validation loss: 0.444\r",
      "Progress: 79.4% ... Training loss: 0.246 ... Validation loss: 0.437\r",
      "Progress: 79.4% ... Training loss: 0.246 ... Validation loss: 0.436\r",
      "Progress: 79.4% ... Training loss: 0.248 ... Validation loss: 0.437\r",
      "Progress: 79.4% ... Training loss: 0.253 ... Validation loss: 0.445\r",
      "Progress: 79.4% ... Training loss: 0.246 ... Validation loss: 0.433\r",
      "Progress: 79.5% ... Training loss: 0.255 ... Validation loss: 0.441\r",
      "Progress: 79.5% ... Training loss: 0.276 ... Validation loss: 0.464\r",
      "Progress: 79.5% ... Training loss: 0.256 ... Validation loss: 0.441\r",
      "Progress: 79.5% ... Training loss: 0.247 ... Validation loss: 0.433\r",
      "Progress: 79.5% ... Training loss: 0.246 ... Validation loss: 0.434\r",
      "Progress: 79.5% ... Training loss: 0.246 ... Validation loss: 0.435\r",
      "Progress: 79.6% ... Training loss: 0.246 ... Validation loss: 0.434\r",
      "Progress: 79.6% ... Training loss: 0.263 ... Validation loss: 0.451\r",
      "Progress: 79.6% ... Training loss: 0.266 ... Validation loss: 0.455\r",
      "Progress: 79.6% ... Training loss: 0.263 ... Validation loss: 0.448\r",
      "Progress: 79.6% ... Training loss: 0.254 ... Validation loss: 0.442\r",
      "Progress: 79.7% ... Training loss: 0.246 ... Validation loss: 0.436\r",
      "Progress: 79.7% ... Training loss: 0.247 ... Validation loss: 0.437\r",
      "Progress: 79.7% ... Training loss: 0.245 ... Validation loss: 0.436\r",
      "Progress: 79.7% ... Training loss: 0.251 ... Validation loss: 0.441\r",
      "Progress: 79.7% ... Training loss: 0.245 ... Validation loss: 0.432\r",
      "Progress: 79.7% ... Training loss: 0.245 ... Validation loss: 0.435\r",
      "Progress: 79.8% ... Training loss: 0.248 ... Validation loss: 0.437\r",
      "Progress: 79.8% ... Training loss: 0.247 ... Validation loss: 0.438\r",
      "Progress: 79.8% ... Training loss: 0.251 ... Validation loss: 0.441\r",
      "Progress: 79.8% ... Training loss: 0.283 ... Validation loss: 0.469\r",
      "Progress: 79.8% ... Training loss: 0.250 ... Validation loss: 0.442\r",
      "Progress: 79.9% ... Training loss: 0.246 ... Validation loss: 0.436\r",
      "Progress: 79.9% ... Training loss: 0.248 ... Validation loss: 0.438\r",
      "Progress: 79.9% ... Training loss: 0.253 ... Validation loss: 0.442\r",
      "Progress: 79.9% ... Training loss: 0.253 ... Validation loss: 0.443\r",
      "Progress: 79.9% ... Training loss: 0.270 ... Validation loss: 0.455\r",
      "Progress: 79.9% ... Training loss: 0.250 ... Validation loss: 0.441\r",
      "Progress: 80.0% ... Training loss: 0.256 ... Validation loss: 0.445\r",
      "Progress: 80.0% ... Training loss: 0.255 ... Validation loss: 0.440\r",
      "Progress: 80.0% ... Training loss: 0.245 ... Validation loss: 0.431\r",
      "Progress: 80.0% ... Training loss: 0.257 ... Validation loss: 0.441\r",
      "Progress: 80.0% ... Training loss: 0.248 ... Validation loss: 0.433\r",
      "Progress: 80.1% ... Training loss: 0.261 ... Validation loss: 0.446\r",
      "Progress: 80.1% ... Training loss: 0.260 ... Validation loss: 0.442\r",
      "Progress: 80.1% ... Training loss: 0.274 ... Validation loss: 0.464\r",
      "Progress: 80.1% ... Training loss: 0.281 ... Validation loss: 0.461\r",
      "Progress: 80.1% ... Training loss: 0.262 ... Validation loss: 0.448\r",
      "Progress: 80.1% ... Training loss: 0.250 ... Validation loss: 0.434\r",
      "Progress: 80.2% ... Training loss: 0.246 ... Validation loss: 0.432\r",
      "Progress: 80.2% ... Training loss: 0.246 ... Validation loss: 0.434\r",
      "Progress: 80.2% ... Training loss: 0.246 ... Validation loss: 0.433\r",
      "Progress: 80.2% ... Training loss: 0.248 ... Validation loss: 0.435\r",
      "Progress: 80.2% ... Training loss: 0.246 ... Validation loss: 0.433\r",
      "Progress: 80.3% ... Training loss: 0.256 ... Validation loss: 0.444\r",
      "Progress: 80.3% ... Training loss: 0.249 ... Validation loss: 0.438\r",
      "Progress: 80.3% ... Training loss: 0.245 ... Validation loss: 0.436\r",
      "Progress: 80.3% ... Training loss: 0.251 ... Validation loss: 0.443\r",
      "Progress: 80.3% ... Training loss: 0.253 ... Validation loss: 0.441\r",
      "Progress: 80.3% ... Training loss: 0.246 ... Validation loss: 0.433\r",
      "Progress: 80.4% ... Training loss: 0.245 ... Validation loss: 0.433\r",
      "Progress: 80.4% ... Training loss: 0.250 ... Validation loss: 0.432\r",
      "Progress: 80.4% ... Training loss: 0.259 ... Validation loss: 0.448\r",
      "Progress: 80.4% ... Training loss: 0.248 ... Validation loss: 0.436\r",
      "Progress: 80.4% ... Training loss: 0.250 ... Validation loss: 0.434\r",
      "Progress: 80.5% ... Training loss: 0.245 ... Validation loss: 0.431\r",
      "Progress: 80.5% ... Training loss: 0.252 ... Validation loss: 0.440\r",
      "Progress: 80.5% ... Training loss: 0.272 ... Validation loss: 0.457\r",
      "Progress: 80.5% ... Training loss: 0.274 ... Validation loss: 0.463\r",
      "Progress: 80.5% ... Training loss: 0.247 ... Validation loss: 0.437\r",
      "Progress: 80.5% ... Training loss: 0.259 ... Validation loss: 0.450\r",
      "Progress: 80.6% ... Training loss: 0.245 ... Validation loss: 0.436\r",
      "Progress: 80.6% ... Training loss: 0.248 ... Validation loss: 0.439\r",
      "Progress: 80.6% ... Training loss: 0.256 ... Validation loss: 0.441\r",
      "Progress: 80.6% ... Training loss: 0.251 ... Validation loss: 0.440\r",
      "Progress: 80.6% ... Training loss: 0.246 ... Validation loss: 0.434\r",
      "Progress: 80.7% ... Training loss: 0.249 ... Validation loss: 0.437\r",
      "Progress: 80.7% ... Training loss: 0.250 ... Validation loss: 0.432\r",
      "Progress: 80.7% ... Training loss: 0.247 ... Validation loss: 0.433\r",
      "Progress: 80.7% ... Training loss: 0.273 ... Validation loss: 0.446\r",
      "Progress: 80.7% ... Training loss: 0.260 ... Validation loss: 0.449\r",
      "Progress: 80.7% ... Training loss: 0.246 ... Validation loss: 0.427\r",
      "Progress: 80.8% ... Training loss: 0.247 ... Validation loss: 0.428\r",
      "Progress: 80.8% ... Training loss: 0.275 ... Validation loss: 0.469\r",
      "Progress: 80.8% ... Training loss: 0.250 ... Validation loss: 0.435\r",
      "Progress: 80.8% ... Training loss: 0.245 ... Validation loss: 0.433\r",
      "Progress: 80.8% ... Training loss: 0.246 ... Validation loss: 0.434\r",
      "Progress: 80.9% ... Training loss: 0.245 ... Validation loss: 0.433\r",
      "Progress: 80.9% ... Training loss: 0.252 ... Validation loss: 0.442\r",
      "Progress: 80.9% ... Training loss: 0.246 ... Validation loss: 0.435\r",
      "Progress: 80.9% ... Training loss: 0.251 ... Validation loss: 0.436\r",
      "Progress: 80.9% ... Training loss: 0.245 ... Validation loss: 0.432\r",
      "Progress: 80.9% ... Training loss: 0.258 ... Validation loss: 0.438\r",
      "Progress: 81.0% ... Training loss: 0.246 ... Validation loss: 0.431\r",
      "Progress: 81.0% ... Training loss: 0.244 ... Validation loss: 0.430\r",
      "Progress: 81.0% ... Training loss: 0.245 ... Validation loss: 0.432\r",
      "Progress: 81.0% ... Training loss: 0.246 ... Validation loss: 0.431\r",
      "Progress: 81.0% ... Training loss: 0.248 ... Validation loss: 0.436\r",
      "Progress: 81.1% ... Training loss: 0.248 ... Validation loss: 0.432\r",
      "Progress: 81.1% ... Training loss: 0.246 ... Validation loss: 0.435\r",
      "Progress: 81.1% ... Training loss: 0.275 ... Validation loss: 0.458\r",
      "Progress: 81.1% ... Training loss: 0.280 ... Validation loss: 0.468\r",
      "Progress: 81.1% ... Training loss: 0.245 ... Validation loss: 0.432\r",
      "Progress: 81.1% ... Training loss: 0.286 ... Validation loss: 0.465\r",
      "Progress: 81.2% ... Training loss: 0.267 ... Validation loss: 0.456\r",
      "Progress: 81.2% ... Training loss: 0.248 ... Validation loss: 0.436\r",
      "Progress: 81.2% ... Training loss: 0.245 ... Validation loss: 0.432\r",
      "Progress: 81.2% ... Training loss: 0.252 ... Validation loss: 0.435\r",
      "Progress: 81.2% ... Training loss: 0.244 ... Validation loss: 0.426\r",
      "Progress: 81.3% ... Training loss: 0.249 ... Validation loss: 0.428\r",
      "Progress: 81.3% ... Training loss: 0.247 ... Validation loss: 0.430\r",
      "Progress: 81.3% ... Training loss: 0.249 ... Validation loss: 0.431\r",
      "Progress: 81.3% ... Training loss: 0.244 ... Validation loss: 0.424\r",
      "Progress: 81.3% ... Training loss: 0.245 ... Validation loss: 0.424\r",
      "Progress: 81.3% ... Training loss: 0.252 ... Validation loss: 0.429\r",
      "Progress: 81.4% ... Training loss: 0.246 ... Validation loss: 0.425\r",
      "Progress: 81.4% ... Training loss: 0.245 ... Validation loss: 0.426\r",
      "Progress: 81.4% ... Training loss: 0.250 ... Validation loss: 0.431\r",
      "Progress: 81.4% ... Training loss: 0.250 ... Validation loss: 0.432\r",
      "Progress: 81.4% ... Training loss: 0.266 ... Validation loss: 0.442\r",
      "Progress: 81.5% ... Training loss: 0.298 ... Validation loss: 0.479\r",
      "Progress: 81.5% ... Training loss: 0.256 ... Validation loss: 0.436\r",
      "Progress: 81.5% ... Training loss: 0.258 ... Validation loss: 0.437\r",
      "Progress: 81.5% ... Training loss: 0.256 ... Validation loss: 0.440\r",
      "Progress: 81.5% ... Training loss: 0.245 ... Validation loss: 0.427\r",
      "Progress: 81.5% ... Training loss: 0.250 ... Validation loss: 0.430\r",
      "Progress: 81.6% ... Training loss: 0.251 ... Validation loss: 0.428\r",
      "Progress: 81.6% ... Training loss: 0.246 ... Validation loss: 0.423\r",
      "Progress: 81.6% ... Training loss: 0.245 ... Validation loss: 0.423\r",
      "Progress: 81.6% ... Training loss: 0.253 ... Validation loss: 0.431\r",
      "Progress: 81.6% ... Training loss: 0.249 ... Validation loss: 0.426\r",
      "Progress: 81.7% ... Training loss: 0.249 ... Validation loss: 0.428\r",
      "Progress: 81.7% ... Training loss: 0.245 ... Validation loss: 0.424\r",
      "Progress: 81.7% ... Training loss: 0.246 ... Validation loss: 0.426\r",
      "Progress: 81.7% ... Training loss: 0.250 ... Validation loss: 0.433\r",
      "Progress: 81.7% ... Training loss: 0.247 ... Validation loss: 0.426\r",
      "Progress: 81.7% ... Training loss: 0.250 ... Validation loss: 0.428\r",
      "Progress: 81.8% ... Training loss: 0.244 ... Validation loss: 0.424\r",
      "Progress: 81.8% ... Training loss: 0.247 ... Validation loss: 0.429\r",
      "Progress: 81.8% ... Training loss: 0.246 ... Validation loss: 0.423\r",
      "Progress: 81.8% ... Training loss: 0.244 ... Validation loss: 0.423\r",
      "Progress: 81.8% ... Training loss: 0.254 ... Validation loss: 0.438\r",
      "Progress: 81.9% ... Training loss: 0.255 ... Validation loss: 0.432\r",
      "Progress: 81.9% ... Training loss: 0.245 ... Validation loss: 0.426\r",
      "Progress: 81.9% ... Training loss: 0.243 ... Validation loss: 0.425\r",
      "Progress: 81.9% ... Training loss: 0.257 ... Validation loss: 0.434\r",
      "Progress: 81.9% ... Training loss: 0.248 ... Validation loss: 0.424\r",
      "Progress: 81.9% ... Training loss: 0.245 ... Validation loss: 0.421\r",
      "Progress: 82.0% ... Training loss: 0.244 ... Validation loss: 0.422\r",
      "Progress: 82.0% ... Training loss: 0.244 ... Validation loss: 0.422\r",
      "Progress: 82.0% ... Training loss: 0.243 ... Validation loss: 0.423\r",
      "Progress: 82.0% ... Training loss: 0.245 ... Validation loss: 0.424\r",
      "Progress: 82.0% ... Training loss: 0.248 ... Validation loss: 0.429\r",
      "Progress: 82.1% ... Training loss: 0.248 ... Validation loss: 0.426\r",
      "Progress: 82.1% ... Training loss: 0.248 ... Validation loss: 0.427\r",
      "Progress: 82.1% ... Training loss: 0.245 ... Validation loss: 0.426\r",
      "Progress: 82.1% ... Training loss: 0.244 ... Validation loss: 0.426\r",
      "Progress: 82.1% ... Training loss: 0.254 ... Validation loss: 0.439\r",
      "Progress: 82.1% ... Training loss: 0.259 ... Validation loss: 0.437\r",
      "Progress: 82.2% ... Training loss: 0.251 ... Validation loss: 0.433\r",
      "Progress: 82.2% ... Training loss: 0.243 ... Validation loss: 0.424\r",
      "Progress: 82.2% ... Training loss: 0.243 ... Validation loss: 0.425\r",
      "Progress: 82.2% ... Training loss: 0.245 ... Validation loss: 0.429\r",
      "Progress: 82.2% ... Training loss: 0.255 ... Validation loss: 0.436\r",
      "Progress: 82.3% ... Training loss: 0.256 ... Validation loss: 0.441\r",
      "Progress: 82.3% ... Training loss: 0.244 ... Validation loss: 0.425\r",
      "Progress: 82.3% ... Training loss: 0.302 ... Validation loss: 0.487\r",
      "Progress: 82.3% ... Training loss: 0.265 ... Validation loss: 0.440\r",
      "Progress: 82.3% ... Training loss: 0.244 ... Validation loss: 0.425\r",
      "Progress: 82.3% ... Training loss: 0.246 ... Validation loss: 0.425\r",
      "Progress: 82.4% ... Training loss: 0.255 ... Validation loss: 0.436\r",
      "Progress: 82.4% ... Training loss: 0.255 ... Validation loss: 0.433\r",
      "Progress: 82.4% ... Training loss: 0.257 ... Validation loss: 0.441\r",
      "Progress: 82.4% ... Training loss: 0.254 ... Validation loss: 0.432\r",
      "Progress: 82.4% ... Training loss: 0.246 ... Validation loss: 0.434\r",
      "Progress: 82.5% ... Training loss: 0.244 ... Validation loss: 0.430\r",
      "Progress: 82.5% ... Training loss: 0.249 ... Validation loss: 0.435\r",
      "Progress: 82.5% ... Training loss: 0.257 ... Validation loss: 0.435\r",
      "Progress: 82.5% ... Training loss: 0.251 ... Validation loss: 0.436\r",
      "Progress: 82.5% ... Training loss: 0.244 ... Validation loss: 0.423\r",
      "Progress: 82.5% ... Training loss: 0.243 ... Validation loss: 0.425\r",
      "Progress: 82.6% ... Training loss: 0.249 ... Validation loss: 0.427\r",
      "Progress: 82.6% ... Training loss: 0.246 ... Validation loss: 0.426\r",
      "Progress: 82.6% ... Training loss: 0.243 ... Validation loss: 0.424\r",
      "Progress: 82.6% ... Training loss: 0.243 ... Validation loss: 0.427\r",
      "Progress: 82.6% ... Training loss: 0.245 ... Validation loss: 0.424\r",
      "Progress: 82.7% ... Training loss: 0.243 ... Validation loss: 0.424\r",
      "Progress: 82.7% ... Training loss: 0.256 ... Validation loss: 0.436\r",
      "Progress: 82.7% ... Training loss: 0.275 ... Validation loss: 0.447\r",
      "Progress: 82.7% ... Training loss: 0.276 ... Validation loss: 0.458\r",
      "Progress: 82.7% ... Training loss: 0.273 ... Validation loss: 0.448\r",
      "Progress: 82.7% ... Training loss: 0.296 ... Validation loss: 0.475\r",
      "Progress: 82.8% ... Training loss: 0.285 ... Validation loss: 0.459\r",
      "Progress: 82.8% ... Training loss: 0.263 ... Validation loss: 0.447\r",
      "Progress: 82.8% ... Training loss: 0.300 ... Validation loss: 0.473\r",
      "Progress: 82.8% ... Training loss: 0.255 ... Validation loss: 0.439\r",
      "Progress: 82.8% ... Training loss: 0.248 ... Validation loss: 0.429\r",
      "Progress: 82.9% ... Training loss: 0.248 ... Validation loss: 0.431\r",
      "Progress: 82.9% ... Training loss: 0.247 ... Validation loss: 0.427\r",
      "Progress: 82.9% ... Training loss: 0.329 ... Validation loss: 0.510\r",
      "Progress: 82.9% ... Training loss: 0.288 ... Validation loss: 0.460\r",
      "Progress: 82.9% ... Training loss: 0.260 ... Validation loss: 0.442\r",
      "Progress: 82.9% ... Training loss: 0.248 ... Validation loss: 0.424\r",
      "Progress: 83.0% ... Training loss: 0.250 ... Validation loss: 0.429\r",
      "Progress: 83.0% ... Training loss: 0.244 ... Validation loss: 0.425\r",
      "Progress: 83.0% ... Training loss: 0.260 ... Validation loss: 0.445\r",
      "Progress: 83.0% ... Training loss: 0.278 ... Validation loss: 0.449\r",
      "Progress: 83.0% ... Training loss: 0.246 ... Validation loss: 0.430\r",
      "Progress: 83.1% ... Training loss: 0.254 ... Validation loss: 0.429\r",
      "Progress: 83.1% ... Training loss: 0.251 ... Validation loss: 0.435\r",
      "Progress: 83.1% ... Training loss: 0.243 ... Validation loss: 0.425\r",
      "Progress: 83.1% ... Training loss: 0.244 ... Validation loss: 0.424\r",
      "Progress: 83.1% ... Training loss: 0.246 ... Validation loss: 0.427\r",
      "Progress: 83.1% ... Training loss: 0.266 ... Validation loss: 0.447\r",
      "Progress: 83.2% ... Training loss: 0.281 ... Validation loss: 0.455\r",
      "Progress: 83.2% ... Training loss: 0.260 ... Validation loss: 0.446\r",
      "Progress: 83.2% ... Training loss: 0.248 ... Validation loss: 0.426\r",
      "Progress: 83.2% ... Training loss: 0.245 ... Validation loss: 0.430\r",
      "Progress: 83.2% ... Training loss: 0.242 ... Validation loss: 0.424\r",
      "Progress: 83.3% ... Training loss: 0.249 ... Validation loss: 0.427\r",
      "Progress: 83.3% ... Training loss: 0.242 ... Validation loss: 0.426\r",
      "Progress: 83.3% ... Training loss: 0.244 ... Validation loss: 0.429\r",
      "Progress: 83.3% ... Training loss: 0.267 ... Validation loss: 0.446\r",
      "Progress: 83.3% ... Training loss: 0.254 ... Validation loss: 0.441\r",
      "Progress: 83.3% ... Training loss: 0.242 ... Validation loss: 0.425\r",
      "Progress: 83.4% ... Training loss: 0.242 ... Validation loss: 0.424\r",
      "Progress: 83.4% ... Training loss: 0.244 ... Validation loss: 0.427\r",
      "Progress: 83.4% ... Training loss: 0.242 ... Validation loss: 0.425\r",
      "Progress: 83.4% ... Training loss: 0.247 ... Validation loss: 0.430\r",
      "Progress: 83.4% ... Training loss: 0.244 ... Validation loss: 0.427\r",
      "Progress: 83.5% ... Training loss: 0.257 ... Validation loss: 0.439\r",
      "Progress: 83.5% ... Training loss: 0.255 ... Validation loss: 0.435\r",
      "Progress: 83.5% ... Training loss: 0.263 ... Validation loss: 0.439\r",
      "Progress: 83.5% ... Training loss: 0.242 ... Validation loss: 0.421\r",
      "Progress: 83.5% ... Training loss: 0.243 ... Validation loss: 0.425\r",
      "Progress: 83.5% ... Training loss: 0.243 ... Validation loss: 0.425\r",
      "Progress: 83.6% ... Training loss: 0.247 ... Validation loss: 0.429\r",
      "Progress: 83.6% ... Training loss: 0.242 ... Validation loss: 0.423\r",
      "Progress: 83.6% ... Training loss: 0.245 ... Validation loss: 0.428\r",
      "Progress: 83.6% ... Training loss: 0.258 ... Validation loss: 0.437\r",
      "Progress: 83.6% ... Training loss: 0.254 ... Validation loss: 0.436\r",
      "Progress: 83.7% ... Training loss: 0.275 ... Validation loss: 0.450\r",
      "Progress: 83.7% ... Training loss: 0.275 ... Validation loss: 0.457\r",
      "Progress: 83.7% ... Training loss: 0.244 ... Validation loss: 0.427\r",
      "Progress: 83.7% ... Training loss: 0.252 ... Validation loss: 0.433\r",
      "Progress: 83.7% ... Training loss: 0.266 ... Validation loss: 0.450\r",
      "Progress: 83.7% ... Training loss: 0.245 ... Validation loss: 0.426\r",
      "Progress: 83.8% ... Training loss: 0.242 ... Validation loss: 0.427\r",
      "Progress: 83.8% ... Training loss: 0.245 ... Validation loss: 0.430\r",
      "Progress: 83.8% ... Training loss: 0.262 ... Validation loss: 0.456\r",
      "Progress: 83.8% ... Training loss: 0.246 ... Validation loss: 0.431\r",
      "Progress: 83.8% ... Training loss: 0.242 ... Validation loss: 0.431\r",
      "Progress: 83.9% ... Training loss: 0.249 ... Validation loss: 0.430\r",
      "Progress: 83.9% ... Training loss: 0.242 ... Validation loss: 0.429\r",
      "Progress: 83.9% ... Training loss: 0.241 ... Validation loss: 0.425\r",
      "Progress: 83.9% ... Training loss: 0.241 ... Validation loss: 0.425\r",
      "Progress: 83.9% ... Training loss: 0.257 ... Validation loss: 0.441\r",
      "Progress: 83.9% ... Training loss: 0.247 ... Validation loss: 0.428\r",
      "Progress: 84.0% ... Training loss: 0.242 ... Validation loss: 0.423\r",
      "Progress: 84.0% ... Training loss: 0.247 ... Validation loss: 0.429\r",
      "Progress: 84.0% ... Training loss: 0.293 ... Validation loss: 0.471\r",
      "Progress: 84.0% ... Training loss: 0.290 ... Validation loss: 0.477\r",
      "Progress: 84.0% ... Training loss: 0.263 ... Validation loss: 0.444\r",
      "Progress: 84.1% ... Training loss: 0.252 ... Validation loss: 0.441\r",
      "Progress: 84.1% ... Training loss: 0.242 ... Validation loss: 0.428\r",
      "Progress: 84.1% ... Training loss: 0.247 ... Validation loss: 0.432\r",
      "Progress: 84.1% ... Training loss: 0.245 ... Validation loss: 0.429\r",
      "Progress: 84.1% ... Training loss: 0.244 ... Validation loss: 0.429\r",
      "Progress: 84.1% ... Training loss: 0.254 ... Validation loss: 0.440\r",
      "Progress: 84.2% ... Training loss: 0.260 ... Validation loss: 0.438\r",
      "Progress: 84.2% ... Training loss: 0.258 ... Validation loss: 0.453\r",
      "Progress: 84.2% ... Training loss: 0.250 ... Validation loss: 0.430\r",
      "Progress: 84.2% ... Training loss: 0.262 ... Validation loss: 0.454\r",
      "Progress: 84.2% ... Training loss: 0.242 ... Validation loss: 0.424\r",
      "Progress: 84.3% ... Training loss: 0.241 ... Validation loss: 0.425\r",
      "Progress: 84.3% ... Training loss: 0.250 ... Validation loss: 0.428\r",
      "Progress: 84.3% ... Training loss: 0.242 ... Validation loss: 0.425\r",
      "Progress: 84.3% ... Training loss: 0.243 ... Validation loss: 0.425\r",
      "Progress: 84.3% ... Training loss: 0.241 ... Validation loss: 0.424\r",
      "Progress: 84.3% ... Training loss: 0.243 ... Validation loss: 0.424\r",
      "Progress: 84.4% ... Training loss: 0.249 ... Validation loss: 0.435\r",
      "Progress: 84.4% ... Training loss: 0.248 ... Validation loss: 0.429\r",
      "Progress: 84.4% ... Training loss: 0.242 ... Validation loss: 0.423\r",
      "Progress: 84.4% ... Training loss: 0.256 ... Validation loss: 0.435\r",
      "Progress: 84.4% ... Training loss: 0.243 ... Validation loss: 0.422\r",
      "Progress: 84.5% ... Training loss: 0.242 ... Validation loss: 0.422\r",
      "Progress: 84.5% ... Training loss: 0.248 ... Validation loss: 0.430\r",
      "Progress: 84.5% ... Training loss: 0.246 ... Validation loss: 0.426\r",
      "Progress: 84.5% ... Training loss: 0.247 ... Validation loss: 0.424\r",
      "Progress: 84.5% ... Training loss: 0.245 ... Validation loss: 0.426\r",
      "Progress: 84.5% ... Training loss: 0.256 ... Validation loss: 0.433\r",
      "Progress: 84.6% ... Training loss: 0.245 ... Validation loss: 0.428\r",
      "Progress: 84.6% ... Training loss: 0.244 ... Validation loss: 0.421\r",
      "Progress: 84.6% ... Training loss: 0.241 ... Validation loss: 0.423\r",
      "Progress: 84.6% ... Training loss: 0.246 ... Validation loss: 0.421\r",
      "Progress: 84.6% ... Training loss: 0.242 ... Validation loss: 0.425\r",
      "Progress: 84.7% ... Training loss: 0.256 ... Validation loss: 0.427\r",
      "Progress: 84.7% ... Training loss: 0.250 ... Validation loss: 0.438\r",
      "Progress: 84.7% ... Training loss: 0.254 ... Validation loss: 0.428\r",
      "Progress: 84.7% ... Training loss: 0.241 ... Validation loss: 0.421\r",
      "Progress: 84.7% ... Training loss: 0.240 ... Validation loss: 0.422\r",
      "Progress: 84.7% ... Training loss: 0.243 ... Validation loss: 0.427\r",
      "Progress: 84.8% ... Training loss: 0.244 ... Validation loss: 0.422\r",
      "Progress: 84.8% ... Training loss: 0.250 ... Validation loss: 0.440\r",
      "Progress: 84.8% ... Training loss: 0.245 ... Validation loss: 0.422\r",
      "Progress: 84.8% ... Training loss: 0.249 ... Validation loss: 0.438\r",
      "Progress: 84.8% ... Training loss: 0.256 ... Validation loss: 0.427\r",
      "Progress: 84.9% ... Training loss: 0.279 ... Validation loss: 0.475\r",
      "Progress: 84.9% ... Training loss: 0.286 ... Validation loss: 0.451\r",
      "Progress: 84.9% ... Training loss: 0.248 ... Validation loss: 0.437\r",
      "Progress: 84.9% ... Training loss: 0.281 ... Validation loss: 0.450\r",
      "Progress: 84.9% ... Training loss: 0.274 ... Validation loss: 0.463\r",
      "Progress: 84.9% ... Training loss: 0.242 ... Validation loss: 0.424\r",
      "Progress: 85.0% ... Training loss: 0.240 ... Validation loss: 0.425\r",
      "Progress: 85.0% ... Training loss: 0.240 ... Validation loss: 0.423\r",
      "Progress: 85.0% ... Training loss: 0.243 ... Validation loss: 0.428\r",
      "Progress: 85.0% ... Training loss: 0.241 ... Validation loss: 0.424\r",
      "Progress: 85.0% ... Training loss: 0.240 ... Validation loss: 0.422\r",
      "Progress: 85.1% ... Training loss: 0.256 ... Validation loss: 0.445\r",
      "Progress: 85.1% ... Training loss: 0.269 ... Validation loss: 0.448\r",
      "Progress: 85.1% ... Training loss: 0.243 ... Validation loss: 0.430\r",
      "Progress: 85.1% ... Training loss: 0.240 ... Validation loss: 0.423\r",
      "Progress: 85.1% ... Training loss: 0.242 ... Validation loss: 0.428\r",
      "Progress: 85.1% ... Training loss: 0.244 ... Validation loss: 0.424\r",
      "Progress: 85.2% ... Training loss: 0.261 ... Validation loss: 0.447\r",
      "Progress: 85.2% ... Training loss: 0.267 ... Validation loss: 0.449\r",
      "Progress: 85.2% ... Training loss: 0.260 ... Validation loss: 0.446\r",
      "Progress: 85.2% ... Training loss: 0.245 ... Validation loss: 0.427\r",
      "Progress: 85.2% ... Training loss: 0.260 ... Validation loss: 0.446\r",
      "Progress: 85.3% ... Training loss: 0.243 ... Validation loss: 0.429\r",
      "Progress: 85.3% ... Training loss: 0.239 ... Validation loss: 0.425\r",
      "Progress: 85.3% ... Training loss: 0.240 ... Validation loss: 0.424\r",
      "Progress: 85.3% ... Training loss: 0.240 ... Validation loss: 0.425\r",
      "Progress: 85.3% ... Training loss: 0.241 ... Validation loss: 0.424\r",
      "Progress: 85.3% ... Training loss: 0.256 ... Validation loss: 0.444\r",
      "Progress: 85.4% ... Training loss: 0.246 ... Validation loss: 0.427\r",
      "Progress: 85.4% ... Training loss: 0.260 ... Validation loss: 0.451\r",
      "Progress: 85.4% ... Training loss: 0.243 ... Validation loss: 0.425\r",
      "Progress: 85.4% ... Training loss: 0.240 ... Validation loss: 0.427\r",
      "Progress: 85.4% ... Training loss: 0.248 ... Validation loss: 0.427\r",
      "Progress: 85.5% ... Training loss: 0.240 ... Validation loss: 0.426\r",
      "Progress: 85.5% ... Training loss: 0.275 ... Validation loss: 0.468\r",
      "Progress: 85.5% ... Training loss: 0.262 ... Validation loss: 0.443\r",
      "Progress: 85.5% ... Training loss: 0.239 ... Validation loss: 0.424\r",
      "Progress: 85.5% ... Training loss: 0.249 ... Validation loss: 0.427\r",
      "Progress: 85.5% ... Training loss: 0.264 ... Validation loss: 0.450\r",
      "Progress: 85.6% ... Training loss: 0.264 ... Validation loss: 0.441\r",
      "Progress: 85.6% ... Training loss: 0.252 ... Validation loss: 0.438\r",
      "Progress: 85.6% ... Training loss: 0.243 ... Validation loss: 0.429\r",
      "Progress: 85.6% ... Training loss: 0.242 ... Validation loss: 0.429\r",
      "Progress: 85.6% ... Training loss: 0.240 ... Validation loss: 0.426\r",
      "Progress: 85.7% ... Training loss: 0.239 ... Validation loss: 0.424\r",
      "Progress: 85.7% ... Training loss: 0.244 ... Validation loss: 0.430\r",
      "Progress: 85.7% ... Training loss: 0.282 ... Validation loss: 0.458\r",
      "Progress: 85.7% ... Training loss: 0.245 ... Validation loss: 0.431\r",
      "Progress: 85.7% ... Training loss: 0.239 ... Validation loss: 0.422\r",
      "Progress: 85.7% ... Training loss: 0.239 ... Validation loss: 0.424\r",
      "Progress: 85.8% ... Training loss: 0.240 ... Validation loss: 0.427\r",
      "Progress: 85.8% ... Training loss: 0.249 ... Validation loss: 0.431\r",
      "Progress: 85.8% ... Training loss: 0.245 ... Validation loss: 0.433\r",
      "Progress: 85.8% ... Training loss: 0.246 ... Validation loss: 0.431\r",
      "Progress: 85.8% ... Training loss: 0.244 ... Validation loss: 0.429\r",
      "Progress: 85.9% ... Training loss: 0.272 ... Validation loss: 0.450\r",
      "Progress: 85.9% ... Training loss: 0.248 ... Validation loss: 0.432\r",
      "Progress: 85.9% ... Training loss: 0.251 ... Validation loss: 0.428\r",
      "Progress: 85.9% ... Training loss: 0.238 ... Validation loss: 0.420\r",
      "Progress: 85.9% ... Training loss: 0.259 ... Validation loss: 0.446\r",
      "Progress: 85.9% ... Training loss: 0.241 ... Validation loss: 0.421\r",
      "Progress: 86.0% ... Training loss: 0.242 ... Validation loss: 0.429\r",
      "Progress: 86.0% ... Training loss: 0.244 ... Validation loss: 0.425\r",
      "Progress: 86.0% ... Training loss: 0.239 ... Validation loss: 0.421\r",
      "Progress: 86.0% ... Training loss: 0.249 ... Validation loss: 0.431\r",
      "Progress: 86.0% ... Training loss: 0.238 ... Validation loss: 0.420\r",
      "Progress: 86.1% ... Training loss: 0.256 ... Validation loss: 0.443\r",
      "Progress: 86.1% ... Training loss: 0.239 ... Validation loss: 0.425\r",
      "Progress: 86.1% ... Training loss: 0.239 ... Validation loss: 0.427\r",
      "Progress: 86.1% ... Training loss: 0.240 ... Validation loss: 0.428\r",
      "Progress: 86.1% ... Training loss: 0.240 ... Validation loss: 0.425\r",
      "Progress: 86.1% ... Training loss: 0.242 ... Validation loss: 0.428\r",
      "Progress: 86.2% ... Training loss: 0.239 ... Validation loss: 0.425\r",
      "Progress: 86.2% ... Training loss: 0.246 ... Validation loss: 0.425\r",
      "Progress: 86.2% ... Training loss: 0.239 ... Validation loss: 0.418\r",
      "Progress: 86.2% ... Training loss: 0.243 ... Validation loss: 0.421\r",
      "Progress: 86.2% ... Training loss: 0.238 ... Validation loss: 0.421\r",
      "Progress: 86.3% ... Training loss: 0.255 ... Validation loss: 0.431\r",
      "Progress: 86.3% ... Training loss: 0.255 ... Validation loss: 0.428\r",
      "Progress: 86.3% ... Training loss: 0.247 ... Validation loss: 0.430\r",
      "Progress: 86.3% ... Training loss: 0.240 ... Validation loss: 0.422\r",
      "Progress: 86.3% ... Training loss: 0.244 ... Validation loss: 0.418\r",
      "Progress: 86.3% ... Training loss: 0.243 ... Validation loss: 0.417\r",
      "Progress: 86.4% ... Training loss: 0.240 ... Validation loss: 0.420\r",
      "Progress: 86.4% ... Training loss: 0.243 ... Validation loss: 0.426\r",
      "Progress: 86.4% ... Training loss: 0.243 ... Validation loss: 0.427\r",
      "Progress: 86.4% ... Training loss: 0.239 ... Validation loss: 0.423\r",
      "Progress: 86.4% ... Training loss: 0.252 ... Validation loss: 0.438\r",
      "Progress: 86.5% ... Training loss: 0.248 ... Validation loss: 0.426\r",
      "Progress: 86.5% ... Training loss: 0.280 ... Validation loss: 0.471\r",
      "Progress: 86.5% ... Training loss: 0.261 ... Validation loss: 0.430\r",
      "Progress: 86.5% ... Training loss: 0.261 ... Validation loss: 0.453\r",
      "Progress: 86.5% ... Training loss: 0.246 ... Validation loss: 0.420\r",
      "Progress: 86.5% ... Training loss: 0.240 ... Validation loss: 0.424\r",
      "Progress: 86.6% ... Training loss: 0.238 ... Validation loss: 0.421\r",
      "Progress: 86.6% ... Training loss: 0.249 ... Validation loss: 0.423\r",
      "Progress: 86.6% ... Training loss: 0.245 ... Validation loss: 0.431\r",
      "Progress: 86.6% ... Training loss: 0.252 ... Validation loss: 0.429\r",
      "Progress: 86.6% ... Training loss: 0.238 ... Validation loss: 0.418\r",
      "Progress: 86.7% ... Training loss: 0.238 ... Validation loss: 0.420\r",
      "Progress: 86.7% ... Training loss: 0.242 ... Validation loss: 0.427\r",
      "Progress: 86.7% ... Training loss: 0.240 ... Validation loss: 0.426\r",
      "Progress: 86.7% ... Training loss: 0.264 ... Validation loss: 0.441\r",
      "Progress: 86.7% ... Training loss: 0.257 ... Validation loss: 0.445\r",
      "Progress: 86.7% ... Training loss: 0.282 ... Validation loss: 0.454\r",
      "Progress: 86.8% ... Training loss: 0.243 ... Validation loss: 0.429\r",
      "Progress: 86.8% ... Training loss: 0.250 ... Validation loss: 0.430\r",
      "Progress: 86.8% ... Training loss: 0.240 ... Validation loss: 0.423\r",
      "Progress: 86.8% ... Training loss: 0.241 ... Validation loss: 0.425\r",
      "Progress: 86.8% ... Training loss: 0.238 ... Validation loss: 0.419\r",
      "Progress: 86.9% ... Training loss: 0.240 ... Validation loss: 0.419\r",
      "Progress: 86.9% ... Training loss: 0.245 ... Validation loss: 0.431\r",
      "Progress: 86.9% ... Training loss: 0.245 ... Validation loss: 0.426\r",
      "Progress: 86.9% ... Training loss: 0.238 ... Validation loss: 0.419\r",
      "Progress: 86.9% ... Training loss: 0.237 ... Validation loss: 0.419\r",
      "Progress: 86.9% ... Training loss: 0.240 ... Validation loss: 0.421\r",
      "Progress: 87.0% ... Training loss: 0.238 ... Validation loss: 0.420\r",
      "Progress: 87.0% ... Training loss: 0.241 ... Validation loss: 0.422\r",
      "Progress: 87.0% ... Training loss: 0.237 ... Validation loss: 0.419\r",
      "Progress: 87.0% ... Training loss: 0.238 ... Validation loss: 0.420\r",
      "Progress: 87.0% ... Training loss: 0.238 ... Validation loss: 0.418\r",
      "Progress: 87.1% ... Training loss: 0.238 ... Validation loss: 0.419\r",
      "Progress: 87.1% ... Training loss: 0.238 ... Validation loss: 0.417\r",
      "Progress: 87.1% ... Training loss: 0.241 ... Validation loss: 0.421\r",
      "Progress: 87.1% ... Training loss: 0.240 ... Validation loss: 0.422\r",
      "Progress: 87.1% ... Training loss: 0.238 ... Validation loss: 0.420\r",
      "Progress: 87.1% ... Training loss: 0.265 ... Validation loss: 0.448\r",
      "Progress: 87.2% ... Training loss: 0.242 ... Validation loss: 0.421\r",
      "Progress: 87.2% ... Training loss: 0.238 ... Validation loss: 0.418\r",
      "Progress: 87.2% ... Training loss: 0.245 ... Validation loss: 0.422\r",
      "Progress: 87.2% ... Training loss: 0.237 ... Validation loss: 0.417\r",
      "Progress: 87.2% ... Training loss: 0.238 ... Validation loss: 0.416\r",
      "Progress: 87.3% ... Training loss: 0.237 ... Validation loss: 0.418\r",
      "Progress: 87.3% ... Training loss: 0.239 ... Validation loss: 0.419\r",
      "Progress: 87.3% ... Training loss: 0.248 ... Validation loss: 0.425\r",
      "Progress: 87.3% ... Training loss: 0.278 ... Validation loss: 0.460\r",
      "Progress: 87.3% ... Training loss: 0.265 ... Validation loss: 0.442\r",
      "Progress: 87.3% ... Training loss: 0.265 ... Validation loss: 0.445\r",
      "Progress: 87.4% ... Training loss: 0.242 ... Validation loss: 0.422\r",
      "Progress: 87.4% ... Training loss: 0.239 ... Validation loss: 0.423\r",
      "Progress: 87.4% ... Training loss: 0.254 ... Validation loss: 0.432\r",
      "Progress: 87.4% ... Training loss: 0.245 ... Validation loss: 0.426\r",
      "Progress: 87.4% ... Training loss: 0.239 ... Validation loss: 0.420\r",
      "Progress: 87.5% ... Training loss: 0.241 ... Validation loss: 0.422\r",
      "Progress: 87.5% ... Training loss: 0.249 ... Validation loss: 0.432\r",
      "Progress: 87.5% ... Training loss: 0.256 ... Validation loss: 0.436\r",
      "Progress: 87.5% ... Training loss: 0.287 ... Validation loss: 0.470\r",
      "Progress: 87.5% ... Training loss: 0.276 ... Validation loss: 0.456\r",
      "Progress: 87.5% ... Training loss: 0.255 ... Validation loss: 0.439\r",
      "Progress: 87.6% ... Training loss: 0.250 ... Validation loss: 0.430\r",
      "Progress: 87.6% ... Training loss: 0.237 ... Validation loss: 0.419\r",
      "Progress: 87.6% ... Training loss: 0.239 ... Validation loss: 0.420\r",
      "Progress: 87.6% ... Training loss: 0.252 ... Validation loss: 0.436\r",
      "Progress: 87.6% ... Training loss: 0.249 ... Validation loss: 0.429\r",
      "Progress: 87.7% ... Training loss: 0.243 ... Validation loss: 0.427\r",
      "Progress: 87.7% ... Training loss: 0.247 ... Validation loss: 0.427\r",
      "Progress: 87.7% ... Training loss: 0.240 ... Validation loss: 0.423\r",
      "Progress: 87.7% ... Training loss: 0.238 ... Validation loss: 0.420\r",
      "Progress: 87.7% ... Training loss: 0.237 ... Validation loss: 0.420\r",
      "Progress: 87.7% ... Training loss: 0.257 ... Validation loss: 0.442\r",
      "Progress: 87.8% ... Training loss: 0.248 ... Validation loss: 0.432\r",
      "Progress: 87.8% ... Training loss: 0.245 ... Validation loss: 0.429\r",
      "Progress: 87.8% ... Training loss: 0.236 ... Validation loss: 0.419\r",
      "Progress: 87.8% ... Training loss: 0.237 ... Validation loss: 0.420\r",
      "Progress: 87.8% ... Training loss: 0.244 ... Validation loss: 0.426\r",
      "Progress: 87.9% ... Training loss: 0.240 ... Validation loss: 0.423\r",
      "Progress: 87.9% ... Training loss: 0.246 ... Validation loss: 0.430\r",
      "Progress: 87.9% ... Training loss: 0.239 ... Validation loss: 0.424\r",
      "Progress: 87.9% ... Training loss: 0.242 ... Validation loss: 0.427\r",
      "Progress: 87.9% ... Training loss: 0.245 ... Validation loss: 0.430\r",
      "Progress: 87.9% ... Training loss: 0.245 ... Validation loss: 0.431\r",
      "Progress: 88.0% ... Training loss: 0.242 ... Validation loss: 0.427\r",
      "Progress: 88.0% ... Training loss: 0.236 ... Validation loss: 0.421\r",
      "Progress: 88.0% ... Training loss: 0.237 ... Validation loss: 0.422\r",
      "Progress: 88.0% ... Training loss: 0.242 ... Validation loss: 0.427\r",
      "Progress: 88.0% ... Training loss: 0.245 ... Validation loss: 0.430\r",
      "Progress: 88.1% ... Training loss: 0.236 ... Validation loss: 0.421\r",
      "Progress: 88.1% ... Training loss: 0.241 ... Validation loss: 0.426\r",
      "Progress: 88.1% ... Training loss: 0.244 ... Validation loss: 0.430\r",
      "Progress: 88.1% ... Training loss: 0.247 ... Validation loss: 0.432\r",
      "Progress: 88.1% ... Training loss: 0.270 ... Validation loss: 0.456\r",
      "Progress: 88.1% ... Training loss: 0.237 ... Validation loss: 0.423\r",
      "Progress: 88.2% ... Training loss: 0.237 ... Validation loss: 0.424\r",
      "Progress: 88.2% ... Training loss: 0.237 ... Validation loss: 0.424\r",
      "Progress: 88.2% ... Training loss: 0.245 ... Validation loss: 0.433\r",
      "Progress: 88.2% ... Training loss: 0.242 ... Validation loss: 0.429\r",
      "Progress: 88.2% ... Training loss: 0.259 ... Validation loss: 0.448\r",
      "Progress: 88.3% ... Training loss: 0.240 ... Validation loss: 0.429\r",
      "Progress: 88.3% ... Training loss: 0.245 ... Validation loss: 0.434\r",
      "Progress: 88.3% ... Training loss: 0.236 ... Validation loss: 0.424\r",
      "Progress: 88.3% ... Training loss: 0.236 ... Validation loss: 0.425\r",
      "Progress: 88.3% ... Training loss: 0.251 ... Validation loss: 0.435\r",
      "Progress: 88.3% ... Training loss: 0.243 ... Validation loss: 0.432\r",
      "Progress: 88.4% ... Training loss: 0.242 ... Validation loss: 0.429\r",
      "Progress: 88.4% ... Training loss: 0.239 ... Validation loss: 0.425\r",
      "Progress: 88.4% ... Training loss: 0.243 ... Validation loss: 0.429\r",
      "Progress: 88.4% ... Training loss: 0.273 ... Validation loss: 0.462\r",
      "Progress: 88.4% ... Training loss: 0.267 ... Validation loss: 0.451\r",
      "Progress: 88.5% ... Training loss: 0.235 ... Validation loss: 0.422\r",
      "Progress: 88.5% ... Training loss: 0.241 ... Validation loss: 0.427\r",
      "Progress: 88.5% ... Training loss: 0.256 ... Validation loss: 0.438\r",
      "Progress: 88.5% ... Training loss: 0.243 ... Validation loss: 0.429\r",
      "Progress: 88.5% ... Training loss: 0.267 ... Validation loss: 0.450\r",
      "Progress: 88.5% ... Training loss: 0.252 ... Validation loss: 0.444\r",
      "Progress: 88.6% ... Training loss: 0.237 ... Validation loss: 0.423\r",
      "Progress: 88.6% ... Training loss: 0.236 ... Validation loss: 0.422\r",
      "Progress: 88.6% ... Training loss: 0.245 ... Validation loss: 0.430\r",
      "Progress: 88.6% ... Training loss: 0.270 ... Validation loss: 0.456\r",
      "Progress: 88.6% ... Training loss: 0.277 ... Validation loss: 0.458\r",
      "Progress: 88.7% ... Training loss: 0.252 ... Validation loss: 0.440\r",
      "Progress: 88.7% ... Training loss: 0.261 ... Validation loss: 0.446\r",
      "Progress: 88.7% ... Training loss: 0.249 ... Validation loss: 0.435\r",
      "Progress: 88.7% ... Training loss: 0.235 ... Validation loss: 0.421\r",
      "Progress: 88.7% ... Training loss: 0.235 ... Validation loss: 0.420\r",
      "Progress: 88.7% ... Training loss: 0.235 ... Validation loss: 0.420\r",
      "Progress: 88.8% ... Training loss: 0.235 ... Validation loss: 0.420\r",
      "Progress: 88.8% ... Training loss: 0.290 ... Validation loss: 0.464\r",
      "Progress: 88.8% ... Training loss: 0.249 ... Validation loss: 0.434\r",
      "Progress: 88.8% ... Training loss: 0.248 ... Validation loss: 0.426\r",
      "Progress: 88.8% ... Training loss: 0.236 ... Validation loss: 0.419\r",
      "Progress: 88.9% ... Training loss: 0.244 ... Validation loss: 0.431\r",
      "Progress: 88.9% ... Training loss: 0.268 ... Validation loss: 0.457\r",
      "Progress: 88.9% ... Training loss: 0.301 ... Validation loss: 0.480\r",
      "Progress: 88.9% ... Training loss: 0.239 ... Validation loss: 0.427\r",
      "Progress: 88.9% ... Training loss: 0.262 ... Validation loss: 0.447\r",
      "Progress: 88.9% ... Training loss: 0.237 ... Validation loss: 0.426\r",
      "Progress: 89.0% ... Training loss: 0.235 ... Validation loss: 0.423\r",
      "Progress: 89.0% ... Training loss: 0.235 ... Validation loss: 0.423\r",
      "Progress: 89.0% ... Training loss: 0.235 ... Validation loss: 0.421\r",
      "Progress: 89.0% ... Training loss: 0.235 ... Validation loss: 0.420\r",
      "Progress: 89.0% ... Training loss: 0.250 ... Validation loss: 0.438\r",
      "Progress: 89.1% ... Training loss: 0.236 ... Validation loss: 0.419\r",
      "Progress: 89.1% ... Training loss: 0.236 ... Validation loss: 0.421\r",
      "Progress: 89.1% ... Training loss: 0.235 ... Validation loss: 0.418\r",
      "Progress: 89.1% ... Training loss: 0.240 ... Validation loss: 0.424\r",
      "Progress: 89.1% ... Training loss: 0.237 ... Validation loss: 0.422\r",
      "Progress: 89.1% ... Training loss: 0.239 ... Validation loss: 0.422\r",
      "Progress: 89.2% ... Training loss: 0.241 ... Validation loss: 0.424\r",
      "Progress: 89.2% ... Training loss: 0.236 ... Validation loss: 0.420\r",
      "Progress: 89.2% ... Training loss: 0.238 ... Validation loss: 0.419\r",
      "Progress: 89.2% ... Training loss: 0.235 ... Validation loss: 0.419\r",
      "Progress: 89.2% ... Training loss: 0.240 ... Validation loss: 0.422\r",
      "Progress: 89.3% ... Training loss: 0.254 ... Validation loss: 0.440\r",
      "Progress: 89.3% ... Training loss: 0.248 ... Validation loss: 0.431\r",
      "Progress: 89.3% ... Training loss: 0.243 ... Validation loss: 0.430\r",
      "Progress: 89.3% ... Training loss: 0.248 ... Validation loss: 0.426\r",
      "Progress: 89.3% ... Training loss: 0.251 ... Validation loss: 0.439\r",
      "Progress: 89.3% ... Training loss: 0.247 ... Validation loss: 0.424\r",
      "Progress: 89.4% ... Training loss: 0.237 ... Validation loss: 0.420\r",
      "Progress: 89.4% ... Training loss: 0.264 ... Validation loss: 0.438\r",
      "Progress: 89.4% ... Training loss: 0.248 ... Validation loss: 0.431\r",
      "Progress: 89.4% ... Training loss: 0.250 ... Validation loss: 0.429\r",
      "Progress: 89.4% ... Training loss: 0.246 ... Validation loss: 0.431\r",
      "Progress: 89.5% ... Training loss: 0.235 ... Validation loss: 0.418\r",
      "Progress: 89.5% ... Training loss: 0.249 ... Validation loss: 0.435\r",
      "Progress: 89.5% ... Training loss: 0.234 ... Validation loss: 0.420\r",
      "Progress: 89.5% ... Training loss: 0.235 ... Validation loss: 0.423\r",
      "Progress: 89.5% ... Training loss: 0.259 ... Validation loss: 0.439\r",
      "Progress: 89.5% ... Training loss: 0.238 ... Validation loss: 0.425\r",
      "Progress: 89.6% ... Training loss: 0.250 ... Validation loss: 0.430\r",
      "Progress: 89.6% ... Training loss: 0.234 ... Validation loss: 0.416\r",
      "Progress: 89.6% ... Training loss: 0.267 ... Validation loss: 0.455\r",
      "Progress: 89.6% ... Training loss: 0.273 ... Validation loss: 0.448\r",
      "Progress: 89.6% ... Training loss: 0.250 ... Validation loss: 0.437\r",
      "Progress: 89.7% ... Training loss: 0.259 ... Validation loss: 0.434\r",
      "Progress: 89.7% ... Training loss: 0.234 ... Validation loss: 0.418\r",
      "Progress: 89.7% ... Training loss: 0.235 ... Validation loss: 0.418\r",
      "Progress: 89.7% ... Training loss: 0.238 ... Validation loss: 0.418\r",
      "Progress: 89.7% ... Training loss: 0.235 ... Validation loss: 0.420\r",
      "Progress: 89.7% ... Training loss: 0.237 ... Validation loss: 0.424\r",
      "Progress: 89.8% ... Training loss: 0.234 ... Validation loss: 0.420\r",
      "Progress: 89.8% ... Training loss: 0.234 ... Validation loss: 0.420\r",
      "Progress: 89.8% ... Training loss: 0.241 ... Validation loss: 0.427\r",
      "Progress: 89.8% ... Training loss: 0.241 ... Validation loss: 0.422\r",
      "Progress: 89.8% ... Training loss: 0.249 ... Validation loss: 0.437\r",
      "Progress: 89.9% ... Training loss: 0.235 ... Validation loss: 0.420\r",
      "Progress: 89.9% ... Training loss: 0.238 ... Validation loss: 0.422\r",
      "Progress: 89.9% ... Training loss: 0.235 ... Validation loss: 0.421\r",
      "Progress: 89.9% ... Training loss: 0.234 ... Validation loss: 0.420\r",
      "Progress: 89.9% ... Training loss: 0.236 ... Validation loss: 0.421\r",
      "Progress: 89.9% ... Training loss: 0.234 ... Validation loss: 0.420\r",
      "Progress: 90.0% ... Training loss: 0.243 ... Validation loss: 0.429\r",
      "Progress: 90.0% ... Training loss: 0.248 ... Validation loss: 0.435\r",
      "Progress: 90.0% ... Training loss: 0.275 ... Validation loss: 0.463\r",
      "Progress: 90.0% ... Training loss: 0.243 ... Validation loss: 0.429\r",
      "Progress: 90.0% ... Training loss: 0.250 ... Validation loss: 0.435\r",
      "Progress: 90.1% ... Training loss: 0.260 ... Validation loss: 0.446\r",
      "Progress: 90.1% ... Training loss: 0.284 ... Validation loss: 0.462\r",
      "Progress: 90.1% ... Training loss: 0.261 ... Validation loss: 0.447\r",
      "Progress: 90.1% ... Training loss: 0.266 ... Validation loss: 0.445\r",
      "Progress: 90.1% ... Training loss: 0.257 ... Validation loss: 0.442\r",
      "Progress: 90.1% ... Training loss: 0.302 ... Validation loss: 0.467\r",
      "Progress: 90.2% ... Training loss: 0.292 ... Validation loss: 0.479\r",
      "Progress: 90.2% ... Training loss: 0.234 ... Validation loss: 0.417\r",
      "Progress: 90.2% ... Training loss: 0.253 ... Validation loss: 0.436\r",
      "Progress: 90.2% ... Training loss: 0.247 ... Validation loss: 0.425\r",
      "Progress: 90.2% ... Training loss: 0.238 ... Validation loss: 0.421\r",
      "Progress: 90.3% ... Training loss: 0.234 ... Validation loss: 0.416\r",
      "Progress: 90.3% ... Training loss: 0.241 ... Validation loss: 0.427\r",
      "Progress: 90.3% ... Training loss: 0.241 ... Validation loss: 0.421\r",
      "Progress: 90.3% ... Training loss: 0.235 ... Validation loss: 0.418\r",
      "Progress: 90.3% ... Training loss: 0.242 ... Validation loss: 0.430\r",
      "Progress: 90.3% ... Training loss: 0.267 ... Validation loss: 0.443\r",
      "Progress: 90.4% ... Training loss: 0.241 ... Validation loss: 0.427\r",
      "Progress: 90.4% ... Training loss: 0.244 ... Validation loss: 0.426\r",
      "Progress: 90.4% ... Training loss: 0.235 ... Validation loss: 0.419\r",
      "Progress: 90.4% ... Training loss: 0.235 ... Validation loss: 0.417\r",
      "Progress: 90.4% ... Training loss: 0.237 ... Validation loss: 0.421\r",
      "Progress: 90.5% ... Training loss: 0.235 ... Validation loss: 0.417\r",
      "Progress: 90.5% ... Training loss: 0.254 ... Validation loss: 0.445\r",
      "Progress: 90.5% ... Training loss: 0.235 ... Validation loss: 0.418\r",
      "Progress: 90.5% ... Training loss: 0.241 ... Validation loss: 0.431\r",
      "Progress: 90.5% ... Training loss: 0.233 ... Validation loss: 0.420\r",
      "Progress: 90.5% ... Training loss: 0.236 ... Validation loss: 0.425\r",
      "Progress: 90.6% ... Training loss: 0.235 ... Validation loss: 0.424\r",
      "Progress: 90.6% ... Training loss: 0.239 ... Validation loss: 0.423\r",
      "Progress: 90.6% ... Training loss: 0.236 ... Validation loss: 0.418\r",
      "Progress: 90.6% ... Training loss: 0.239 ... Validation loss: 0.419\r",
      "Progress: 90.6% ... Training loss: 0.232 ... Validation loss: 0.418\r",
      "Progress: 90.7% ... Training loss: 0.233 ... Validation loss: 0.419\r",
      "Progress: 90.7% ... Training loss: 0.236 ... Validation loss: 0.417\r",
      "Progress: 90.7% ... Training loss: 0.243 ... Validation loss: 0.432\r",
      "Progress: 90.7% ... Training loss: 0.247 ... Validation loss: 0.428\r",
      "Progress: 90.7% ... Training loss: 0.242 ... Validation loss: 0.430\r",
      "Progress: 90.7% ... Training loss: 0.236 ... Validation loss: 0.420\r",
      "Progress: 90.8% ... Training loss: 0.256 ... Validation loss: 0.446\r",
      "Progress: 90.8% ... Training loss: 0.296 ... Validation loss: 0.475\r",
      "Progress: 90.8% ... Training loss: 0.260 ... Validation loss: 0.449\r",
      "Progress: 90.8% ... Training loss: 0.238 ... Validation loss: 0.421\r",
      "Progress: 90.8% ... Training loss: 0.233 ... Validation loss: 0.416\r",
      "Progress: 90.9% ... Training loss: 0.239 ... Validation loss: 0.419\r",
      "Progress: 90.9% ... Training loss: 0.242 ... Validation loss: 0.429\r",
      "Progress: 90.9% ... Training loss: 0.239 ... Validation loss: 0.419\r",
      "Progress: 90.9% ... Training loss: 0.239 ... Validation loss: 0.419\r",
      "Progress: 90.9% ... Training loss: 0.234 ... Validation loss: 0.415\r",
      "Progress: 90.9% ... Training loss: 0.233 ... Validation loss: 0.416\r",
      "Progress: 91.0% ... Training loss: 0.243 ... Validation loss: 0.429\r",
      "Progress: 91.0% ... Training loss: 0.232 ... Validation loss: 0.419\r",
      "Progress: 91.0% ... Training loss: 0.232 ... Validation loss: 0.419\r",
      "Progress: 91.0% ... Training loss: 0.235 ... Validation loss: 0.422\r",
      "Progress: 91.0% ... Training loss: 0.232 ... Validation loss: 0.418\r",
      "Progress: 91.1% ... Training loss: 0.233 ... Validation loss: 0.420\r",
      "Progress: 91.1% ... Training loss: 0.232 ... Validation loss: 0.420\r",
      "Progress: 91.1% ... Training loss: 0.238 ... Validation loss: 0.426\r",
      "Progress: 91.1% ... Training loss: 0.238 ... Validation loss: 0.424\r",
      "Progress: 91.1% ... Training loss: 0.234 ... Validation loss: 0.420\r",
      "Progress: 91.1% ... Training loss: 0.241 ... Validation loss: 0.427\r",
      "Progress: 91.2% ... Training loss: 0.234 ... Validation loss: 0.421\r",
      "Progress: 91.2% ... Training loss: 0.237 ... Validation loss: 0.423\r",
      "Progress: 91.2% ... Training loss: 0.231 ... Validation loss: 0.419\r",
      "Progress: 91.2% ... Training loss: 0.234 ... Validation loss: 0.422\r",
      "Progress: 91.2% ... Training loss: 0.241 ... Validation loss: 0.429\r",
      "Progress: 91.3% ... Training loss: 0.232 ... Validation loss: 0.420\r",
      "Progress: 91.3% ... Training loss: 0.232 ... Validation loss: 0.421\r",
      "Progress: 91.3% ... Training loss: 0.259 ... Validation loss: 0.446\r",
      "Progress: 91.3% ... Training loss: 0.244 ... Validation loss: 0.430\r",
      "Progress: 91.3% ... Training loss: 0.231 ... Validation loss: 0.419\r",
      "Progress: 91.3% ... Training loss: 0.237 ... Validation loss: 0.423\r",
      "Progress: 91.4% ... Training loss: 0.262 ... Validation loss: 0.447\r",
      "Progress: 91.4% ... Training loss: 0.246 ... Validation loss: 0.428\r",
      "Progress: 91.4% ... Training loss: 0.249 ... Validation loss: 0.432\r",
      "Progress: 91.4% ... Training loss: 0.246 ... Validation loss: 0.432\r",
      "Progress: 91.4% ... Training loss: 0.235 ... Validation loss: 0.419\r",
      "Progress: 91.5% ... Training loss: 0.265 ... Validation loss: 0.445\r",
      "Progress: 91.5% ... Training loss: 0.242 ... Validation loss: 0.426\r",
      "Progress: 91.5% ... Training loss: 0.238 ... Validation loss: 0.420\r",
      "Progress: 91.5% ... Training loss: 0.231 ... Validation loss: 0.415\r",
      "Progress: 91.5% ... Training loss: 0.234 ... Validation loss: 0.419\r",
      "Progress: 91.5% ... Training loss: 0.306 ... Validation loss: 0.483\r",
      "Progress: 91.6% ... Training loss: 0.269 ... Validation loss: 0.451\r",
      "Progress: 91.6% ... Training loss: 0.252 ... Validation loss: 0.437\r",
      "Progress: 91.6% ... Training loss: 0.239 ... Validation loss: 0.423\r",
      "Progress: 91.6% ... Training loss: 0.242 ... Validation loss: 0.426\r",
      "Progress: 91.6% ... Training loss: 0.231 ... Validation loss: 0.416\r",
      "Progress: 91.7% ... Training loss: 0.231 ... Validation loss: 0.416\r",
      "Progress: 91.7% ... Training loss: 0.232 ... Validation loss: 0.418\r",
      "Progress: 91.7% ... Training loss: 0.233 ... Validation loss: 0.421\r",
      "Progress: 91.7% ... Training loss: 0.231 ... Validation loss: 0.417\r",
      "Progress: 91.7% ... Training loss: 0.232 ... Validation loss: 0.418\r",
      "Progress: 91.7% ... Training loss: 0.237 ... Validation loss: 0.424\r",
      "Progress: 91.8% ... Training loss: 0.231 ... Validation loss: 0.418\r",
      "Progress: 91.8% ... Training loss: 0.232 ... Validation loss: 0.420\r",
      "Progress: 91.8% ... Training loss: 0.234 ... Validation loss: 0.422\r",
      "Progress: 91.8% ... Training loss: 0.232 ... Validation loss: 0.423\r",
      "Progress: 91.8% ... Training loss: 0.233 ... Validation loss: 0.422\r",
      "Progress: 91.9% ... Training loss: 0.251 ... Validation loss: 0.446\r",
      "Progress: 91.9% ... Training loss: 0.231 ... Validation loss: 0.419\r",
      "Progress: 91.9% ... Training loss: 0.232 ... Validation loss: 0.421\r",
      "Progress: 91.9% ... Training loss: 0.231 ... Validation loss: 0.420\r",
      "Progress: 91.9% ... Training loss: 0.231 ... Validation loss: 0.417\r",
      "Progress: 91.9% ... Training loss: 0.232 ... Validation loss: 0.420\r",
      "Progress: 92.0% ... Training loss: 0.232 ... Validation loss: 0.418\r",
      "Progress: 92.0% ... Training loss: 0.232 ... Validation loss: 0.420\r",
      "Progress: 92.0% ... Training loss: 0.231 ... Validation loss: 0.416\r",
      "Progress: 92.0% ... Training loss: 0.230 ... Validation loss: 0.414\r",
      "Progress: 92.0% ... Training loss: 0.232 ... Validation loss: 0.415\r",
      "Progress: 92.1% ... Training loss: 0.232 ... Validation loss: 0.418\r",
      "Progress: 92.1% ... Training loss: 0.231 ... Validation loss: 0.417\r",
      "Progress: 92.1% ... Training loss: 0.231 ... Validation loss: 0.418\r",
      "Progress: 92.1% ... Training loss: 0.238 ... Validation loss: 0.421\r",
      "Progress: 92.1% ... Training loss: 0.230 ... Validation loss: 0.414\r",
      "Progress: 92.1% ... Training loss: 0.235 ... Validation loss: 0.419\r",
      "Progress: 92.2% ... Training loss: 0.230 ... Validation loss: 0.413\r",
      "Progress: 92.2% ... Training loss: 0.242 ... Validation loss: 0.426\r",
      "Progress: 92.2% ... Training loss: 0.270 ... Validation loss: 0.457\r",
      "Progress: 92.2% ... Training loss: 0.279 ... Validation loss: 0.463\r",
      "Progress: 92.2% ... Training loss: 0.234 ... Validation loss: 0.422\r",
      "Progress: 92.3% ... Training loss: 0.241 ... Validation loss: 0.428\r",
      "Progress: 92.3% ... Training loss: 0.232 ... Validation loss: 0.418\r",
      "Progress: 92.3% ... Training loss: 0.233 ... Validation loss: 0.419\r",
      "Progress: 92.3% ... Training loss: 0.234 ... Validation loss: 0.421\r",
      "Progress: 92.3% ... Training loss: 0.276 ... Validation loss: 0.451\r",
      "Progress: 92.3% ... Training loss: 0.235 ... Validation loss: 0.419\r",
      "Progress: 92.4% ... Training loss: 0.254 ... Validation loss: 0.430\r",
      "Progress: 92.4% ... Training loss: 0.233 ... Validation loss: 0.416\r",
      "Progress: 92.4% ... Training loss: 0.243 ... Validation loss: 0.420\r",
      "Progress: 92.4% ... Training loss: 0.254 ... Validation loss: 0.436\r",
      "Progress: 92.4% ... Training loss: 0.259 ... Validation loss: 0.437\r",
      "Progress: 92.5% ... Training loss: 0.240 ... Validation loss: 0.423\r",
      "Progress: 92.5% ... Training loss: 0.230 ... Validation loss: 0.414\r",
      "Progress: 92.5% ... Training loss: 0.232 ... Validation loss: 0.417\r",
      "Progress: 92.5% ... Training loss: 0.235 ... Validation loss: 0.419\r",
      "Progress: 92.5% ... Training loss: 0.266 ... Validation loss: 0.447\r",
      "Progress: 92.5% ... Training loss: 0.236 ... Validation loss: 0.419\r",
      "Progress: 92.6% ... Training loss: 0.263 ... Validation loss: 0.438\r",
      "Progress: 92.6% ... Training loss: 0.237 ... Validation loss: 0.420\r",
      "Progress: 92.6% ... Training loss: 0.231 ... Validation loss: 0.412\r",
      "Progress: 92.6% ... Training loss: 0.233 ... Validation loss: 0.416\r",
      "Progress: 92.6% ... Training loss: 0.257 ... Validation loss: 0.436\r",
      "Progress: 92.7% ... Training loss: 0.234 ... Validation loss: 0.417\r",
      "Progress: 92.7% ... Training loss: 0.230 ... Validation loss: 0.413\r",
      "Progress: 92.7% ... Training loss: 0.232 ... Validation loss: 0.415\r",
      "Progress: 92.7% ... Training loss: 0.230 ... Validation loss: 0.411\r",
      "Progress: 92.7% ... Training loss: 0.229 ... Validation loss: 0.411\r",
      "Progress: 92.7% ... Training loss: 0.237 ... Validation loss: 0.418\r",
      "Progress: 92.8% ... Training loss: 0.244 ... Validation loss: 0.428\r",
      "Progress: 92.8% ... Training loss: 0.254 ... Validation loss: 0.433\r",
      "Progress: 92.8% ... Training loss: 0.230 ... Validation loss: 0.412\r",
      "Progress: 92.8% ... Training loss: 0.252 ... Validation loss: 0.431\r",
      "Progress: 92.8% ... Training loss: 0.235 ... Validation loss: 0.417\r",
      "Progress: 92.9% ... Training loss: 0.229 ... Validation loss: 0.411\r",
      "Progress: 92.9% ... Training loss: 0.233 ... Validation loss: 0.414\r",
      "Progress: 92.9% ... Training loss: 0.271 ... Validation loss: 0.452\r",
      "Progress: 92.9% ... Training loss: 0.230 ... Validation loss: 0.410\r",
      "Progress: 92.9% ... Training loss: 0.235 ... Validation loss: 0.415\r",
      "Progress: 92.9% ... Training loss: 0.231 ... Validation loss: 0.412\r",
      "Progress: 93.0% ... Training loss: 0.231 ... Validation loss: 0.412\r",
      "Progress: 93.0% ... Training loss: 0.231 ... Validation loss: 0.413\r",
      "Progress: 93.0% ... Training loss: 0.232 ... Validation loss: 0.412\r",
      "Progress: 93.0% ... Training loss: 0.229 ... Validation loss: 0.409\r",
      "Progress: 93.0% ... Training loss: 0.229 ... Validation loss: 0.409\r",
      "Progress: 93.1% ... Training loss: 0.233 ... Validation loss: 0.413\r",
      "Progress: 93.1% ... Training loss: 0.230 ... Validation loss: 0.413\r",
      "Progress: 93.1% ... Training loss: 0.232 ... Validation loss: 0.414\r",
      "Progress: 93.1% ... Training loss: 0.231 ... Validation loss: 0.412\r",
      "Progress: 93.1% ... Training loss: 0.234 ... Validation loss: 0.412\r",
      "Progress: 93.1% ... Training loss: 0.230 ... Validation loss: 0.410\r",
      "Progress: 93.2% ... Training loss: 0.235 ... Validation loss: 0.417\r",
      "Progress: 93.2% ... Training loss: 0.235 ... Validation loss: 0.413\r",
      "Progress: 93.2% ... Training loss: 0.232 ... Validation loss: 0.414\r",
      "Progress: 93.2% ... Training loss: 0.230 ... Validation loss: 0.409\r",
      "Progress: 93.2% ... Training loss: 0.230 ... Validation loss: 0.410\r",
      "Progress: 93.3% ... Training loss: 0.235 ... Validation loss: 0.412\r",
      "Progress: 93.3% ... Training loss: 0.238 ... Validation loss: 0.420\r",
      "Progress: 93.3% ... Training loss: 0.229 ... Validation loss: 0.412\r",
      "Progress: 93.3% ... Training loss: 0.229 ... Validation loss: 0.410\r",
      "Progress: 93.3% ... Training loss: 0.237 ... Validation loss: 0.421\r",
      "Progress: 93.3% ... Training loss: 0.233 ... Validation loss: 0.413\r",
      "Progress: 93.4% ... Training loss: 0.239 ... Validation loss: 0.424\r",
      "Progress: 93.4% ... Training loss: 0.231 ... Validation loss: 0.413\r",
      "Progress: 93.4% ... Training loss: 0.230 ... Validation loss: 0.416\r",
      "Progress: 93.4% ... Training loss: 0.233 ... Validation loss: 0.412\r",
      "Progress: 93.4% ... Training loss: 0.243 ... Validation loss: 0.433\r",
      "Progress: 93.5% ... Training loss: 0.230 ... Validation loss: 0.417\r",
      "Progress: 93.5% ... Training loss: 0.233 ... Validation loss: 0.416\r",
      "Progress: 93.5% ... Training loss: 0.239 ... Validation loss: 0.428\r",
      "Progress: 93.5% ... Training loss: 0.230 ... Validation loss: 0.414\r",
      "Progress: 93.5% ... Training loss: 0.230 ... Validation loss: 0.418\r",
      "Progress: 93.5% ... Training loss: 0.229 ... Validation loss: 0.414\r",
      "Progress: 93.6% ... Training loss: 0.229 ... Validation loss: 0.416\r",
      "Progress: 93.6% ... Training loss: 0.233 ... Validation loss: 0.417\r",
      "Progress: 93.6% ... Training loss: 0.229 ... Validation loss: 0.415\r",
      "Progress: 93.6% ... Training loss: 0.230 ... Validation loss: 0.413\r",
      "Progress: 93.6% ... Training loss: 0.228 ... Validation loss: 0.412\r",
      "Progress: 93.7% ... Training loss: 0.229 ... Validation loss: 0.414\r",
      "Progress: 93.7% ... Training loss: 0.230 ... Validation loss: 0.413\r",
      "Progress: 93.7% ... Training loss: 0.232 ... Validation loss: 0.418\r",
      "Progress: 93.7% ... Training loss: 0.248 ... Validation loss: 0.430\r",
      "Progress: 93.7% ... Training loss: 0.239 ... Validation loss: 0.425\r",
      "Progress: 93.7% ... Training loss: 0.228 ... Validation loss: 0.413\r",
      "Progress: 93.8% ... Training loss: 0.228 ... Validation loss: 0.414\r",
      "Progress: 93.8% ... Training loss: 0.228 ... Validation loss: 0.413\r",
      "Progress: 93.8% ... Training loss: 0.239 ... Validation loss: 0.422\r",
      "Progress: 93.8% ... Training loss: 0.228 ... Validation loss: 0.411\r",
      "Progress: 93.8% ... Training loss: 0.228 ... Validation loss: 0.411\r",
      "Progress: 93.9% ... Training loss: 0.228 ... Validation loss: 0.413\r",
      "Progress: 93.9% ... Training loss: 0.228 ... Validation loss: 0.412\r",
      "Progress: 93.9% ... Training loss: 0.238 ... Validation loss: 0.417\r",
      "Progress: 93.9% ... Training loss: 0.256 ... Validation loss: 0.443\r",
      "Progress: 93.9% ... Training loss: 0.230 ... Validation loss: 0.413\r",
      "Progress: 93.9% ... Training loss: 0.232 ... Validation loss: 0.415\r",
      "Progress: 94.0% ... Training loss: 0.228 ... Validation loss: 0.411\r",
      "Progress: 94.0% ... Training loss: 0.234 ... Validation loss: 0.414\r",
      "Progress: 94.0% ... Training loss: 0.229 ... Validation loss: 0.409\r",
      "Progress: 94.0% ... Training loss: 0.230 ... Validation loss: 0.412\r",
      "Progress: 94.0% ... Training loss: 0.232 ... Validation loss: 0.413\r",
      "Progress: 94.1% ... Training loss: 0.233 ... Validation loss: 0.414\r",
      "Progress: 94.1% ... Training loss: 0.228 ... Validation loss: 0.409\r",
      "Progress: 94.1% ... Training loss: 0.233 ... Validation loss: 0.415\r",
      "Progress: 94.1% ... Training loss: 0.232 ... Validation loss: 0.412\r",
      "Progress: 94.1% ... Training loss: 0.250 ... Validation loss: 0.426\r",
      "Progress: 94.1% ... Training loss: 0.235 ... Validation loss: 0.413\r",
      "Progress: 94.2% ... Training loss: 0.251 ... Validation loss: 0.426\r",
      "Progress: 94.2% ... Training loss: 0.253 ... Validation loss: 0.430\r",
      "Progress: 94.2% ... Training loss: 0.235 ... Validation loss: 0.415\r",
      "Progress: 94.2% ... Training loss: 0.231 ... Validation loss: 0.409\r",
      "Progress: 94.2% ... Training loss: 0.233 ... Validation loss: 0.409\r",
      "Progress: 94.3% ... Training loss: 0.230 ... Validation loss: 0.406\r",
      "Progress: 94.3% ... Training loss: 0.228 ... Validation loss: 0.405\r",
      "Progress: 94.3% ... Training loss: 0.231 ... Validation loss: 0.408\r",
      "Progress: 94.3% ... Training loss: 0.229 ... Validation loss: 0.407\r",
      "Progress: 94.3% ... Training loss: 0.229 ... Validation loss: 0.407\r",
      "Progress: 94.3% ... Training loss: 0.229 ... Validation loss: 0.407\r",
      "Progress: 94.4% ... Training loss: 0.237 ... Validation loss: 0.416\r",
      "Progress: 94.4% ... Training loss: 0.246 ... Validation loss: 0.420\r",
      "Progress: 94.4% ... Training loss: 0.262 ... Validation loss: 0.441\r",
      "Progress: 94.4% ... Training loss: 0.246 ... Validation loss: 0.426\r",
      "Progress: 94.4% ... Training loss: 0.239 ... Validation loss: 0.418\r",
      "Progress: 94.5% ... Training loss: 0.233 ... Validation loss: 0.411\r",
      "Progress: 94.5% ... Training loss: 0.245 ... Validation loss: 0.423\r",
      "Progress: 94.5% ... Training loss: 0.229 ... Validation loss: 0.409\r",
      "Progress: 94.5% ... Training loss: 0.228 ... Validation loss: 0.411\r",
      "Progress: 94.5% ... Training loss: 0.229 ... Validation loss: 0.411\r",
      "Progress: 94.5% ... Training loss: 0.243 ... Validation loss: 0.433\r",
      "Progress: 94.6% ... Training loss: 0.241 ... Validation loss: 0.423\r",
      "Progress: 94.6% ... Training loss: 0.228 ... Validation loss: 0.415\r",
      "Progress: 94.6% ... Training loss: 0.233 ... Validation loss: 0.417\r",
      "Progress: 94.6% ... Training loss: 0.238 ... Validation loss: 0.425\r",
      "Progress: 94.6% ... Training loss: 0.227 ... Validation loss: 0.412\r",
      "Progress: 94.7% ... Training loss: 0.243 ... Validation loss: 0.427\r",
      "Progress: 94.7% ... Training loss: 0.242 ... Validation loss: 0.427\r",
      "Progress: 94.7% ... Training loss: 0.265 ... Validation loss: 0.450\r",
      "Progress: 94.7% ... Training loss: 0.291 ... Validation loss: 0.468\r",
      "Progress: 94.7% ... Training loss: 0.257 ... Validation loss: 0.445\r",
      "Progress: 94.7% ... Training loss: 0.228 ... Validation loss: 0.410\r",
      "Progress: 94.8% ... Training loss: 0.228 ... Validation loss: 0.411\r",
      "Progress: 94.8% ... Training loss: 0.229 ... Validation loss: 0.411\r",
      "Progress: 94.8% ... Training loss: 0.230 ... Validation loss: 0.415\r",
      "Progress: 94.8% ... Training loss: 0.228 ... Validation loss: 0.411\r",
      "Progress: 94.8% ... Training loss: 0.232 ... Validation loss: 0.412\r",
      "Progress: 94.9% ... Training loss: 0.227 ... Validation loss: 0.408\r",
      "Progress: 94.9% ... Training loss: 0.236 ... Validation loss: 0.415\r",
      "Progress: 94.9% ... Training loss: 0.228 ... Validation loss: 0.410\r",
      "Progress: 94.9% ... Training loss: 0.226 ... Validation loss: 0.410\r",
      "Progress: 94.9% ... Training loss: 0.229 ... Validation loss: 0.412\r",
      "Progress: 94.9% ... Training loss: 0.237 ... Validation loss: 0.419\r",
      "Progress: 95.0% ... Training loss: 0.239 ... Validation loss: 0.423\r",
      "Progress: 95.0% ... Training loss: 0.231 ... Validation loss: 0.414\r",
      "Progress: 95.0% ... Training loss: 0.226 ... Validation loss: 0.410\r",
      "Progress: 95.0% ... Training loss: 0.240 ... Validation loss: 0.423\r",
      "Progress: 95.0% ... Training loss: 0.245 ... Validation loss: 0.426\r",
      "Progress: 95.1% ... Training loss: 0.227 ... Validation loss: 0.410\r",
      "Progress: 95.1% ... Training loss: 0.226 ... Validation loss: 0.411\r",
      "Progress: 95.1% ... Training loss: 0.244 ... Validation loss: 0.427\r",
      "Progress: 95.1% ... Training loss: 0.231 ... Validation loss: 0.412\r",
      "Progress: 95.1% ... Training loss: 0.227 ... Validation loss: 0.407\r",
      "Progress: 95.1% ... Training loss: 0.226 ... Validation loss: 0.409\r",
      "Progress: 95.2% ... Training loss: 0.226 ... Validation loss: 0.409\r",
      "Progress: 95.2% ... Training loss: 0.226 ... Validation loss: 0.408\r",
      "Progress: 95.2% ... Training loss: 0.230 ... Validation loss: 0.413\r",
      "Progress: 95.2% ... Training loss: 0.226 ... Validation loss: 0.412\r",
      "Progress: 95.2% ... Training loss: 0.242 ... Validation loss: 0.425\r",
      "Progress: 95.3% ... Training loss: 0.258 ... Validation loss: 0.441\r",
      "Progress: 95.3% ... Training loss: 0.235 ... Validation loss: 0.418\r",
      "Progress: 95.3% ... Training loss: 0.229 ... Validation loss: 0.415\r",
      "Progress: 95.3% ... Training loss: 0.228 ... Validation loss: 0.413\r",
      "Progress: 95.3% ... Training loss: 0.230 ... Validation loss: 0.417\r",
      "Progress: 95.3% ... Training loss: 0.229 ... Validation loss: 0.414\r",
      "Progress: 95.4% ... Training loss: 0.236 ... Validation loss: 0.423\r",
      "Progress: 95.4% ... Training loss: 0.257 ... Validation loss: 0.436\r",
      "Progress: 95.4% ... Training loss: 0.230 ... Validation loss: 0.417\r",
      "Progress: 95.4% ... Training loss: 0.226 ... Validation loss: 0.410\r",
      "Progress: 95.4% ... Training loss: 0.229 ... Validation loss: 0.415\r",
      "Progress: 95.5% ... Training loss: 0.238 ... Validation loss: 0.424\r",
      "Progress: 95.5% ... Training loss: 0.241 ... Validation loss: 0.426\r",
      "Progress: 95.5% ... Training loss: 0.236 ... Validation loss: 0.426\r",
      "Progress: 95.5% ... Training loss: 0.242 ... Validation loss: 0.427\r",
      "Progress: 95.5% ... Training loss: 0.234 ... Validation loss: 0.421\r",
      "Progress: 95.5% ... Training loss: 0.259 ... Validation loss: 0.443\r",
      "Progress: 95.6% ... Training loss: 0.255 ... Validation loss: 0.444\r",
      "Progress: 95.6% ... Training loss: 0.271 ... Validation loss: 0.458\r",
      "Progress: 95.6% ... Training loss: 0.267 ... Validation loss: 0.447\r",
      "Progress: 95.6% ... Training loss: 0.245 ... Validation loss: 0.431\r",
      "Progress: 95.6% ... Training loss: 0.244 ... Validation loss: 0.427\r",
      "Progress: 95.7% ... Training loss: 0.250 ... Validation loss: 0.436\r",
      "Progress: 95.7% ... Training loss: 0.234 ... Validation loss: 0.416\r",
      "Progress: 95.7% ... Training loss: 0.261 ... Validation loss: 0.450\r",
      "Progress: 95.7% ... Training loss: 0.226 ... Validation loss: 0.413\r",
      "Progress: 95.7% ... Training loss: 0.231 ... Validation loss: 0.419\r",
      "Progress: 95.7% ... Training loss: 0.230 ... Validation loss: 0.414\r",
      "Progress: 95.8% ... Training loss: 0.229 ... Validation loss: 0.417\r",
      "Progress: 95.8% ... Training loss: 0.230 ... Validation loss: 0.413\r",
      "Progress: 95.8% ... Training loss: 0.228 ... Validation loss: 0.415\r",
      "Progress: 95.8% ... Training loss: 0.246 ... Validation loss: 0.424\r",
      "Progress: 95.8% ... Training loss: 0.229 ... Validation loss: 0.410\r",
      "Progress: 95.9% ... Training loss: 0.250 ... Validation loss: 0.440\r",
      "Progress: 95.9% ... Training loss: 0.237 ... Validation loss: 0.415\r",
      "Progress: 95.9% ... Training loss: 0.225 ... Validation loss: 0.408\r",
      "Progress: 95.9% ... Training loss: 0.225 ... Validation loss: 0.408\r",
      "Progress: 95.9% ... Training loss: 0.225 ... Validation loss: 0.411\r",
      "Progress: 95.9% ... Training loss: 0.227 ... Validation loss: 0.409\r",
      "Progress: 96.0% ... Training loss: 0.249 ... Validation loss: 0.439\r",
      "Progress: 96.0% ... Training loss: 0.259 ... Validation loss: 0.436\r",
      "Progress: 96.0% ... Training loss: 0.226 ... Validation loss: 0.412\r",
      "Progress: 96.0% ... Training loss: 0.225 ... Validation loss: 0.409\r",
      "Progress: 96.0% ... Training loss: 0.227 ... Validation loss: 0.410\r",
      "Progress: 96.1% ... Training loss: 0.231 ... Validation loss: 0.420\r",
      "Progress: 96.1% ... Training loss: 0.224 ... Validation loss: 0.409\r",
      "Progress: 96.1% ... Training loss: 0.227 ... Validation loss: 0.412\r",
      "Progress: 96.1% ... Training loss: 0.243 ... Validation loss: 0.417\r",
      "Progress: 96.1% ... Training loss: 0.225 ... Validation loss: 0.406\r",
      "Progress: 96.1% ... Training loss: 0.233 ... Validation loss: 0.409\r",
      "Progress: 96.2% ... Training loss: 0.225 ... Validation loss: 0.407\r",
      "Progress: 96.2% ... Training loss: 0.230 ... Validation loss: 0.416\r",
      "Progress: 96.2% ... Training loss: 0.230 ... Validation loss: 0.409\r",
      "Progress: 96.2% ... Training loss: 0.225 ... Validation loss: 0.406\r",
      "Progress: 96.2% ... Training loss: 0.228 ... Validation loss: 0.414\r",
      "Progress: 96.3% ... Training loss: 0.225 ... Validation loss: 0.410\r",
      "Progress: 96.3% ... Training loss: 0.229 ... Validation loss: 0.418\r",
      "Progress: 96.3% ... Training loss: 0.244 ... Validation loss: 0.425\r",
      "Progress: 96.3% ... Training loss: 0.240 ... Validation loss: 0.432\r",
      "Progress: 96.3% ... Training loss: 0.228 ... Validation loss: 0.414\r",
      "Progress: 96.3% ... Training loss: 0.233 ... Validation loss: 0.417\r",
      "Progress: 96.4% ... Training loss: 0.241 ... Validation loss: 0.431\r",
      "Progress: 96.4% ... Training loss: 0.259 ... Validation loss: 0.435\r",
      "Progress: 96.4% ... Training loss: 0.244 ... Validation loss: 0.434\r",
      "Progress: 96.4% ... Training loss: 0.236 ... Validation loss: 0.418\r",
      "Progress: 96.4% ... Training loss: 0.232 ... Validation loss: 0.421\r",
      "Progress: 96.5% ... Training loss: 0.236 ... Validation loss: 0.413\r",
      "Progress: 96.5% ... Training loss: 0.226 ... Validation loss: 0.413\r",
      "Progress: 96.5% ... Training loss: 0.227 ... Validation loss: 0.410\r",
      "Progress: 96.5% ... Training loss: 0.226 ... Validation loss: 0.413\r",
      "Progress: 96.5% ... Training loss: 0.224 ... Validation loss: 0.407\r",
      "Progress: 96.5% ... Training loss: 0.224 ... Validation loss: 0.407\r",
      "Progress: 96.6% ... Training loss: 0.224 ... Validation loss: 0.411\r",
      "Progress: 96.6% ... Training loss: 0.224 ... Validation loss: 0.408\r",
      "Progress: 96.6% ... Training loss: 0.224 ... Validation loss: 0.409\r",
      "Progress: 96.6% ... Training loss: 0.224 ... Validation loss: 0.410\r",
      "Progress: 96.6% ... Training loss: 0.226 ... Validation loss: 0.407\r",
      "Progress: 96.7% ... Training loss: 0.240 ... Validation loss: 0.432\r",
      "Progress: 96.7% ... Training loss: 0.224 ... Validation loss: 0.409\r",
      "Progress: 96.7% ... Training loss: 0.224 ... Validation loss: 0.409\r",
      "Progress: 96.7% ... Training loss: 0.225 ... Validation loss: 0.407\r",
      "Progress: 96.7% ... Training loss: 0.224 ... Validation loss: 0.407\r",
      "Progress: 96.7% ... Training loss: 0.224 ... Validation loss: 0.409\r",
      "Progress: 96.8% ... Training loss: 0.226 ... Validation loss: 0.414\r",
      "Progress: 96.8% ... Training loss: 0.225 ... Validation loss: 0.407\r",
      "Progress: 96.8% ... Training loss: 0.236 ... Validation loss: 0.426\r",
      "Progress: 96.8% ... Training loss: 0.261 ... Validation loss: 0.429\r",
      "Progress: 96.8% ... Training loss: 0.238 ... Validation loss: 0.427\r",
      "Progress: 96.9% ... Training loss: 0.226 ... Validation loss: 0.408\r",
      "Progress: 96.9% ... Training loss: 0.225 ... Validation loss: 0.407\r",
      "Progress: 96.9% ... Training loss: 0.224 ... Validation loss: 0.410\r",
      "Progress: 96.9% ... Training loss: 0.227 ... Validation loss: 0.408\r",
      "Progress: 96.9% ... Training loss: 0.235 ... Validation loss: 0.411\r",
      "Progress: 96.9% ... Training loss: 0.229 ... Validation loss: 0.417\r",
      "Progress: 97.0% ... Training loss: 0.224 ... Validation loss: 0.404\r",
      "Progress: 97.0% ... Training loss: 0.224 ... Validation loss: 0.409\r",
      "Progress: 97.0% ... Training loss: 0.230 ... Validation loss: 0.409\r",
      "Progress: 97.0% ... Training loss: 0.237 ... Validation loss: 0.429\r",
      "Progress: 97.0% ... Training loss: 0.224 ... Validation loss: 0.406\r",
      "Progress: 97.1% ... Training loss: 0.226 ... Validation loss: 0.416\r",
      "Progress: 97.1% ... Training loss: 0.223 ... Validation loss: 0.409\r",
      "Progress: 97.1% ... Training loss: 0.223 ... Validation loss: 0.406\r",
      "Progress: 97.1% ... Training loss: 0.224 ... Validation loss: 0.411\r",
      "Progress: 97.1% ... Training loss: 0.224 ... Validation loss: 0.413\r",
      "Progress: 97.1% ... Training loss: 0.224 ... Validation loss: 0.407\r",
      "Progress: 97.2% ... Training loss: 0.229 ... Validation loss: 0.422\r",
      "Progress: 97.2% ... Training loss: 0.236 ... Validation loss: 0.413\r",
      "Progress: 97.2% ... Training loss: 0.225 ... Validation loss: 0.415\r",
      "Progress: 97.2% ... Training loss: 0.226 ... Validation loss: 0.410\r",
      "Progress: 97.2% ... Training loss: 0.223 ... Validation loss: 0.410\r",
      "Progress: 97.3% ... Training loss: 0.225 ... Validation loss: 0.409\r",
      "Progress: 97.3% ... Training loss: 0.226 ... Validation loss: 0.414\r",
      "Progress: 97.3% ... Training loss: 0.227 ... Validation loss: 0.409\r",
      "Progress: 97.3% ... Training loss: 0.229 ... Validation loss: 0.418\r",
      "Progress: 97.3% ... Training loss: 0.225 ... Validation loss: 0.413\r",
      "Progress: 97.3% ... Training loss: 0.254 ... Validation loss: 0.432\r",
      "Progress: 97.4% ... Training loss: 0.237 ... Validation loss: 0.429\r",
      "Progress: 97.4% ... Training loss: 0.226 ... Validation loss: 0.411\r",
      "Progress: 97.4% ... Training loss: 0.237 ... Validation loss: 0.430\r",
      "Progress: 97.4% ... Training loss: 0.227 ... Validation loss: 0.413\r",
      "Progress: 97.4% ... Training loss: 0.224 ... Validation loss: 0.411\r",
      "Progress: 97.5% ... Training loss: 0.229 ... Validation loss: 0.412\r",
      "Progress: 97.5% ... Training loss: 0.223 ... Validation loss: 0.410\r",
      "Progress: 97.5% ... Training loss: 0.224 ... Validation loss: 0.412\r",
      "Progress: 97.5% ... Training loss: 0.236 ... Validation loss: 0.427\r",
      "Progress: 97.5% ... Training loss: 0.232 ... Validation loss: 0.416\r",
      "Progress: 97.5% ... Training loss: 0.225 ... Validation loss: 0.413\r",
      "Progress: 97.6% ... Training loss: 0.229 ... Validation loss: 0.409\r",
      "Progress: 97.6% ... Training loss: 0.233 ... Validation loss: 0.421\r",
      "Progress: 97.6% ... Training loss: 0.227 ... Validation loss: 0.416\r",
      "Progress: 97.6% ... Training loss: 0.233 ... Validation loss: 0.416\r",
      "Progress: 97.6% ... Training loss: 0.236 ... Validation loss: 0.426\r",
      "Progress: 97.7% ... Training loss: 0.282 ... Validation loss: 0.453\r",
      "Progress: 97.7% ... Training loss: 0.232 ... Validation loss: 0.421\r",
      "Progress: 97.7% ... Training loss: 0.224 ... Validation loss: 0.411\r",
      "Progress: 97.7% ... Training loss: 0.225 ... Validation loss: 0.405\r",
      "Progress: 97.7% ... Training loss: 0.226 ... Validation loss: 0.413\r",
      "Progress: 97.7% ... Training loss: 0.224 ... Validation loss: 0.411\r",
      "Progress: 97.8% ... Training loss: 0.222 ... Validation loss: 0.407\r",
      "Progress: 97.8% ... Training loss: 0.238 ... Validation loss: 0.430\r",
      "Progress: 97.8% ... Training loss: 0.224 ... Validation loss: 0.409\r",
      "Progress: 97.8% ... Training loss: 0.222 ... Validation loss: 0.409\r",
      "Progress: 97.8% ... Training loss: 0.226 ... Validation loss: 0.407\r",
      "Progress: 97.9% ... Training loss: 0.233 ... Validation loss: 0.425\r",
      "Progress: 97.9% ... Training loss: 0.222 ... Validation loss: 0.406\r",
      "Progress: 97.9% ... Training loss: 0.227 ... Validation loss: 0.417\r",
      "Progress: 97.9% ... Training loss: 0.222 ... Validation loss: 0.410\r",
      "Progress: 97.9% ... Training loss: 0.224 ... Validation loss: 0.406\r",
      "Progress: 97.9% ... Training loss: 0.232 ... Validation loss: 0.422\r",
      "Progress: 98.0% ... Training loss: 0.224 ... Validation loss: 0.405\r",
      "Progress: 98.0% ... Training loss: 0.223 ... Validation loss: 0.408\r",
      "Progress: 98.0% ... Training loss: 0.222 ... Validation loss: 0.405\r",
      "Progress: 98.0% ... Training loss: 0.225 ... Validation loss: 0.411\r",
      "Progress: 98.0% ... Training loss: 0.227 ... Validation loss: 0.409\r",
      "Progress: 98.1% ... Training loss: 0.223 ... Validation loss: 0.407\r",
      "Progress: 98.1% ... Training loss: 0.228 ... Validation loss: 0.407\r",
      "Progress: 98.1% ... Training loss: 0.238 ... Validation loss: 0.426\r",
      "Progress: 98.1% ... Training loss: 0.223 ... Validation loss: 0.405\r",
      "Progress: 98.1% ... Training loss: 0.258 ... Validation loss: 0.446\r",
      "Progress: 98.1% ... Training loss: 0.223 ... Validation loss: 0.410\r",
      "Progress: 98.2% ... Training loss: 0.228 ... Validation loss: 0.413\r",
      "Progress: 98.2% ... Training loss: 0.234 ... Validation loss: 0.420\r",
      "Progress: 98.2% ... Training loss: 0.222 ... Validation loss: 0.407\r",
      "Progress: 98.2% ... Training loss: 0.222 ... Validation loss: 0.408\r",
      "Progress: 98.2% ... Training loss: 0.229 ... Validation loss: 0.411\r",
      "Progress: 98.3% ... Training loss: 0.224 ... Validation loss: 0.409\r",
      "Progress: 98.3% ... Training loss: 0.226 ... Validation loss: 0.415\r",
      "Progress: 98.3% ... Training loss: 0.225 ... Validation loss: 0.407\r",
      "Progress: 98.3% ... Training loss: 0.241 ... Validation loss: 0.437\r",
      "Progress: 98.3% ... Training loss: 0.225 ... Validation loss: 0.408\r",
      "Progress: 98.3% ... Training loss: 0.225 ... Validation loss: 0.416\r",
      "Progress: 98.4% ... Training loss: 0.221 ... Validation loss: 0.407\r",
      "Progress: 98.4% ... Training loss: 0.222 ... Validation loss: 0.411\r",
      "Progress: 98.4% ... Training loss: 0.227 ... Validation loss: 0.419\r",
      "Progress: 98.4% ... Training loss: 0.231 ... Validation loss: 0.425\r",
      "Progress: 98.4% ... Training loss: 0.229 ... Validation loss: 0.411\r",
      "Progress: 98.5% ... Training loss: 0.258 ... Validation loss: 0.457\r",
      "Progress: 98.5% ... Training loss: 0.223 ... Validation loss: 0.409\r",
      "Progress: 98.5% ... Training loss: 0.223 ... Validation loss: 0.413\r",
      "Progress: 98.5% ... Training loss: 0.223 ... Validation loss: 0.405\r",
      "Progress: 98.5% ... Training loss: 0.225 ... Validation loss: 0.405\r",
      "Progress: 98.5% ... Training loss: 0.221 ... Validation loss: 0.408\r",
      "Progress: 98.6% ... Training loss: 0.224 ... Validation loss: 0.407\r",
      "Progress: 98.6% ... Training loss: 0.225 ... Validation loss: 0.412\r",
      "Progress: 98.6% ... Training loss: 0.223 ... Validation loss: 0.405\r",
      "Progress: 98.6% ... Training loss: 0.226 ... Validation loss: 0.406\r",
      "Progress: 98.6% ... Training loss: 0.221 ... Validation loss: 0.404\r",
      "Progress: 98.7% ... Training loss: 0.221 ... Validation loss: 0.402\r",
      "Progress: 98.7% ... Training loss: 0.221 ... Validation loss: 0.406\r",
      "Progress: 98.7% ... Training loss: 0.223 ... Validation loss: 0.404\r",
      "Progress: 98.7% ... Training loss: 0.221 ... Validation loss: 0.407\r",
      "Progress: 98.7% ... Training loss: 0.221 ... Validation loss: 0.407\r",
      "Progress: 98.7% ... Training loss: 0.220 ... Validation loss: 0.405\r",
      "Progress: 98.8% ... Training loss: 0.224 ... Validation loss: 0.409\r",
      "Progress: 98.8% ... Training loss: 0.227 ... Validation loss: 0.407\r",
      "Progress: 98.8% ... Training loss: 0.234 ... Validation loss: 0.421\r",
      "Progress: 98.8% ... Training loss: 0.221 ... Validation loss: 0.404\r",
      "Progress: 98.8% ... Training loss: 0.229 ... Validation loss: 0.409\r",
      "Progress: 98.9% ... Training loss: 0.221 ... Validation loss: 0.406\r",
      "Progress: 98.9% ... Training loss: 0.224 ... Validation loss: 0.409\r",
      "Progress: 98.9% ... Training loss: 0.225 ... Validation loss: 0.407\r",
      "Progress: 98.9% ... Training loss: 0.232 ... Validation loss: 0.416\r",
      "Progress: 98.9% ... Training loss: 0.225 ... Validation loss: 0.409\r",
      "Progress: 98.9% ... Training loss: 0.221 ... Validation loss: 0.403\r",
      "Progress: 99.0% ... Training loss: 0.226 ... Validation loss: 0.409\r",
      "Progress: 99.0% ... Training loss: 0.224 ... Validation loss: 0.407\r",
      "Progress: 99.0% ... Training loss: 0.220 ... Validation loss: 0.402\r",
      "Progress: 99.0% ... Training loss: 0.221 ... Validation loss: 0.403\r",
      "Progress: 99.0% ... Training loss: 0.230 ... Validation loss: 0.414\r",
      "Progress: 99.1% ... Training loss: 0.227 ... Validation loss: 0.409\r",
      "Progress: 99.1% ... Training loss: 0.253 ... Validation loss: 0.435\r",
      "Progress: 99.1% ... Training loss: 0.225 ... Validation loss: 0.410\r",
      "Progress: 99.1% ... Training loss: 0.251 ... Validation loss: 0.440\r",
      "Progress: 99.1% ... Training loss: 0.314 ... Validation loss: 0.488\r",
      "Progress: 99.1% ... Training loss: 0.225 ... Validation loss: 0.410\r",
      "Progress: 99.2% ... Training loss: 0.221 ... Validation loss: 0.405\r",
      "Progress: 99.2% ... Training loss: 0.220 ... Validation loss: 0.404\r",
      "Progress: 99.2% ... Training loss: 0.221 ... Validation loss: 0.404\r",
      "Progress: 99.2% ... Training loss: 0.227 ... Validation loss: 0.410\r",
      "Progress: 99.2% ... Training loss: 0.257 ... Validation loss: 0.441\r",
      "Progress: 99.3% ... Training loss: 0.220 ... Validation loss: 0.403\r",
      "Progress: 99.3% ... Training loss: 0.223 ... Validation loss: 0.404\r",
      "Progress: 99.3% ... Training loss: 0.222 ... Validation loss: 0.405\r",
      "Progress: 99.3% ... Training loss: 0.238 ... Validation loss: 0.413\r",
      "Progress: 99.3% ... Training loss: 0.230 ... Validation loss: 0.415\r",
      "Progress: 99.3% ... Training loss: 0.220 ... Validation loss: 0.403\r",
      "Progress: 99.4% ... Training loss: 0.241 ... Validation loss: 0.416\r",
      "Progress: 99.4% ... Training loss: 0.263 ... Validation loss: 0.451\r",
      "Progress: 99.4% ... Training loss: 0.225 ... Validation loss: 0.409\r",
      "Progress: 99.4% ... Training loss: 0.232 ... Validation loss: 0.420\r",
      "Progress: 99.4% ... Training loss: 0.224 ... Validation loss: 0.407\r",
      "Progress: 99.5% ... Training loss: 0.219 ... Validation loss: 0.405\r",
      "Progress: 99.5% ... Training loss: 0.233 ... Validation loss: 0.420\r",
      "Progress: 99.5% ... Training loss: 0.219 ... Validation loss: 0.405\r",
      "Progress: 99.5% ... Training loss: 0.225 ... Validation loss: 0.413\r",
      "Progress: 99.5% ... Training loss: 0.235 ... Validation loss: 0.420\r",
      "Progress: 99.5% ... Training loss: 0.227 ... Validation loss: 0.415\r",
      "Progress: 99.6% ... Training loss: 0.219 ... Validation loss: 0.404\r",
      "Progress: 99.6% ... Training loss: 0.221 ... Validation loss: 0.408\r",
      "Progress: 99.6% ... Training loss: 0.225 ... Validation loss: 0.406\r",
      "Progress: 99.6% ... Training loss: 0.244 ... Validation loss: 0.433\r",
      "Progress: 99.6% ... Training loss: 0.226 ... Validation loss: 0.411\r",
      "Progress: 99.7% ... Training loss: 0.226 ... Validation loss: 0.414\r",
      "Progress: 99.7% ... Training loss: 0.224 ... Validation loss: 0.408\r",
      "Progress: 99.7% ... Training loss: 0.225 ... Validation loss: 0.415\r",
      "Progress: 99.7% ... Training loss: 0.226 ... Validation loss: 0.408\r",
      "Progress: 99.7% ... Training loss: 0.219 ... Validation loss: 0.406\r",
      "Progress: 99.7% ... Training loss: 0.220 ... Validation loss: 0.406\r",
      "Progress: 99.8% ... Training loss: 0.219 ... Validation loss: 0.405\r",
      "Progress: 99.8% ... Training loss: 0.241 ... Validation loss: 0.422\r",
      "Progress: 99.8% ... Training loss: 0.225 ... Validation loss: 0.410\r",
      "Progress: 99.8% ... Training loss: 0.218 ... Validation loss: 0.404\r",
      "Progress: 99.8% ... Training loss: 0.219 ... Validation loss: 0.405\r",
      "Progress: 99.9% ... Training loss: 0.222 ... Validation loss: 0.409\r",
      "Progress: 99.9% ... Training loss: 0.238 ... Validation loss: 0.421\r",
      "Progress: 99.9% ... Training loss: 0.232 ... Validation loss: 0.420\r",
      "Progress: 99.9% ... Training loss: 0.221 ... Validation loss: 0.404\r",
      "Progress: 99.9% ... Training loss: 0.220 ... Validation loss: 0.406\r",
      "Progress: 99.9% ... Training loss: 0.233 ... Validation loss: 0.423\r",
      "Progress: 100.0% ... Training loss: 0.223 ... Validation loss: 0.409\r",
      "Progress: 100.0% ... Training loss: 0.236 ... Validation loss: 0.426"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "### TODO:Set the hyperparameters here, you need to change the defalut to get a better solution ###\n",
    "iterations = 5500\n",
    "learning_rate = 0.15\n",
    "hidden_nodes = 50\n",
    "output_nodes = 1\n",
    "\n",
    "N_i = train_features.shape[1]\n",
    "network = NeuralNetwork(N_i, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "losses = {'train':[], 'validation':[]}\n",
    "for ii in range(iterations):\n",
    "    # Go through a random batch of 128 records from the training data set\n",
    "    batch = np.random.choice(train_features.index, size=128)\n",
    "    X, y = train_features.ix[batch].values, train_targets.ix[batch]['cnt']\n",
    "                             \n",
    "    network.train(X, y)\n",
    "    \n",
    "    # Printing out the training progress\n",
    "    train_loss = MSE(network.run(train_features).T, train_targets['cnt'].values)\n",
    "    val_loss = MSE(network.run(val_features).T, val_targets['cnt'].values)\n",
    "    sys.stdout.write(\"\\rProgress: {:2.1f}\".format(100 * ii/float(iterations)) \\\n",
    "                     + \"% ... Training loss: \" + str(train_loss)[:5] \\\n",
    "                     + \" ... Validation loss: \" + str(val_loss)[:5])\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    losses['train'].append(train_loss)\n",
    "    losses['validation'].append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAH0CAYAAACEkWPuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nILyU/wd5kTzsnda69AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1074daeb8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 373
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses['train'], label='Training loss')\n",
    "plt.plot(losses['validation'], label='Validation loss')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查预测结果\n",
    "\n",
    "使用测试数据看看网络对数据建模的效果如何。如果完全错了，请确保网络中的每步都正确实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+0AAAIgCAYAAADwRojNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113578860>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 272,
       "width": 502
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "\n",
    "mean, std = scaled_features['cnt']\n",
    "predictions = network.run(test_features).T*std + mean\n",
    "ax.plot(predictions[0], label='Prediction')\n",
    "ax.plot((test_targets['cnt']*std + mean).values, label='Data')\n",
    "ax.set_xlim(right=len(predictions))\n",
    "ax.legend()\n",
    "\n",
    "dates = pd.to_datetime(rides.ix[test_data.index]['dteday'])\n",
    "dates = dates.apply(lambda d: d.strftime('%b %d'))\n",
    "ax.set_xticks(np.arange(len(dates))[12::24])\n",
    "_ = ax.set_xticklabels(dates[12::24], rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可选：思考下你的结果（我们不会评估这道题的答案）\n",
    "\n",
    " \n",
    "请针对你的结果回答以下问题。模型对数据的预测效果如何？哪里出现问题了？为何出现问题呢？\n",
    "\n",
    "> **注意**：你可以通过双击该单元编辑文本。如果想要预览文本，请按 Control + Enter\n",
    "\n",
    "#### 请将你的答案填写在下方\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
